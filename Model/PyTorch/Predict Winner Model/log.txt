Training on:   cpu
Loading Test Data...
Finished Loading Test Data.

Iteration: 1
    Time:  96.194
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  1.0317784236545697
    Accuracy:  0.5639867966764047
Iteration: 2
    Time:  95.315
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  1.1532135541677981
    Accuracy:  0.5639867966764047
Iteration: 3
    Time:  99.825
    Number of Data points:         512
    Number of Training batches:    16 

    Loss:  0.9763480239089442
    Accuracy:  0.5639867966764047
Iteration: 4
    Time:  77.773
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.852222512908666
    Accuracy:  0.5639867966764047
Iteration: 5
    Time:  91.406
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.7500683044110643
    Accuracy:  0.5639867966764047
Iteration: 6
    Time:  95.267
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  0.6566242564851281
    Accuracy:  0.5639867966764047
Iteration: 7
    Time:  83.04
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.6438381658330448
    Accuracy:  0.5639867966764047
Iteration: 8
    Time:  96.867
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  1.4670940741196627
    Accuracy:  0.5639867966764047
Iteration: 9
    Time:  80.158
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.4331179025979721
    Accuracy:  0.5639867966764047
Iteration: 10
    Time:  99.071
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  1.3903417317077194
    Accuracy:  0.5639867966764047
Iteration: 11
    Time:  80.819
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.7279559850082908
    Accuracy:  0.5639867966764047
Iteration: 12
    Time:  96.687
    Number of Data points:         512
    Number of Training batches:    16 

    Loss:  0.6463010035899148
    Accuracy:  0.5639867966764047
Iteration: 13
    Time:  100.747
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  0.6209681260651982
    Accuracy:  0.5639867966764047
Iteration: 14
    Time:  83.594
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.6189152981957581
    Accuracy:  0.5639867966764047
Iteration: 15
    Time:  98.549
    Number of Data points:         520
    Number of Training batches:    17 

    Loss:  1.4848064264743157
    Accuracy:  0.5639867966764047
Iteration: 16
    Time:  107.245
    Number of Data points:         520
    Number of Training batches:    17 

    Loss:  1.476768910376481
    Accuracy:  0.5639867966764047
Iteration: 17
    Time:  100.481
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  1.4460840193542275
    Accuracy:  0.5639867966764047
Iteration: 18
    Time:  74.793
    Number of Data points:         368
    Number of Training batches:    12 

    Loss:  0.6941776197189974
    Accuracy:  0.5639867966764047
Iteration: 19
    Time:  77.674
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  1.418600194277201
    Accuracy:  0.5639867966764047
Iteration: 20
    Time:  112.75
    Number of Data points:         528
    Number of Training batches:    17 

    Loss:  1.3944730112497699
    Accuracy:  0.5639867966764047
Iteration: 21
    Time:  83.125
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.739367937225256
    Accuracy:  0.5639867966764047
Iteration: 22
    Time:  99.636
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  0.6576602776385653
    Accuracy:  0.5639867966764047
Iteration: 23
    Time:  81.362
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.635985250487326
    Accuracy:  0.5639867966764047
Iteration: 24
    Time:  88.329
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.437078868390057
    Accuracy:  0.5639867966764047
Iteration: 25
    Time:  78.017
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.3997615609687328
    Accuracy:  0.5639867966764047
Iteration: 26
    Time:  93.336
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  0.6700153506713347
    Accuracy:  0.5639867966764047
Iteration: 27
    Time:  82.161
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.6346377168374249
    Accuracy:  0.5639867966764047
Iteration: 28
    Time:  71.579
    Number of Data points:         360
    Number of Training batches:    12 

    Loss:  1.434387538248098
    Accuracy:  0.5639867966764047
Iteration: 29
    Time:  83.704
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.6313651713522906
    Accuracy:  0.5639867966764047
Iteration: 30
    Time:  85.979
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.6190166059759753
    Accuracy:  0.5639867966764047
Iteration: 31
    Time:  101.101
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  1.4771799177224216
    Accuracy:  0.5639867966764047
Iteration: 32
    Time:  94.699
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.635827434874323
    Accuracy:  0.5639867966764047
Iteration: 33
    Time:  81.225
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  1.4613429408692156
    Accuracy:  0.5639867966764047
Iteration: 34
    Time:  82.791
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.4509819317237533
    Accuracy:  0.5639867966764047
Iteration: 35
    Time:  83.656
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  1.4465137326782276
    Accuracy:  0.5639867966764047
Iteration: 36
    Time:  85.604
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.6595760987528454
    Accuracy:  0.5639867966764047
Iteration: 37
    Time:  80.16
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.6432224984111383
    Accuracy:  0.5639867966764047
Iteration: 38
    Time:  88.587
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.449741414255221
    Accuracy:  0.5639867966764047
Iteration: 39
    Time:  80.968
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.6438571824794196
    Accuracy:  0.5639867966764047
Iteration: 40
    Time:  96.137
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  0.6226731230773525
    Accuracy:  0.5639867966764047
Iteration: 41
    Time:  91.662
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.4745170443717386
    Accuracy:  0.5639867966764047
Iteration: 42
    Time:  76.413
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  1.448759641542667
    Accuracy:  0.5639867966764047
Iteration: 43
    Time:  89.939
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  1.4507463601290183
    Accuracy:  0.5639867966764047
Iteration: 44
    Time:  92.472
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  1.3853404299075696
    Accuracy:  0.5639867966764047
Iteration: 45
    Time:  91.446
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.3430167252043737
    Accuracy:  0.5639867966764047
Iteration: 46
    Time:  96.884
    Number of Data points:         520
    Number of Training batches:    17 

    Loss:  1.266825424595323
    Accuracy:  0.5639867966764047
Iteration: 47
    Time:  75.135
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  1.1687943200253035
    Accuracy:  0.5639867966764047
Iteration: 48
Could not find child with move:  5 0
An Exception was thrown
Iteration: 49
    Time:  99.119
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  1.129051968967466
    Accuracy:  0.5557347194293736
Iteration: 50
    Time:  89.436
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.0580437962327311
    Accuracy:  0.3826687407519824
Iteration: 51
    Time:  91.149
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.9469965781977027
    Accuracy:  0.3823652160716318
Iteration: 52
    Time:  72.634
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  1.1665228781185475
    Accuracy:  0.38509693819478696
Iteration: 53
    Time:  88.779
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.9374073580041627
    Accuracy:  0.3823652160716318
Iteration: 54
    Time:  92.375
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.2070833108063799
    Accuracy:  0.3823652160716318
Iteration: 55
    Time:  94.97
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  0.8687742329057759
    Accuracy:  0.3823652160716318
Iteration: 56
    Time:  105.414
    Number of Data points:         512
    Number of Training batches:    16 

    Loss:  1.2757934155651185
    Accuracy:  0.3823652160716318
Iteration: 57
    Time:  78.98
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.8676732192955
    Accuracy:  0.3823652160716318
Iteration: 58
    Time:  116.348
    Number of Data points:         592
    Number of Training batches:    19 

    Loss:  1.2792040198699663
    Accuracy:  0.3823652160716318
Iteration: 59
Could not find child with move:  8 1
An Exception was thrown
Iteration: 60
    Time:  71.921
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  0.9352297307000287
    Accuracy:  0.3823652160716318
Iteration: 61
Could not find child with move:  7 6
An Exception was thrown
Iteration: 62
    Time:  97.758
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  1.2068262612369964
    Accuracy:  0.3823652160716318
Iteration: 63
    Time:  83.052
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  1.1187324553449667
    Accuracy:  0.4971544561217134
Iteration: 64
Could not find child with move:  0 4
An Exception was thrown
Iteration: 65
    Time:  82.125
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  1.0283273310184664
    Accuracy:  0.5639867966764047
Iteration: 66
    Time:  87.183
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.8747222843127312
    Accuracy:  0.5639867966764047
Iteration: 67
    Time:  90.688
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.7556842779090065
    Accuracy:  0.5639867966764047
Iteration: 68
    Time:  95.778
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  1.3235496155681215
    Accuracy:  0.5639867966764047
Iteration: 69
    Time:  86.498
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.7393928606643116
    Accuracy:  0.5639867966764047
Iteration: 70
    Time:  87.91
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  1.336322716211672
    Accuracy:  0.5639867966764047
Iteration: 71
    Time:  91.493
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.2528859426109376
    Accuracy:  0.5639867966764047
Iteration: 72
    Time:  75.888
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  1.1361757880848165
    Accuracy:  0.5585233524300944
Iteration: 73
    Time:  84.328
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.8919355730432363
    Accuracy:  0.5639867966764047
Iteration: 74
    Time:  95.922
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  0.7200961933177394
    Accuracy:  0.5639867966764047
Iteration: 75
    Time:  76.204
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  1.3079958644115532
    Accuracy:  0.5639867966764047
Iteration: 76
    Time:  68.473
    Number of Data points:         368
    Number of Training batches:    12 

    Loss:  0.8136918772084983
    Accuracy:  0.5639867966764047
Iteration: 77
    Time:  84.864
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.3184015081352816
    Accuracy:  0.5639867966764047
Iteration: 78
    Time:  86.128
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  1.269446660019893
    Accuracy:  0.5639867966764047
Iteration: 79
    Time:  99.542
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  0.8302101337389016
    Accuracy:  0.5639867966764047
Iteration: 80
    Time:  91.997
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.7893172321752199
    Accuracy:  0.5639867966764047
Iteration: 81
    Time:  91.802
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.391851800390629
    Accuracy:  0.5639867966764047
Iteration: 82
    Time:  106.839
    Number of Data points:         520
    Number of Training batches:    17 

    Loss:  1.2904930936953292
    Accuracy:  0.5639867966764047
Iteration: 83
    Time:  88.861
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.7960192099820224
    Accuracy:  0.5639867966764047
Iteration: 84
    Time:  77.266
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  1.333992799656868
    Accuracy:  0.5639867966764047
Iteration: 85
    Time:  90.807
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.7629423119045199
    Accuracy:  0.5639867966764047
Iteration: 86
    Time:  79.347
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.7273565741093194
    Accuracy:  0.5639867966764047
Iteration: 87
    Time:  102.959
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  0.6349718974366179
    Accuracy:  0.5639867966764047
Iteration: 88
    Time:  91.715
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  1.4053303543723332
    Accuracy:  0.5639867966764047
Iteration: 89
    Time:  92.586
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  1.3399879561572423
    Accuracy:  0.5639867966764047
Iteration: 90
    Time:  79.054
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.7582839262748761
    Accuracy:  0.5639867966764047
Iteration: 91
    Time:  76.422
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  1.307933702263009
    Accuracy:  0.5639867966764047
Iteration: 92
    Time:  94.415
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  1.276145640037425
    Accuracy:  0.5639867966764047
Iteration: 93
    Time:  95.517
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  1.0833623966167811
    Accuracy:  0.5272982509390295
Iteration: 94
    Time:  104.825
    Number of Data points:         520
    Number of Training batches:    17 

    Loss:  0.9603507792641042
    Accuracy:  0.382972265432333
Iteration: 95
    Time:  74.239
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  0.8051739780380021
    Accuracy:  0.3823652160716318
Iteration: 96
    Time:  96.872
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  1.2914850278717354
    Accuracy:  0.38467959175930494
Iteration: 97
    Time:  93.392
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.7996994886098231
    Accuracy:  0.3823652160716318
Iteration: 98
    Time:  89.676
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  1.274767946669414
    Accuracy:  0.38414842356869144
Iteration: 99
    Time:  91.36
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.7942546883134209
    Accuracy:  0.3823652160716318
Iteration: 100
    Time:  100.351
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  1.2027033107045768
    Accuracy:  0.43134651136320523
Iteration: 101
    Time:  97.723
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.821161222935228
    Accuracy:  0.3823652160716318
Iteration: 102
    Time:  101.078
    Number of Data points:         512
    Number of Training batches:    16 

    Loss:  1.0932917360455545
    Accuracy:  0.5053306521986569
Iteration: 103
    Time:  92.697
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.860175475897909
    Accuracy:  0.3963083810752362
Iteration: 104
    Time:  75.582
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  0.7426216880745006
    Accuracy:  0.3824600675342414
Iteration: 105
    Time:  71.773
    Number of Data points:         360
    Number of Training batches:    12 

    Loss:  0.6815686931132131
    Accuracy:  0.3823652160716318
Iteration: 106
    Time:  96.738
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.6493212194141239
    Accuracy:  0.3823652160716318
Iteration: 107
    Time:  83.058
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  1.4474728569462045
    Accuracy:  0.3823652160716318
Iteration: 108
    Time:  84.102
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.3993933875218987
    Accuracy:  0.383389611867815
Iteration: 109
    Time:  82.713
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.7332311911673094
    Accuracy:  0.3823652160716318
Iteration: 110
    Time:  94.487
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  1.4283002620795548
    Accuracy:  0.3823652160716318
Iteration: 111
    Time:  75.892
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  1.1431977706999412
    Accuracy:  0.42446029517775163
Iteration: 112
    Time:  79.264
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.7197975462616351
    Accuracy:  0.3887582046515157
Iteration: 113
    Time:  82.968
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  1.2789881311512887
    Accuracy:  0.4667640475016125
Iteration: 114
    Time:  82.167
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.9470221392102272
    Accuracy:  0.5524149182380392
Iteration: 115
    Time:  71.614
    Number of Data points:         336
    Number of Training batches:    11 

    Loss:  0.785052609175452
    Accuracy:  0.5640057669689267
Iteration: 116
    Time:  70.208
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  1.2285311729656265
    Accuracy:  0.5195773418826118
Iteration: 117
    Time:  97.446
    Number of Data points:         512
    Number of Training batches:    16 

    Loss:  0.6973072057944294
    Accuracy:  0.5617672724513412
Iteration: 118
    Time:  97.755
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  1.4386103061727762
    Accuracy:  0.5489623249990515
Iteration: 119
    Time:  82.18
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.024683763212766
    Accuracy:  0.4126607732291232
Iteration: 120
    Time:  101.798
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  0.9382932845115244
    Accuracy:  0.5597943620290625
Iteration: 121
    Time:  87.941
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.66743351380098
    Accuracy:  0.5643282619417992
Iteration: 122
    Time:  94.627
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.6756944011504432
    Accuracy:  0.5640626778464924
Iteration: 123
    Time:  78.007
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  1.3700020000335935
    Accuracy:  0.56413855901658
Iteration: 124
    Time:  77.951
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.6120745049618724
    Accuracy:  0.5644989945744964
Iteration: 125
    Time:  90.007
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.6480819346065122
    Accuracy:  0.5640626778464924
Iteration: 126
    Time:  89.158
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.4619578666555029
    Accuracy:  0.5641764996016239
Iteration: 127
    Time:  76.384
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  1.3312968971394268
    Accuracy:  0.5590734909132299
Iteration: 128
    Time:  81.674
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.6983544199185296
    Accuracy:  0.5646128163296278
Iteration: 129
    Time:  89.453
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.6117457987695307
    Accuracy:  0.5641195887240581
Iteration: 130
    Time:  75.539
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.6450586721658003
    Accuracy:  0.5639867966764047
Iteration: 131
    Time:  74.117
    Number of Data points:         368
    Number of Training batches:    12 

    Loss:  0.6339926113938927
    Accuracy:  0.5639867966764047
Iteration: 132
    Time:  85.956
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.4641626992376686
    Accuracy:  0.5639867966764047
Iteration: 133
    Time:  88.276
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.6024939910629045
    Accuracy:  0.5639867966764047
Iteration: 134
    Time:  93.159
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.5752720199976992
    Accuracy:  0.5639867966764047
Iteration: 135
    Time:  69.86
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  1.4901076231036685
    Accuracy:  0.5639867966764047
Iteration: 136
    Time:  84.374
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.608387159764197
    Accuracy:  0.5639867966764047
Iteration: 137
    Time:  82.306
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.496570327336117
    Accuracy:  0.5639867966764047
Iteration: 138
An Exception was thrown
Iteration: 139
    Time:  72.639
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.6045363858630038
    Accuracy:  0.5639867966764047
Iteration: 140
    Time:  93.767
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  1.5238579323615737
    Accuracy:  0.5639867966764047
Iteration: 141
    Time:  95.38
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  1.498949209152637
    Accuracy:  0.5639867966764047
Iteration: 142
    Time:  85.599
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.4554552352526298
    Accuracy:  0.5641575293091019
Iteration: 143
    Time:  67.186
    Number of Data points:         344
    Number of Training batches:    11 

    Loss:  1.3829834806430077
    Accuracy:  0.5644231134044086
Iteration: 144
    Time:  96.402
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  1.1546016541913744
    Accuracy:  0.5237508062374322
Iteration: 145
    Time:  80.596
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.8085288583296124
    Accuracy:  0.5603824410972417
Iteration: 146
    Time:  80.819
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.6579283938299976
    Accuracy:  0.5641195887240581
Iteration: 147
    Time:  108.759
    Number of Data points:         536
    Number of Training batches:    17 

    Loss:  1.4947238317005584
    Accuracy:  0.5625829950297834
Iteration: 148
    Time:  70.163
    Number of Data points:         344
    Number of Training batches:    11 

    Loss:  1.3130961110696586
    Accuracy:  0.5459081079030239
Iteration: 149
    Time:  93.171
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  1.3895853745395979
    Accuracy:  0.518913381644345
Iteration: 150
    Time:  102.465
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  0.7390178245786629
    Accuracy:  0.5625071138596958
Iteration: 151
    Time:  108.638
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.667984435222008
    Accuracy:  0.5639109155063171
Iteration: 152
    Time:  82.55
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.6120369597824269
    Accuracy:  0.5640437075539705
Iteration: 153
    Time:  76.613
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  1.4853118444555768
    Accuracy:  0.5638729749212733
Iteration: 154
    Time:  95.84
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.6165096985992319
    Accuracy:  0.5640816481390143
Iteration: 155
    Time:  71.176
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  1.488822264206072
    Accuracy:  0.5639867966764047
Iteration: 156
    Time:  85.053
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.366669170745514
    Accuracy:  0.5613309557233372
Iteration: 157
    Time:  98.899
    Number of Data points:         504
    Number of Training batches:    16 

    Loss:  1.4511881905403505
    Accuracy:  0.5551276700686725
Iteration: 158
    Time:  81.366
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.7180160341170426
    Accuracy:  0.563512539363357
Iteration: 159
    Time:  86.493
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.6363691724645022
    Accuracy:  0.5637022422885761
Iteration: 160
    Time:  97.877
    Number of Data points:         504
    Number of Training batches:    16 

    Loss:  1.3346855826150463
    Accuracy:  0.5511059680540273
Iteration: 161
    Time:  89.454
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.7115813017717303
    Accuracy:  0.5637781234586637
Iteration: 162
    Time:  76.772
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.660934746699671
    Accuracy:  0.5639488560913609
Iteration: 163
Could not find child with move:  4 2
An Exception was thrown
Iteration: 164
    Time:  80.603
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.6109380102073012
    Accuracy:  0.5641575293091019
Iteration: 165
    Time:  96.059
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  0.6042970211747245
    Accuracy:  0.5640626778464924
Iteration: 166
    Time:  81.038
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.582936118584348
    Accuracy:  0.5639867966764047
Iteration: 167
    Time:  77.159
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.5853631504794742
    Accuracy:  0.5639867966764047
Iteration: 168
    Time:  92.62
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  0.5669010894698839
    Accuracy:  0.5639867966764047
Iteration: 169
    Time:  86.155
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.5890277598935514
    Accuracy:  0.5639867966764047
Iteration: 170
    Time:  80.77
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  0.5766242314447904
    Accuracy:  0.5639867966764047
Iteration: 171
    Time:  105.591
    Number of Data points:         512
    Number of Training batches:    16 

    Loss:  0.5685176993352448
    Accuracy:  0.5639867966764047
Iteration: 172
    Time:  66.425
    Number of Data points:         336
    Number of Training batches:    11 

    Loss:  0.5730188902791443
    Accuracy:  0.5639867966764047
Iteration: 173
    Time:  97.451
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.5706534757603356
    Accuracy:  0.5639867966764047
Iteration: 174
    Time:  69.46
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  1.5178483254126325
    Accuracy:  0.5639867966764047
Iteration: 175
    Time:  101.73
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  0.5716460989204682
    Accuracy:  0.5639867966764047
Iteration: 176
    Time:  84.017
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.5316095873015634
    Accuracy:  0.5639867966764047
Iteration: 177
    Time:  72.186
    Number of Data points:         368
    Number of Training batches:    12 

    Loss:  0.5656266516962181
    Accuracy:  0.5639867966764047
Iteration: 178
    Time:  105.361
    Number of Data points:         528
    Number of Training batches:    17 

    Loss:  0.5661064278100236
    Accuracy:  0.5639867966764047
Iteration: 179
    Time:  105.556
    Number of Data points:         528
    Number of Training batches:    17 

    Loss:  1.5337020056669726
    Accuracy:  0.5639867966764047
Iteration: 180
    Time:  95.816
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  1.531588482492921
    Accuracy:  0.5639867966764047
Iteration: 181
    Time:  79.955
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  1.4860413082027313
    Accuracy:  0.5639867966764047
Iteration: 182
    Time:  81.184
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.5701836427906832
    Accuracy:  0.5639867966764047
Iteration: 183
    Time:  96.984
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  1.526088201582482
    Accuracy:  0.5639867966764047
Iteration: 184
    Time:  73.402
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  1.5068099259724734
    Accuracy:  0.5639867966764047
Iteration: 185
    Time:  92.007
    Number of Data points:         504
    Number of Training batches:    16 

    Loss:  1.5322934934847654
    Accuracy:  0.5640057669689267
Iteration: 186
    Time:  82.756
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.5757311155284713
    Accuracy:  0.5639867966764047
Iteration: 187
    Time:  80.918
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.51934979096819
    Accuracy:  0.5640437075539705
Iteration: 188
    Time:  77.8
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.6146860521290933
    Accuracy:  0.5639867966764047
Iteration: 189
    Time:  100.034
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  1.5016363445811445
    Accuracy:  0.5640247372614485
Iteration: 190
    Time:  79.614
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.501063943908759
    Accuracy:  0.5642144401866677
Iteration: 191
    Time:  90.74
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.6503455683126305
    Accuracy:  0.5639867966764047
Iteration: 192
    Time:  87.942
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  1.5195855522046342
    Accuracy:  0.5639867966764047
Iteration: 193
    Time:  83.897
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.608070293574674
    Accuracy:  0.5639867966764047
Iteration: 194
    Time:  82.909
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.521404158398013
    Accuracy:  0.5639867966764047
Iteration: 195
    Time:  96.705
    Number of Data points:         528
    Number of Training batches:    17 

    Loss:  1.486606321077188
    Accuracy:  0.5639867966764047
Iteration: 196
An Exception was thrown
Iteration: 197
    Time:  71.825
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  0.5805692393339189
    Accuracy:  0.5639867966764047
Iteration: 198
    Time:  87.462
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.5764340776623443
    Accuracy:  0.5639867966764047
Iteration: 199
    Time:  89.148
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.5925815762719896
    Accuracy:  0.5639867966764047
Iteration: 200
    Time:  85.508
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.5188405946377075
    Accuracy:  0.5639867966764047
Iteration: 201
    Time:  96.633
    Number of Data points:         520
    Number of Training batches:    17 

    Loss:  1.5200621639461716
    Accuracy:  0.5639867966764047
Iteration: 202
    Time:  84.535
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.4327418074948408
    Accuracy:  0.5640247372614485
Iteration: 203
    Time:  88.68
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  1.3997091215679756
    Accuracy:  0.5608566984102895
Iteration: 204
    Time:  70.127
    Number of Data points:         368
    Number of Training batches:    12 

    Loss:  0.669151063833199
    Accuracy:  0.5638350343362295
Iteration: 205
    Time:  94.278
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  0.6155313123805407
    Accuracy:  0.5640247372614485
Iteration: 206
    Time:  85.924
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.6088083025797358
    Accuracy:  0.5641006184315362
Iteration: 207
Could not find child with move:  2 6
An Exception was thrown
Iteration: 208
    Time:  78.615
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  1.4443944994583946
    Accuracy:  0.5640437075539705
Iteration: 209
    Time:  78.774
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  1.1707432367759707
    Accuracy:  0.5392685055203551
Iteration: 210
    Time:  85.434
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.6615027597739416
    Accuracy:  0.5534013734491786
Iteration: 211
    Time:  79.072
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.7564364803756733
    Accuracy:  0.4846340630572523
Iteration: 212
    Time:  70.535
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  0.7058800617050245
    Accuracy:  0.4251621960010623
Iteration: 213
    Time:  82.85
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  1.4633042310641855
    Accuracy:  0.4525932389877452
Iteration: 214
    Time:  97.452
    Number of Data points:         504
    Number of Training batches:    16 

    Loss:  0.6778551576984455
    Accuracy:  0.38701293773949996
Iteration: 215
    Time:  102.309
    Number of Data points:         512
    Number of Training batches:    16 

    Loss:  1.1835613899906212
    Accuracy:  0.49231703152862616
Iteration: 216
    Time:  104.463
    Number of Data points:         528
    Number of Training batches:    17 

    Loss:  0.6271818231999386
    Accuracy:  0.5274120726941609
Iteration: 217
    Time:  82.797
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.6168824869579422
    Accuracy:  0.5465720681412908
Iteration: 218
    Time:  84.561
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.5974720023892333
    Accuracy:  0.5509542057138521
Iteration: 219
    Time:  89.635
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  0.6102717340387132
    Accuracy:  0.5594339264711462
Iteration: 220
    Time:  86.928
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  1.5315698358763958
    Accuracy:  0.5591493720833175
Iteration: 221
    Time:  74.291
    Number of Data points:         368
    Number of Training batches:    12 

    Loss:  0.6358498204012167
    Accuracy:  0.5635694502409228
Iteration: 222
    Time:  86.843
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.5394736390194605
    Accuracy:  0.5636073908259666
Iteration: 223
    Time:  73.716
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  1.5248715018422732
    Accuracy:  0.5631331335129187
Iteration: 224
Could not find child with move:  2 8
An Exception was thrown
Iteration: 225
    Time:  94.605
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  1.5317996956737834
    Accuracy:  0.5627916682475244
Iteration: 226
    Time:  80.633
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.5306739916106926
    Accuracy:  0.5624881435671738
Iteration: 227
    Time:  94.958
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  1.5190654928446021
    Accuracy:  0.5613499260158592
Iteration: 228
    Time:  85.377
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.4985522002472271
    Accuracy:  0.5590734909132299
Iteration: 229
    Time:  64.812
    Number of Data points:         360
    Number of Training batches:    12 

    Loss:  1.4755145687237257
    Accuracy:  0.5575179269264332
Iteration: 230
    Time:  84.318
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.1454279056646663
    Accuracy:  0.5069051864779754
Iteration: 231
    Time:  92.612
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.6687719214588383
    Accuracy:  0.5461926622908525
Iteration: 232
    Time:  88.485
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.6360628073396485
    Accuracy:  0.5551276700686725
Iteration: 233
    Time:  70.007
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  1.4760249380621053
    Accuracy:  0.5509352354213302
Iteration: 234
    Time:  71.742
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  1.4685500251637054
    Accuracy:  0.5411086238949805
Iteration: 235
    Time:  75.489
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.5968143010544058
    Accuracy:  0.5493227605569678
Iteration: 236
    Time:  73.134
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  1.4594273548695629
    Accuracy:  0.5368592783700724
Iteration: 237
    Time:  78.345
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.9079556006556951
    Accuracy:  0.4404901923587662
Iteration: 238
    Time:  79.448
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.7605743596460146
    Accuracy:  0.3828963842622453
Iteration: 239
    Time:  81.71
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  0.5788187536863122
    Accuracy:  0.38268771104450433
Iteration: 240
    Time:  80.838
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.4747714861908168
    Accuracy:  0.3843191562013886
Iteration: 241
    Time:  88.972
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.5784365582751523
    Accuracy:  0.3834085821603369
Iteration: 242
    Time:  93.364
    Number of Data points:         528
    Number of Training batches:    17 

    Loss:  1.5321697352641468
    Accuracy:  0.38382592859581893
Iteration: 243
    Time:  72.044
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.2623361099605808
    Accuracy:  0.42432750313009826
Iteration: 244
    Time:  73.121
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.7081640191859607
    Accuracy:  0.3908069962438821
Iteration: 245
    Time:  94.528
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  0.9175973272593462
    Accuracy:  0.4892059035550328
Iteration: 246
    Time:  81.049
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.76805044888087
    Accuracy:  0.40799408126873316
Iteration: 247
    Time:  89.334
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.9821789403164758
    Accuracy:  0.4857912509010889
Iteration: 248
    Time:  93.348
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  1.4501659707418457
    Accuracy:  0.47245513525818567
Iteration: 249
An Exception was thrown
Iteration: 250
    Time:  75.575
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.9984953507388463
    Accuracy:  0.3954736882042721
Iteration: 251
    Time:  84.485
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.6156311665698554
    Accuracy:  0.3887582046515157
Iteration: 252
    Time:  81.422
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  1.412763845224819
    Accuracy:  0.4128125355692985
Iteration: 253
    Time:  82.587
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.6638988418877733
    Accuracy:  0.3957772128846227
Iteration: 254
    Time:  67.323
    Number of Data points:         352
    Number of Training batches:    11 

    Loss:  1.0455712713684606
    Accuracy:  0.43671510414690595
Iteration: 255
    Time:  68.97
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  0.7440622517670774
    Accuracy:  0.4082976059490837
Iteration: 256
    Time:  86.14
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  1.3170351822637716
    Accuracy:  0.4503926850552036
Iteration: 257
    Time:  88.321
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.9986247042634756
    Accuracy:  0.5349812194104033
Iteration: 258
    Time:  66.441
    Number of Data points:         368
    Number of Training batches:    12 

    Loss:  0.6070999430091982
    Accuracy:  0.5419243464734226
Iteration: 259
    Time:  87.006
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.232758651227747
    Accuracy:  0.5004173464354821
Iteration: 260
    Time:  88.651
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.7055796996452371
    Accuracy:  0.5315286261714156
Iteration: 261
    Time:  103.456
    Number of Data points:         512
    Number of Training batches:    16 

    Loss:  1.5171494570484776
    Accuracy:  0.5268998747960694
Iteration: 262
    Time:  87.165
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.8231536484515256
    Accuracy:  0.4404332814812004
Iteration: 263
    Time:  76.161
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.9384554406844945
    Accuracy:  0.5225746481010737
Iteration: 264
    Time:  87.559
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.810105008021905
    Accuracy:  0.4404712220662443
Iteration: 265
    Time:  85.222
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.8245437122163288
    Accuracy:  0.5051978601510035
Iteration: 266
Could not find child with move:  8 3
An Exception was thrown
Iteration: 267
    Time:  89.722
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.672625421617985
    Accuracy:  0.477273589558751
Iteration: 268
    Time:  89.473
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.7347214188187089
    Accuracy:  0.5487726220738324
Iteration: 269
    Time:  88.483
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.4317930516832527
    Accuracy:  0.5314527450013279
Iteration: 270
    Time:  95.857
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  1.1722771476853555
    Accuracy:  0.4459156960200326
Iteration: 271
    Time:  86.856
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  0.7108079448967572
    Accuracy:  0.4171187919717722
Iteration: 272
    Time:  93.296
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  1.373242531354196
    Accuracy:  0.45221383313730695
Iteration: 273
    Time:  93.869
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.0375177496218895
    Accuracy:  0.5319459726068976
Iteration: 274
    Time:  78.537
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  1.480945039225808
    Accuracy:  0.5242819744280457
Iteration: 275
    Time:  85.554
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.8768409417616916
    Accuracy:  0.4697613537200744
Iteration: 276
    Time:  61.855
    Number of Data points:         328
    Number of Training batches:    11 

    Loss:  0.9310714545464212
    Accuracy:  0.4300944720567591
Iteration: 277
    Time:  103.117
    Number of Data points:         528
    Number of Training batches:    17 

    Loss:  1.456641871186974
    Accuracy:  0.449026823993626
Iteration: 278
    Time:  88.939
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.6419593036818206
    Accuracy:  0.42884243275031303
Iteration: 279
    Time:  86.953
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  1.2753791245062713
    Accuracy:  0.4826421823424517
Iteration: 280
    Time:  77.159
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.0870928279783665
    Accuracy:  0.5281898546875593
Iteration: 281
    Time:  101.117
    Number of Data points:         512
    Number of Training batches:    16 

    Loss:  1.3920090513659453
    Accuracy:  0.5303904086201009
Iteration: 282
    Time:  84.7
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.6722295450589622
    Accuracy:  0.551618165952119
Iteration: 283
    Time:  93.716
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.61219343527484
    Accuracy:  0.5554122244565011
Iteration: 284
    Time:  93.834
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  1.5040276524301377
    Accuracy:  0.5527943240884774
Iteration: 285
    Time:  100.048
    Number of Data points:         520
    Number of Training batches:    17 

    Loss:  1.412509657273846
    Accuracy:  0.5423986037864704
Iteration: 286
    Time:  96.427
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  1.4246989293373882
    Accuracy:  0.5309974579808021
Iteration: 287
    Time:  91.173
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.989958388978457
    Accuracy:  0.4727017490609705
Iteration: 288
    Time:  88.663
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.897866845686059
    Accuracy:  0.4121675456235535
Iteration: 289
    Time:  87.412
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.1756864278891404
    Accuracy:  0.44610539894525175
Iteration: 290
    Time:  103.613
    Number of Data points:         504
    Number of Training batches:    16 

    Loss:  0.7335268996308756
    Accuracy:  0.4174981978222104
Iteration: 291
    Time:  98.767
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  1.3078668790433572
    Accuracy:  0.45126531851121143
Iteration: 292
    Time:  68.624
    Number of Data points:         352
    Number of Training batches:    11 

    Loss:  1.1209464334248844
    Accuracy:  0.4865690328944872
Iteration: 293
    Time:  68.409
    Number of Data points:         360
    Number of Training batches:    12 

    Loss:  0.8130476427500275
    Accuracy:  0.45221383313730695
Iteration: 294
    Time:  74.797
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.0779486501005684
    Accuracy:  0.5061084341920552
Iteration: 295
    Time:  90.245
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.9494828715575206
    Accuracy:  0.4331297188602648
Iteration: 296
    Time:  88.983
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.9697270927929142
    Accuracy:  0.5073984140835451
Iteration: 297
    Time:  87.613
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.8640562760654412
    Accuracy:  0.5494176120195774
Iteration: 298
    Time:  86.26
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.6545223396622435
    Accuracy:  0.557764540729218
Iteration: 299
    Time:  83.144
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  1.3576537687324917
    Accuracy:  0.5397807034184468
Iteration: 300
    Time:  94.215
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  0.7086303941415973
    Accuracy:  0.5589406988655765
Iteration: 301
    Time:  98.391
    Number of Data points:         520
    Number of Training batches:    17 

    Loss:  1.4429763792635455
    Accuracy:  0.5529650567211747
Iteration: 302
    Time:  65.407
    Number of Data points:         336
    Number of Training batches:    11 

    Loss:  0.6928158315385424
    Accuracy:  0.5580870357020905
Iteration: 303
    Time:  82.388
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  1.346016150960278
    Accuracy:  0.546723830481466
Iteration: 304
    Time:  96.003
    Number of Data points:         512
    Number of Training batches:    16 

    Loss:  1.3976005192072205
    Accuracy:  0.5353226846757977
Iteration: 305
    Time:  78.171
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.7769139166107243
    Accuracy:  0.5559623629396365
Iteration: 306
    Time:  80.384
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.9824403400202222
    Accuracy:  0.5102439579618318
Iteration: 307
Could not find child with move:  5 1
An Exception was thrown
Iteration: 308
    Time:  91.603
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  0.7321386785840306
    Accuracy:  0.47040634366581935
Iteration: 309
    Time:  113.247
    Number of Data points:         552
    Number of Training batches:    18 

    Loss:  1.4515858398163963
    Accuracy:  0.48582919148613274
Iteration: 310
    Time:  83.779
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.6708488823207212
    Accuracy:  0.5105854232272261
Iteration: 311
    Time:  82.7
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.6827916420668655
    Accuracy:  0.48945251735781764
Iteration: 312
    Time:  91.184
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.8718731701223421
    Accuracy:  0.4080509921462989
Iteration: 313
An Exception was thrown
Iteration: 314
    Time:  88.118
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  1.4749938807596437
    Accuracy:  0.4176689304549076
Iteration: 315
    Time:  89.4
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.7638677011917139
    Accuracy:  0.4831543802405433
Iteration: 316
    Time:  96.199
    Number of Data points:         512
    Number of Training batches:    16 

    Loss:  1.419569615550335
    Accuracy:  0.47503509504116553
Iteration: 317
    Time:  93.448
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  0.8510217039838046
    Accuracy:  0.5344690215123117
Iteration: 318
    Time:  82.23
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.430881325459491
    Accuracy:  0.5228022916113366
Iteration: 319
    Time:  82.617
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.1814979451498764
    Accuracy:  0.47057707629851653
Iteration: 320
    Time:  92.969
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.7054246558431596
    Accuracy:  0.4315551845809462
Iteration: 321
    Time:  93.954
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  0.7188528689231843
    Accuracy:  0.4011837462533672
Iteration: 322
    Time:  98.173
    Number of Data points:         504
    Number of Training batches:    16 

    Loss:  0.587692513490362
    Accuracy:  0.3957582425921008
Iteration: 323
    Time:  85.141
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.6493209992910648
    Accuracy:  0.38684220510680273
Iteration: 324
    Time:  100.63
    Number of Data points:         504
    Number of Training batches:    16 

    Loss:  1.4531277073052258
    Accuracy:  0.39602382668740754
Iteration: 325
    Time:  89.333
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.6626978391310779
    Accuracy:  0.3860264825283606
Iteration: 326
    Time:  86.049
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.5747721630957934
    Accuracy:  0.3853435519975718
Iteration: 327
    Time:  77.784
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  1.5250061686226029
    Accuracy:  0.38595060135827297
Iteration: 328
    Time:  78.701
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.2653279742687487
    Accuracy:  0.42182342451720606
Iteration: 329
    Time:  101.266
    Number of Data points:         512
    Number of Training batches:    16 

    Loss:  1.4561192286275793
    Accuracy:  0.4334901544181811
Iteration: 330
    Time:  77.626
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.212492652444207
    Accuracy:  0.48780210190841145
Iteration: 331
    Time:  86.046
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  1.1157138074406718
    Accuracy:  0.5221383313730698
Iteration: 332
    Time:  92.156
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.7058784135486482
    Accuracy:  0.5512577303942027
Iteration: 333
    Time:  98.228
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  0.6271288774553618
    Accuracy:  0.5593390750085366
Iteration: 334
    Time:  88.77
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.5899782041615096
    Accuracy:  0.5613309557233372
Iteration: 335
    Time:  94.87
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.9395168704122234
    Accuracy:  0.522954053951512
Iteration: 336
    Time:  74.979
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.8865320671855786
    Accuracy:  0.4728724816936677
Iteration: 337
    Time:  94.973
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.8094503349827871
    Accuracy:  0.5257995978297986
Iteration: 338
    Time:  66.233
    Number of Data points:         368
    Number of Training batches:    12 

    Loss:  0.8425219181207076
    Accuracy:  0.5456045832226732
Iteration: 339
    Time:  84.003
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.0612338214827743
    Accuracy:  0.5083848692946845
Iteration: 340
    Time:  100.531
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.7126888212964965
    Accuracy:  0.48093485601547975
Iteration: 341
    Time:  84.92
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.658837112557337
    Accuracy:  0.42925977918579505
Iteration: 342
    Time:  83.353
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.4115974030900498
    Accuracy:  0.4573927229957886
Iteration: 343
    Time:  93.416
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.5852253966208195
    Accuracy:  0.44665553742838715
Iteration: 344
    Time:  81.362
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.0973851591910746
    Accuracy:  0.5035284744090753
Iteration: 345
    Time:  99.457
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  0.7088843289879869
    Accuracy:  0.5294229237014835
Iteration: 346
    Time:  81.471
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.7319319663146212
    Accuracy:  0.5048184543005653
Iteration: 347
    Time:  94.722
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.8340646353956279
    Accuracy:  0.4717342641423531
Iteration: 348
    Time:  88.498
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.6409494171884973
    Accuracy:  0.43034108585954395
Iteration: 349
    Time:  89.828
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.9464180953080958
    Accuracy:  0.4966612285161437
Iteration: 350
    Time:  81.838
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.956322018067206
    Accuracy:  0.5267101718708502
Iteration: 351
    Time:  71.693
    Number of Data points:         368
    Number of Training batches:    12 

    Loss:  0.8361794134443884
    Accuracy:  0.5464772166786812
Iteration: 352
    Time:  106.636
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  1.5276209636978757
    Accuracy:  0.5440490192358766
Iteration: 353
    Time:  86.631
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.5700989075634048
    Accuracy:  0.545889137610502
Iteration: 354
    Time:  67.145
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  0.5867787085753456
    Accuracy:  0.5472739689646015
Iteration: 355
    Time:  80.011
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.5193421362893385
    Accuracy:  0.5448837121068407
Iteration: 356
    Time:  86.002
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  1.4448010448793644
    Accuracy:  0.542057138521076
Iteration: 357
    Time:  66.873
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  0.6620606561567867
    Accuracy:  0.5496452555298402
Iteration: 358
    Time:  86.762
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  1.5233014778931626
    Accuracy:  0.5485829191486132
Iteration: 359
    Time:  108.595
    Number of Data points:         544
    Number of Training batches:    17 

    Loss:  1.5468799837119476
    Accuracy:  0.5482224835906969
Iteration: 360
    Time:  114.784
    Number of Data points:         544
    Number of Training batches:    17 

    Loss:  0.5866550424724801
    Accuracy:  0.5548051750958
Iteration: 361
    Time:  97.564
    Number of Data points:         504
    Number of Training batches:    16 

    Loss:  1.5134548292383128
    Accuracy:  0.5512008195166369
Iteration: 362
    Time:  86.13
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  1.4094008476815805
    Accuracy:  0.5422847820313389
Iteration: 363
    Time:  88.946
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.5750180195132707
    Accuracy:  0.544390484501271
Iteration: 364
    Time:  86.056
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  1.1237032300605185
    Accuracy:  0.5199188071480062
Iteration: 365
    Time:  97.398
    Number of Data points:         504
    Number of Training batches:    16 

    Loss:  0.7287500562781338
    Accuracy:  0.485980953826308
Iteration: 366
    Time:  73.82
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  0.5906968125349888
    Accuracy:  0.4835527563835034
Iteration: 367
    Time:  64.792
    Number of Data points:         352
    Number of Training batches:    11 

    Loss:  0.6359616965892733
    Accuracy:  0.4904579428614789
Iteration: 368
    Time:  92.48
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  1.4912831969871645
    Accuracy:  0.4930189323519369
Iteration: 369
    Time:  85.832
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.6557046301251275
    Accuracy:  0.48395113252646355
Iteration: 370
    Time:  89.997
    Number of Data points:         528
    Number of Training batches:    17 

    Loss:  1.408967303003051
    Accuracy:  0.49480213984899646
Iteration: 371
    Time:  77.048
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.8844749066832157
    Accuracy:  0.5262169442652805
Iteration: 372
    Time:  85.037
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.8140109638840597
    Accuracy:  0.547596463937474
Iteration: 373
    Time:  73.646
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  1.4831852265112222
    Accuracy:  0.5426072770042114
Iteration: 374
    Time:  72.01
    Number of Data points:         352
    Number of Training batches:    11 

    Loss:  0.574233631024956
    Accuracy:  0.5435747619228288
Iteration: 375
    Time:  101.131
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  1.5128252872911
    Accuracy:  0.5406912774594984
Iteration: 376
    Time:  92.007
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.5898594260520571
    Accuracy:  0.5445612171339682
Iteration: 377
    Time:  97.221
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  0.565761870913654
    Accuracy:  0.5465530978487688
Iteration: 378
    Time:  83.646
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.5637174437038942
    Accuracy:  0.5473119095496453
Iteration: 379
    Time:  73.738
    Number of Data points:         352
    Number of Training batches:    11 

    Loss:  0.584024336900486
    Accuracy:  0.5487726220738324
Iteration: 380
Could not find child with move:  2 7
An Exception was thrown
Iteration: 381
    Time:  97.874
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  0.5600793556184113
    Accuracy:  0.5490761467541829
Iteration: 382
    Time:  84.441
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.5863883085620234
    Accuracy:  0.5519975718025572
Iteration: 383
    Time:  70.211
    Number of Data points:         368
    Number of Training batches:    12 

    Loss:  0.5578077959772357
    Accuracy:  0.5525287399931706
Iteration: 384
    Time:  69.508
    Number of Data points:         368
    Number of Training batches:    12 

    Loss:  0.6042966726652692
    Accuracy:  0.5571954319535607
Iteration: 385
    Time:  107.785
    Number of Data points:         520
    Number of Training batches:    17 

    Loss:  1.5462023612004907
    Accuracy:  0.5571195507834731
Iteration: 386
    Time:  87.664
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.2140452602939331
    Accuracy:  0.5344879918048336
Iteration: 387
Could not find child with move:  6 3
An Exception was thrown
Iteration: 388
    Time:  68.559
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  0.9399976535630964
    Accuracy:  0.5134499373980347
Iteration: 389
    Time:  84.719
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.0970293535636126
    Accuracy:  0.5358538528664112
Iteration: 390
    Time:  71.797
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  1.5286444298494417
    Accuracy:  0.5337102098114352
Iteration: 391
    Time:  95.069
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  1.4788846052322946
    Accuracy:  0.5287779337557386
Iteration: 392
    Time:  104.966
    Number of Data points:         512
    Number of Training batches:    16 

    Loss:  0.7346859521850948
    Accuracy:  0.5445801874264902
Iteration: 393
    Time:  93.523
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.5697536083992968
    Accuracy:  0.5465341275562469
Iteration: 394
    Time:  91.563
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  0.5745177831440944
    Accuracy:  0.5485449785635694
Iteration: 395
    Time:  104.492
    Number of Data points:         504
    Number of Training batches:    16 

    Loss:  1.5401474024633126
    Accuracy:  0.547596463937474
Iteration: 396
    Time:  90.932
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.1773774481770747
    Accuracy:  0.5301437948173161
Iteration: 397
    Time:  104.574
    Number of Data points:         536
    Number of Training batches:    17 

    Loss:  1.4702003210995966
    Accuracy:  0.530371438327579
Iteration: 398
    Time:  90.468
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.2169592515099052
    Accuracy:  0.5064309291649277
Iteration: 399
    Time:  83.456
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.6428044561280977
    Accuracy:  0.5184580946238191
Iteration: 400
    Time:  88.158
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.7546014149437191
    Accuracy:  0.5324392002124673
Iteration: 401
    Time:  99.059
    Number of Data points:         520
    Number of Training batches:    17 

    Loss:  1.4403436100375593
    Accuracy:  0.5301058542322723
Iteration: 402
    Time:  95.409
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  1.5315941555336159
    Accuracy:  0.5274500132792047
Iteration: 403
    Time:  83.876
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.6291609999390999
    Accuracy:  0.5338430018590886
Iteration: 404
    Time:  101.115
    Number of Data points:         528
    Number of Training batches:    17 

    Loss:  1.4613609171142359
    Accuracy:  0.5315475964639375
Iteration: 405
    Time:  95.849
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  0.6125945713547055
    Accuracy:  0.5364419319345904
Iteration: 406
    Time:  88.752
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  1.4909793839251562
    Accuracy:  0.5325150813825549
Iteration: 407
    Time:  72.548
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.9250064102273772
    Accuracy:  0.5511628789315931
Iteration: 408
    Time:  86.065
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.8706006251173292
    Accuracy:  0.5260082710475396
Iteration: 409
    Time:  91.004
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.5840914682345186
    Accuracy:  0.5281329438099935
Iteration: 410
    Time:  82.022
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.8059005616736479
    Accuracy:  0.5475395530599082
Iteration: 411
    Time:  96.118
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  0.5680647534187219
    Accuracy:  0.5507834730811549
Iteration: 412
    Time:  76.595
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.6240070577514409
    Accuracy:  0.555658838259286
Iteration: 413
    Time:  69.728
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  1.4045276097913997
    Accuracy:  0.5477671965701711
Iteration: 414
    Time:  83.719
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.266465340439579
    Accuracy:  0.5377698524111242
Iteration: 415
    Time:  92.095
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.1898588853512402
    Accuracy:  0.515935045718405
Iteration: 416
    Time:  79.952
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.6146602553321387
    Accuracy:  0.5227833213188148
Iteration: 417
    Time:  92.761
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.6257649636682513
    Accuracy:  0.5328565466479493
Iteration: 418
    Time:  89.488
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.5754058482933824
    Accuracy:  0.5344500512197898
Iteration: 419
    Time:  86.568
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  1.4362227870892597
    Accuracy:  0.5222331828356793
Iteration: 420
Could not find child with move:  4 3
An Exception was thrown
Iteration: 421
    Time:  109.247
    Number of Data points:         544
    Number of Training batches:    17 

    Loss:  1.4144466618221123
    Accuracy:  0.5230109648290777
Iteration: 422
    Time:  91.334
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.8176527906281996
    Accuracy:  0.47651477785787455
Iteration: 423
    Time:  84.351
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.5858900933766452
    Accuracy:  0.47292939257123345
Iteration: 424
    Time:  72.71
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  0.6658494461961035
    Accuracy:  0.4557992184239481
Iteration: 425
    Time:  87.057
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  1.3900357886675332
    Accuracy:  0.4779754903820617
Iteration: 426
    Time:  79.939
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.9764509130819706
    Accuracy:  0.43441969875175473
Iteration: 427
    Time:  91.306
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.0908703632555106
    Accuracy:  0.4841977463292484
Iteration: 428
    Time:  97.507
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  1.490988788950468
    Accuracy:  0.4884660621466783
Iteration: 429
    Time:  83.293
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.1110408999724042
    Accuracy:  0.514853739044656
Iteration: 430
    Time:  88.57
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  1.0703509566581026
    Accuracy:  0.48053647987251963
Iteration: 431
    Time:  93.342
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.950082368577885
    Accuracy:  0.5124824524794173
Iteration: 432
    Time:  92.468
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.048022601950877
    Accuracy:  0.4827370338050613
Iteration: 433
Could not find child with move:  8 4
An Exception was thrown
Iteration: 434
    Time:  111.851
    Number of Data points:         536
    Number of Training batches:    17 

    Loss:  1.3881718167330366
    Accuracy:  0.47793754979701786
Iteration: 435
    Time:  89.894
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.0979939468579565
    Accuracy:  0.5085366316348598
Iteration: 436
    Time:  94.016
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.923735761454661
    Accuracy:  0.4678074135903176
Iteration: 437
    Time:  92.431
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.6830574026671539
    Accuracy:  0.44684524035360623
Iteration: 438
    Time:  92.577
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  1.2943950357997671
    Accuracy:  0.4801570740220814
Iteration: 439
    Time:  76.076
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.9836084150190094
    Accuracy:  0.5088022157301666
Iteration: 440
    Time:  85.191
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  1.064862562195999
    Accuracy:  0.46955268050233334
Iteration: 441
    Time:  67.163
    Number of Data points:         336
    Number of Training batches:    11 

    Loss:  0.7924573042020682
    Accuracy:  0.4980270895777213
Iteration: 442
    Time:  89.521
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  0.8678346486666126
    Accuracy:  0.5236749250673446
Iteration: 443
    Time:  90.319
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.6377341800092281
    Accuracy:  0.530807755055583
Iteration: 444
    Time:  78.864
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.6219058020551451
    Accuracy:  0.5368023674925068
Iteration: 445
    Time:  82.033
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.6144763568336218
    Accuracy:  0.5402739310240164
Iteration: 446
    Time:  103.504
    Number of Data points:         512
    Number of Training batches:    16 

    Loss:  0.6098134579003851
    Accuracy:  0.5485639488560914
Iteration: 447
    Time:  88.436
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.6207295444251569
    Accuracy:  0.5549569374359753
Iteration: 448
    Time:  90.52
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.5812298082608062
    Accuracy:  0.559452896763668
Iteration: 449
    Time:  97.034
    Number of Data points:         504
    Number of Training batches:    16 

    Loss:  1.5038921105847876
    Accuracy:  0.5560192738172023
Iteration: 450
    Time:  86.275
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.4723406052916046
    Accuracy:  0.550764502788633
Iteration: 451
    Time:  80.763
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  1.5186354262047899
    Accuracy:  0.5488864438289638
Iteration: 452
    Time:  95.015
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  1.4234776167647902
    Accuracy:  0.5396289410782714
Iteration: 453
    Time:  87.654
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.6224784825990268
    Accuracy:  0.5472549986720795
Iteration: 454
    Time:  74.008
    Number of Data points:         368
    Number of Training batches:    12 

    Loss:  0.6888311196172432
    Accuracy:  0.5580301248245247
Iteration: 455
    Time:  101.45
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  1.5277752143841654
    Accuracy:  0.5559623629396365
Iteration: 456
    Time:  94.001
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  0.5995530352135482
    Accuracy:  0.5592252532534052
Iteration: 457
    Time:  87.798
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.469959786821177
    Accuracy:  0.5538566604697045
Iteration: 458
    Time:  95.69
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.6399007198299109
    Accuracy:  0.5618810942064727
Iteration: 459
    Time:  76.346
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.5837887306819254
    Accuracy:  0.5627726979550025
Iteration: 460
    Time:  81.102
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  1.5056898288396463
    Accuracy:  0.5618241833289069
Iteration: 461
    Time:  76.438
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  0.5594976616281012
    Accuracy:  0.5619949159616041
Iteration: 462
    Time:  90.245
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.5744516875206108
    Accuracy:  0.5626019653223052
Iteration: 463
    Time:  89.243
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.5780201845202312
    Accuracy:  0.5628865197101339
Iteration: 464
    Time:  66.031
    Number of Data points:         368
    Number of Training batches:    12 

    Loss:  0.5534757691956148
    Accuracy:  0.562867549417612
Iteration: 465
    Time:  83.391
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  1.2268465463125282
    Accuracy:  0.5451492962021475
Iteration: 466
    Time:  90.957
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.4620749897720893
    Accuracy:  0.5383579314793034
Iteration: 467
    Time:  81.225
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  1.210460591550411
    Accuracy:  0.5171301741472853
Iteration: 468
An Exception was thrown
Iteration: 469
    Time:  94.187
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.9349222678825299
    Accuracy:  0.4758128770345639
Iteration: 470
    Time:  84.063
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  1.0353631078948062
    Accuracy:  0.5234662518496035
Iteration: 471
    Time:  87.43
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.7740883790855524
    Accuracy:  0.5424365443715142
Iteration: 472
    Time:  83.759
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.6405295721191678
    Accuracy:  0.5574041051713018
Iteration: 473
    Time:  94.114
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  1.5286814966333027
    Accuracy:  0.5554691353340668
Iteration: 474
    Time:  80.278
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.7200692917606192
    Accuracy:  0.5636263611184884
Iteration: 475
    Time:  81.37
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.535990659844937
    Accuracy:  0.563531509655879
Iteration: 476
    Time:  87.121
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.2008245895373655
    Accuracy:  0.5484880676860037
Iteration: 477
    Time:  92.626
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.5922429420850757
    Accuracy:  0.5529460864286527
Iteration: 478
    Time:  98.102
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  1.4442545091581682
    Accuracy:  0.5461357514132867
Iteration: 479
    Time:  98.223
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  0.7351253207304164
    Accuracy:  0.5626399059073491
Iteration: 480
    Time:  87.676
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.3961720873694152
    Accuracy:  0.5592062829608833
Iteration: 481
    Time:  98.781
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  0.5721753525486133
    Accuracy:  0.5598512729066282
Iteration: 482
    Time:  79.65
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  0.6081137032479663
    Accuracy:  0.561387866600903
Iteration: 483
    Time:  95.425
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  1.5043673939835007
    Accuracy:  0.5600030352468035
Iteration: 484
    Time:  81.078
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.5829415312330699
    Accuracy:  0.5600030352468035
Iteration: 485
    Time:  88.202
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.203039645105991
    Accuracy:  0.5409378912622833
Iteration: 486
    Time:  98.528
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.5893797138212566
    Accuracy:  0.543764464848048
Iteration: 487
    Time:  78.962
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.2198585454673125
    Accuracy:  0.5198808665629624
Iteration: 488
    Time:  91.95
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.7515017009377684
    Accuracy:  0.4837045187236787
Iteration: 489
    Time:  83.973
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.5899853447937485
    Accuracy:  0.4762302234700459
Iteration: 490
    Time:  68.314
    Number of Data points:         360
    Number of Training batches:    12 

    Loss:  1.1963358321102462
    Accuracy:  0.4210646128163296
Iteration: 491
    Time:  88.169
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.6226386443095563
    Accuracy:  0.40554691353340666
Iteration: 492
    Time:  82.126
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  1.1897383550097396
    Accuracy:  0.43872595515422846
Iteration: 493
    Time:  100.575
    Number of Data points:         528
    Number of Training batches:    17 

    Loss:  1.4616350002194396
    Accuracy:  0.45750654475092006
Iteration: 494
    Time:  76.366
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  0.6129106461321523
    Accuracy:  0.44919755662632316
Iteration: 495
    Time:  101.315
    Number of Data points:         528
    Number of Training batches:    17 

    Loss:  1.4354572156552035
    Accuracy:  0.46564480024281973
Iteration: 496
Could not find child with move:  0 2
An Exception was thrown
Iteration: 497
    Time:  95.664
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  0.6437957989717296
    Accuracy:  0.4302462343969344
Iteration: 498
    Time:  97.215
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  0.8924214101767709
    Accuracy:  0.507872671396593
Iteration: 499
Could not find child with move:  2 1
An Exception was thrown
Iteration: 500
    Time:  81.14
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.7985388534719237
    Accuracy:  0.5311681906134993
Iteration: 501
    Time:  78.233
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  1.4653414077476963
    Accuracy:  0.519539401297568
Iteration: 502
    Time:  106.307
    Number of Data points:         504
    Number of Training batches:    16 

    Loss:  1.1343665470569977
    Accuracy:  0.4712789771218272
Iteration: 503
    Time:  98.786
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  0.7021268663635978
    Accuracy:  0.5144933034867397
Iteration: 504
    Time:  82.041
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.7944441583101342
    Accuracy:  0.4856584588534355
Iteration: 505
    Time:  81.015
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.0244172199526385
    Accuracy:  0.42872861099518156
Iteration: 506
    Time:  84.782
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.696044361081998
    Accuracy:  0.46105398945251735
Iteration: 507
    Time:  94.144
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.6005226633897862
    Accuracy:  0.45025989300755015
Iteration: 508
    Time:  87.24
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.2303739368800557
    Accuracy:  0.49869104981598816
Iteration: 509
    Time:  97.4
    Number of Data points:         536
    Number of Training batches:    17 

    Loss:  1.4783020335646044
    Accuracy:  0.5034336229464659
Iteration: 510
    Time:  90.474
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.8470701246440051
    Accuracy:  0.5375422089008612
Iteration: 511
    Time:  94.723
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.888608102447219
    Accuracy:  0.4959024168152673
Iteration: 512
    Time:  89.332
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.8621019271195304
    Accuracy:  0.5241112417953485
Iteration: 513
    Time:  100.009
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  0.8669704618054317
    Accuracy:  0.5502523048905414
Iteration: 514
    Time:  95.512
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  1.4301711852086778
    Accuracy:  0.5447129794741435
Iteration: 515
    Time:  73.03
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  1.3951213699952814
    Accuracy:  0.5383010206017377
Iteration: 516
    Time:  103.224
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  0.6265420538097981
    Accuracy:  0.5430056531471715
Iteration: 517
    Time:  84.627
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  1.4404461310082877
    Accuracy:  0.5428918313920401
Iteration: 518
    Time:  84.593
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.7529409331211477
    Accuracy:  0.5539325416397921
Iteration: 519
    Time:  69.023
    Number of Data points:         368
    Number of Training batches:    12 

    Loss:  0.5598511338654252
    Accuracy:  0.554368858367796
Iteration: 520
    Time:  88.422
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  1.4479846760205257
    Accuracy:  0.5480327806654779
Iteration: 521
    Time:  82.34
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.5309545424993733
    Accuracy:  0.5473498501346891
Iteration: 522
    Time:  74.237
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.361639042296193
    Accuracy:  0.5389080699624388
Iteration: 523
    Time:  89.718
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.7340346034457843
    Accuracy:  0.546742800773988
Iteration: 524
    Time:  88.056
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  1.438227301196102
    Accuracy:  0.541848465303335
Iteration: 525
    Time:  86.959
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.3451524327658533
    Accuracy:  0.5265204689456311
Iteration: 526
    Time:  90.789
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.6512290560540425
    Accuracy:  0.5338999127366544
Iteration: 527
    Time:  90.981
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.6978409845828427
    Accuracy:  0.543328148120044
Iteration: 528
    Time:  101.924
    Number of Data points:         512
    Number of Training batches:    16 

    Loss:  0.6940862104661286
    Accuracy:  0.5553742838714573
Iteration: 529
    Time:  86.312
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.5797703512900814
    Accuracy:  0.5570816101984293
Iteration: 530
    Time:  89.517
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.5829259520650288
    Accuracy:  0.5585043821375726
Iteration: 531
An Exception was thrown
Iteration: 532
    Time:  81.257
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  1.4765178988006935
    Accuracy:  0.5553553135789354
Iteration: 533
    Time:  75.631
    Number of Data points:         368
    Number of Training batches:    12 

    Loss:  0.6321574791049841
    Accuracy:  0.5583715900899192
Iteration: 534
    Time:  93.47
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.5762358874273112
    Accuracy:  0.5593959858861024
Iteration: 535
    Time:  94.553
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.5961092352927341
    Accuracy:  0.5611412527981181
Iteration: 536
    Time:  98.533
    Number of Data points:         512
    Number of Training batches:    16 

    Loss:  1.5314874779303174
    Accuracy:  0.560553173729939
Iteration: 537
    Time:  73.323
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  1.1219979257255348
    Accuracy:  0.5427400690518648
Iteration: 538
    Time:  96.243
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.6194150587985939
    Accuracy:  0.5466669196039003
Iteration: 539
    Time:  80.949
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.6000666461251171
    Accuracy:  0.5499677505027127
Iteration: 540
Could not find child with move:  4 1
An Exception was thrown
Iteration: 541
    Time:  68.647
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  1.4737358982905124
    Accuracy:  0.5475205827673862
Iteration: 542
    Time:  76.962
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.5609505537544621
    Accuracy:  0.5476723451075616
Iteration: 543
    Time:  83.336
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.629860219888645
    Accuracy:  0.5520734529726449
Iteration: 544
    Time:  89.456
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.5584854678534187
    Accuracy:  0.5525666805782146
Iteration: 545
    Time:  86.198
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.554980021219752
    Accuracy:  0.5525287399931706
Iteration: 546
    Time:  84.672
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  1.5252534893609426
    Accuracy:  0.5507075919110672
Iteration: 547
    Time:  80.262
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  1.5264242428626578
    Accuracy:  0.5501764237204537
Iteration: 548
    Time:  97.477
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.5770444364034774
    Accuracy:  0.5517130174147286
Iteration: 549
    Time:  98.68
    Number of Data points:         504
    Number of Training batches:    16 

    Loss:  1.4799916786824987
    Accuracy:  0.5476913154000834
Iteration: 550
    Time:  67.202
    Number of Data points:         360
    Number of Training batches:    12 

    Loss:  1.403709523482035
    Accuracy:  0.5450354744470159
Iteration: 551
    Time:  89.57
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.6040136582013192
    Accuracy:  0.5468945631141632
Iteration: 552
    Time:  75.084
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.5956452566261095
    Accuracy:  0.5495124634821869
Iteration: 553
    Time:  74.681
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  1.5169512094537363
    Accuracy:  0.5479189589103464
Iteration: 554
    Time:  72.889
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  1.515981871583347
    Accuracy:  0.5469704442842509
Iteration: 555
An Exception was thrown
Iteration: 556
    Time:  85.876
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.5983714138684092
    Accuracy:  0.5496452555298402
Iteration: 557
    Time:  79.968
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  1.4774324742155558
    Accuracy:  0.5464772166786812
Iteration: 558
    Time:  75.642
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  1.053524706675869
    Accuracy:  0.5377319118260804
Iteration: 559
    Time:  89.239
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  0.7808662833613501
    Accuracy:  0.5146260955343931
Iteration: 560
    Time:  76.447
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.4441122824969246
    Accuracy:  0.5162954812763213
Iteration: 561
    Time:  77.13
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  0.5985661755537739
    Accuracy:  0.5121599575065447
Iteration: 562
    Time:  90.119
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.6856815617137807
    Accuracy:  0.5281519141025155
Iteration: 563
    Time:  83.676
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.9433245127124678
    Accuracy:  0.5425124255416018
Iteration: 564
    Time:  88.867
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  1.5000402059412776
    Accuracy:  0.540349812194104
Iteration: 565
    Time:  78.013
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  1.149818092380621
    Accuracy:  0.5272223697689419
Iteration: 566
    Time:  102.847
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  0.7446597599267454
    Accuracy:  0.5410327427248928
Iteration: 567
    Time:  97.89
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  1.404763191708808
    Accuracy:  0.5302196759874037
Iteration: 568
    Time:  68.319
    Number of Data points:         368
    Number of Training batches:    12 

    Loss:  0.7313025627756465
    Accuracy:  0.5400842280987973
Iteration: 569
    Time:  90.286
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.381126100691623
    Accuracy:  0.5292901316538301
Iteration: 570
    Time:  69.453
    Number of Data points:         368
    Number of Training batches:    12 

    Loss:  0.6323131007524118
    Accuracy:  0.5337291801039572
Iteration: 571
    Time:  99.161
    Number of Data points:         504
    Number of Training batches:    16 

    Loss:  0.8717309223579042
    Accuracy:  0.5155366695754449
Iteration: 572
    Time:  86.454
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.067379770395793
    Accuracy:  0.5340327047843078
Iteration: 573
    Time:  97.149
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  1.4592385213994092
    Accuracy:  0.531642447926547
Iteration: 574
    Time:  101.099
    Number of Data points:         512
    Number of Training batches:    16 

    Loss:  1.4647170852286708
    Accuracy:  0.5252873999317069
Iteration: 575
    Time:  85.602
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  1.0041095259261161
    Accuracy:  0.5395910004932276
Iteration: 576
    Time:  96.689
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.6647444042228602
    Accuracy:  0.5448457715217969
Iteration: 577
    Time:  88.591
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.1835895961173708
    Accuracy:  0.5301817354023599
Iteration: 578
    Time:  87.538
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.647815447821588
    Accuracy:  0.537390446560686
Iteration: 579
    Time:  102.559
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  0.613338251106134
    Accuracy:  0.5404067230716698
Iteration: 580
    Time:  103.529
    Number of Data points:         520
    Number of Training batches:    17 

    Loss:  1.51340117867768
    Accuracy:  0.5388890996699169
Iteration: 581
    Time:  81.409
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.9129556325846906
    Accuracy:  0.5558864817695489
Iteration: 582
    Time:  63.531
    Number of Data points:         336
    Number of Training batches:    11 

    Loss:  0.5942129420894626
    Accuracy:  0.5566452934704254
Iteration: 583
    Time:  94.056
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.5762136369855497
    Accuracy:  0.5574799863413894
Iteration: 584
    Time:  101.223
    Number of Data points:         504
    Number of Training batches:    16 

    Loss:  1.4182523764226973
    Accuracy:  0.5500436316728003
Iteration: 585
    Time:  85.543
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.5005996970717725
    Accuracy:  0.5483552756383503
Iteration: 586
    Time:  96.303
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  1.2710161859424438
    Accuracy:  0.5345259323898774
Iteration: 587
    Time:  85.461
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.6282870205701971
    Accuracy:  0.5381113176765185
Iteration: 588
    Time:  86.758
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  1.3819359623586844
    Accuracy:  0.5363470804719809
Iteration: 589
    Time:  79.449
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.0057871412460473
    Accuracy:  0.5161057783511022
Iteration: 590
    Time:  81.501
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.0282231077113955
    Accuracy:  0.47308115491140873
Iteration: 591
    Time:  100.045
    Number of Data points:         520
    Number of Training batches:    17 

    Loss:  1.3808554874134937
    Accuracy:  0.4763630155176993
Iteration: 592
    Time:  95.925
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.7686326494394444
    Accuracy:  0.45067723944303223
Iteration: 593
    Time:  83.82
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.7803609797472988
    Accuracy:  0.4256174830215882
Iteration: 594
    Time:  105.679
    Number of Data points:         512
    Number of Training batches:    16 

    Loss:  1.3967738955368327
    Accuracy:  0.4438858747201882
Iteration: 595
    Time:  86.924
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.7058109537584849
    Accuracy:  0.42819744280456806
Iteration: 596
    Time:  98.107
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.7050347202915709
    Accuracy:  0.4064385172819365
Iteration: 597
    Time:  87.997
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  1.3417065659969858
    Accuracy:  0.4279697992943051
Iteration: 598
    Time:  93.574
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  1.445781517784972
    Accuracy:  0.43578555981333233
Iteration: 599
    Time:  86.87
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.0016321165117796
    Accuracy:  0.4849375877376029
Iteration: 600
    Time:  98.826
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  1.117065884454463
    Accuracy:  0.5183822134537315
Iteration: 601
    Time:  84.074
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.1149466107881696
    Accuracy:  0.4682247600257996
Iteration: 602
    Time:  86.919
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.9415087503816032
    Accuracy:  0.4120916644534659
Iteration: 603
    Time:  82.092
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.18613658070926
    Accuracy:  0.43937094509997343
Iteration: 604
    Time:  83.049
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.0138908856021782
    Accuracy:  0.49630079295822743
Iteration: 605
    Time:  100.7
    Number of Data points:         528
    Number of Training batches:    17 

    Loss:  0.8970893236885172
    Accuracy:  0.5489623249990515
Iteration: 606
    Time:  91.064
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.7482421024247395
    Accuracy:  0.5588458474029669
Iteration: 607
    Time:  88.928
    Number of Data points:         512
    Number of Training batches:    16 

    Loss:  0.6797685595792489
    Accuracy:  0.5626778464923929
Iteration: 608
    Time:  89.998
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.5936111642035538
    Accuracy:  0.5632279849755283
Iteration: 609
    Time:  85.084
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.1123153081897352
    Accuracy:  0.5487157111962666
Iteration: 610
    Time:  72.733
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  0.6593464960992442
    Accuracy:  0.5547103236331904
Iteration: 611
    Time:  97.072
    Number of Data points:         512
    Number of Training batches:    16 

    Loss:  1.5125578849279333
    Accuracy:  0.5520734529726449
Iteration: 612
    Time:  99.643
    Number of Data points:         504
    Number of Training batches:    16 

    Loss:  1.3598721448559161
    Accuracy:  0.5436316728003946
Iteration: 613
Could not find child with move:  4 3
An Exception was thrown
Iteration: 614
    Time:  87.406
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.1487164937940924
    Accuracy:  0.5278483894221649
Iteration: 615
    Time:  107.029
    Number of Data points:         520
    Number of Training batches:    17 

    Loss:  0.9731321906420942
    Accuracy:  0.4428235383389612
Iteration: 616
    Time:  83.129
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.6945029769987758
    Accuracy:  0.4196418408771863
Iteration: 617
    Time:  107.924
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  1.1054519232248612
    Accuracy:  0.4924877641613234
Iteration: 618
    Time:  93.044
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  1.027896509527663
    Accuracy:  0.5390029214250484
Iteration: 619
    Time:  77.256
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.061548611338249
    Accuracy:  0.4950866942368251
Iteration: 620
    Time:  78.47
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.9011587222887706
    Accuracy:  0.5358538528664112
Iteration: 621
    Time:  98.337
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  1.095665658202648
    Accuracy:  0.4583222673293622
Iteration: 622
    Time:  80.887
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.878362773852987
    Accuracy:  0.41696702963159693
Iteration: 623
    Time:  80.512
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  1.074076210773162
    Accuracy:  0.4613575141328679
Iteration: 624
    Time:  90.541
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.0139402614497264
    Accuracy:  0.5340896156618735
Iteration: 625
    Time:  88.208
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.9685641258211674
    Accuracy:  0.4572599309481352
Iteration: 626
    Time:  92.543
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.8707824621063931
    Accuracy:  0.41340061463747774
Iteration: 627
    Time:  88.801
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.7502319879046443
    Accuracy:  0.39257123344841977
Iteration: 628
    Time:  97.449
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.1570371930048684
    Accuracy:  0.44608642865272985
Iteration: 629
    Time:  86.859
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  1.4097375129820533
    Accuracy:  0.45016504154494064
Iteration: 630
    Time:  73.082
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  0.7196498902336596
    Accuracy:  0.4311378381454642
Iteration: 631
    Time:  97.721
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  1.1046959860320098
    Accuracy:  0.5110217399552301
Iteration: 632
    Time:  81.467
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.8913131898214158
    Accuracy:  0.444568805250977
Iteration: 633
    Time:  85.854
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.8979485835386616
    Accuracy:  0.5269567856736351
Iteration: 634
    Time:  85.886
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.6500875228628953
    Accuracy:  0.5361384072542399
Iteration: 635
    Time:  84.968
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.7567458173609397
    Accuracy:  0.5433850589976097
Iteration: 636
    Time:  93.232
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  1.3369170706002653
    Accuracy:  0.5338999127366544
Iteration: 637
    Time:  93.045
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.7521442171073158
    Accuracy:  0.4683006411958872
Iteration: 638
    Time:  76.227
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  0.7575894655181261
    Accuracy:  0.44014872709337177
Iteration: 639
    Time:  90.651
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.671744083313617
    Accuracy:  0.47791857950449596
Iteration: 640
    Time:  77.884
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  0.7160751042276977
    Accuracy:  0.4321812042341693
Iteration: 641
    Time:  94.412
    Number of Data points:         504
    Number of Training batches:    16 

    Loss:  0.6147968495571453
    Accuracy:  0.4212163751565049
Iteration: 642
    Time:  77.658
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  1.4652257234807549
    Accuracy:  0.437986113745874
Iteration: 643
    Time:  91.811
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  0.8779503316451257
    Accuracy:  0.3849831164396555
Iteration: 644
    Time:  92.947
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  1.4979313780397436
    Accuracy:  0.3879424820730736
Iteration: 645
    Time:  78.291
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.6257021693484608
    Accuracy:  0.3846226808817392
Iteration: 646
    Time:  88.038
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.6012065798204116
    Accuracy:  0.3839018097659066
Iteration: 647
    Time:  92.117
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.5679533130214464
    Accuracy:  0.3835034336229465
Iteration: 648
    Time:  83.097
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  1.5312941101991775
    Accuracy:  0.3839397503509504
Iteration: 649
    Time:  84.945
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.4684180904131676
    Accuracy:  0.3858178093106196
Iteration: 650
    Time:  79.178
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.4931087093035416
    Accuracy:  0.387430284174982
Iteration: 651
    Time:  94.944
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  1.5080087567973086
    Accuracy:  0.38911864020943204
Iteration: 652
    Time:  117.528
    Number of Data points:         552
    Number of Training batches:    18 

    Loss:  1.5162848808170146
    Accuracy:  0.39145198618962707
Iteration: 653
    Time:  98.696
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  0.6375241061847854
    Accuracy:  0.3855332549227909
Iteration: 654
    Time:  87.803
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.5716395512605182
    Accuracy:  0.38505899760974316
Iteration: 655
    Time:  90.915
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.5690706301590874
    Accuracy:  0.38466062146678304
Iteration: 656
    Time:  81.703
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.5861751654289262
    Accuracy:  0.3840725423986038
Iteration: 657
    Time:  79.609
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.5896104808559556
    Accuracy:  0.3834844633304246
Iteration: 658
    Time:  73.877
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  1.5211542956615531
    Accuracy:  0.3838638691808628
Iteration: 659
    Time:  95.477
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.2561676174266019
    Accuracy:  0.40406723071669765
Iteration: 660
    Time:  98.02
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  1.409418325421219
    Accuracy:  0.42252532534051673
Iteration: 661
    Time:  72.284
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  1.171145343742295
    Accuracy:  0.4676935918351861
Iteration: 662
    Time:  63.286
    Number of Data points:         336
    Number of Training batches:    11 

    Loss:  1.0415576915465996
    Accuracy:  0.5206207079713169
Iteration: 663
    Time:  100.622
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.7968072222190622
    Accuracy:  0.5459081079030239
Iteration: 664
    Time:  87.325
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.0718924157659635
    Accuracy:  0.5044769890351709
Iteration: 665
    Time:  88.333
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.0783862671395896
    Accuracy:  0.5472549986720795
Iteration: 666
    Time:  91.115
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.8880206569416225
    Accuracy:  0.5590355503281861
Iteration: 667
    Time:  90.982
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.3499622804285127
    Accuracy:  0.5522252153128201
Iteration: 668
    Time:  70.513
    Number of Data points:         352
    Number of Training batches:    11 

    Loss:  0.6818142414108636
    Accuracy:  0.5554691353340668
Iteration: 669
    Time:  91.999
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  0.7124605360629339
    Accuracy:  0.5602686193421103
Iteration: 670
    Time:  87.908
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.2581857535812868
    Accuracy:  0.5508593542512426
Iteration: 671
    Time:  88.507
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.702767328755585
    Accuracy:  0.5566073528853815
Iteration: 672
    Time:  85.327
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.9847420234719025
    Accuracy:  0.5406912774594984
Iteration: 673
    Time:  81.531
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.7191085820980562
    Accuracy:  0.5495504040672308
Iteration: 674
    Time:  101.361
    Number of Data points:         504
    Number of Training batches:    16 

    Loss:  0.8619056740622764
    Accuracy:  0.48381834047881017
Iteration: 675
    Time:  93.047
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.9322448178233699
    Accuracy:  0.5457373752703266
Iteration: 676
    Time:  74.849
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.7497623236866977
    Accuracy:  0.5557536897218955
Iteration: 677
    Time:  91.103
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  1.4602954392243177
    Accuracy:  0.5541222445650112
Iteration: 678
    Time:  80.092
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.6321434745885954
    Accuracy:  0.5556019273817202
Iteration: 679
    Time:  77.349
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  1.3154778786152646
    Accuracy:  0.5504799484008044
Iteration: 680
    Time:  87.071
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.9324623289721535
    Accuracy:  0.5081382554918997
Iteration: 681
    Time:  64.997
    Number of Data points:         360
    Number of Training batches:    12 

    Loss:  0.985548894361703
    Accuracy:  0.45283985279053
Iteration: 682
    Time:  95.452
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  1.170297375392838
    Accuracy:  0.5265773798231969
Iteration: 683
    Time:  84.133
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.6813419842807337
    Accuracy:  0.5430625640247373
Iteration: 684
    Time:  97.363
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  0.6643030838331282
    Accuracy:  0.5470463254543385
Iteration: 685
    Time:  73.912
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  1.0903055334488128
    Accuracy:  0.5312440717835869
Iteration: 686
    Time:  98.313
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  1.4386784381105138
    Accuracy:  0.5412034753575901
Iteration: 687
    Time:  74.47
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  0.6155594196142784
    Accuracy:  0.5417536138407254
Iteration: 688
    Time:  85.232
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.7206177337082985
    Accuracy:  0.5484880676860037
Iteration: 689
    Time:  98.584
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  1.4287076123029268
    Accuracy:  0.5445612171339682
Iteration: 690
    Time:  92.437
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  1.4109509187432658
    Accuracy:  0.5455287020525856
Iteration: 691
    Time:  76.122
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  1.1720597682537421
    Accuracy:  0.5347535759001404
Iteration: 692
    Time:  86.457
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.7260885921984261
    Accuracy:  0.5445232765489244
Iteration: 693
    Time:  83.998
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  1.1874853553290516
    Accuracy:  0.5284364684903441
Iteration: 694
    Time:  75.254
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.0716391447183846
    Accuracy:  0.5488105626588762
Iteration: 695
    Time:  68.922
    Number of Data points:         360
    Number of Training batches:    12 

    Loss:  0.8857222429667267
    Accuracy:  0.5353037143832758
Iteration: 696
    Time:  68.637
    Number of Data points:         360
    Number of Training batches:    12 

    Loss:  1.0447372287260983
    Accuracy:  0.5025420191979361
Iteration: 697
    Time:  83.817
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.8844243507778308
    Accuracy:  0.4629130781196646
Iteration: 698
    Time:  83.615
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.2963365494613945
    Accuracy:  0.4971354858291915
Iteration: 699
    Time:  82.816
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  1.0097763618667337
    Accuracy:  0.5419053761809007
Iteration: 700
    Time:  90.642
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.088732895601715
    Accuracy:  0.48503243920021244
Iteration: 701
    Time:  86.054
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.9030604924516249
    Accuracy:  0.4285958189475282
Iteration: 702
    Time:  96.497
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  1.060277552536665
    Accuracy:  0.49131160602496493
Iteration: 703
    Time:  79.171
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.856252378001947
    Accuracy:  0.441590469325037
Iteration: 704
    Time:  87.704
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.7919965397514094
    Accuracy:  0.4022271123420723
Iteration: 705
    Time:  103.905
    Number of Data points:         512
    Number of Training batches:    16 

    Loss:  1.4197791147453438
    Accuracy:  0.4088098038471753
Iteration: 706
    Time:  78.854
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.7942000418945188
    Accuracy:  0.3898774519103085
Iteration: 707
    Time:  67.542
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  1.2615806032744503
    Accuracy:  0.4054141214857533
Iteration: 708
    Time:  76.464
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.0718934163252731
    Accuracy:  0.44673141859847476
Iteration: 709
    Time:  81.382
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.3971393057859156
    Accuracy:  0.4537124862465379
Iteration: 710
    Time:  70.877
    Number of Data points:         360
    Number of Training batches:    12 

    Loss:  0.9299728461439928
    Accuracy:  0.41544940622984405
Iteration: 711
    Time:  91.488
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.7104121512601809
    Accuracy:  0.39905907349091324
Iteration: 712
    Time:  110.413
    Number of Data points:         544
    Number of Training batches:    17 

    Loss:  1.4208651716417564
    Accuracy:  0.40755776454072923
Iteration: 713
    Time:  99.201
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  1.1522035721360742
    Accuracy:  0.4552870205258565
Iteration: 714
    Time:  97.649
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  1.3845248398160492
    Accuracy:  0.45818947528170884
Iteration: 715
    Time:  67.143
    Number of Data points:         344
    Number of Training batches:    11 

    Loss:  0.9063312788646528
    Accuracy:  0.42962021474371137
Iteration: 716
    Time:  88.246
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  1.0916943055068964
    Accuracy:  0.48036574723982245
Iteration: 717
    Time:  78.93
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  1.0152973374738197
    Accuracy:  0.5371058921728573
Iteration: 718
    Time:  89.019
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.9108177641132464
    Accuracy:  0.5563607390825966
Iteration: 719
    Time:  69.643
    Number of Data points:         352
    Number of Training batches:    11 

    Loss:  0.8049089844107954
    Accuracy:  0.5592821641309709
Iteration: 720
    Time:  105.521
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.9508021253474267
    Accuracy:  0.5329893386956027
Iteration: 721
    Time:  89.774
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.9612589292196886
    Accuracy:  0.5588837879880107
Iteration: 722
    Time:  91.046
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.6947853040368739
    Accuracy:  0.5602306787570664
Iteration: 723
    Time:  101.572
    Number of Data points:         520
    Number of Training batches:    17 

    Loss:  1.1775647148004422
    Accuracy:  0.5487536517813104
Iteration: 724
    Time:  86.969
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.0538167421377929
    Accuracy:  0.4616800091057404
Iteration: 725
    Time:  84.227
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.987588658116504
    Accuracy:  0.5519216906324695
Iteration: 726
    Time:  79.82
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.6745361321180117
    Accuracy:  0.5570436696133855
Iteration: 727
    Time:  105.116
    Number of Data points:         528
    Number of Training batches:    17 

    Loss:  0.6279390120708416
    Accuracy:  0.5595856888113214
Iteration: 728
    Time:  83.762
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.7981736684352665
    Accuracy:  0.5613119854308154
Iteration: 729
    Time:  83.711
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  1.1987017360100718
    Accuracy:  0.5593011344234928
Iteration: 730
    Time:  84.979
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.5942478799965603
    Accuracy:  0.5594339264711462
Iteration: 731
    Time:  84.944
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  1.046846185009261
    Accuracy:  0.5365557536897219
Iteration: 732
    Time:  67.479
    Number of Data points:         344
    Number of Training batches:    11 

    Loss:  0.9034079717854727
    Accuracy:  0.4906097052016542
Iteration: 733
    Time:  91.395
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  0.9053427534356847
    Accuracy:  0.40501574534279317
Iteration: 734
    Time:  95.979
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.6543475898181531
    Accuracy:  0.3909587585840574
Iteration: 735
    Time:  85.112
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  1.377853379538125
    Accuracy:  0.4161323367606328
Iteration: 736
    Time:  88.471
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.9066108884235607
    Accuracy:  0.5085935425124255
Iteration: 737
    Time:  82.162
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.6838708689036974
    Accuracy:  0.5297643889668778
Iteration: 738
    Time:  86.614
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.9879424421523043
    Accuracy:  0.4591569602003263
Iteration: 739
    Time:  90.625
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.8788024679703864
    Accuracy:  0.3899533330803961
Iteration: 740
    Time:  97.368
    Number of Data points:         504
    Number of Training batches:    16 

    Loss:  1.48248984549493
    Accuracy:  0.39452517357817657
Iteration: 741
    Time:  111.625
    Number of Data points:         536
    Number of Training batches:    17 

    Loss:  0.6118692000150636
    Accuracy:  0.3885495314337747
Iteration: 742
    Time:  69.123
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  1.0295847479403786
    Accuracy:  0.44322191448192133
Iteration: 743
    Time:  101.14
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.7296051725592876
    Accuracy:  0.411427704215199
Iteration: 744
    Time:  86.983
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.4094782737399891
    Accuracy:  0.4310050460978108
Iteration: 745
    Time:  82.501
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.6868199823038807
    Accuracy:  0.40886671472474106
Iteration: 746
    Time:  95.684
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  1.4939222148232123
    Accuracy:  0.41543043593732215
Iteration: 747
    Time:  99.746
    Number of Data points:         520
    Number of Training batches:    17 

    Loss:  0.6443637431195348
    Accuracy:  0.40055772660014416
Iteration: 748
    Time:  83.42
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.6243784035156617
    Accuracy:  0.3941837083127822
Iteration: 749
    Time:  86.327
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  1.3197396776671764
    Accuracy:  0.43576658952081043
Iteration: 750
    Time:  84.816
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.6928621770384852
    Accuracy:  0.40996699169101186
Iteration: 751
    Time:  94.584
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  1.3833612556709045
    Accuracy:  0.43815684637857116
Iteration: 752
    Time:  88.945
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.9214760430913203
    Accuracy:  0.5003604355579163
Iteration: 753
    Time:  90.457
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.8207782841487637
    Accuracy:  0.45820844557423074
Iteration: 754
    Time:  100.431
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  1.2318009764368725
    Accuracy:  0.5059187312668362
Iteration: 755
    Time:  107.338
    Number of Data points:         528
    Number of Training batches:    17 

    Loss:  1.461189381545035
    Accuracy:  0.514853739044656
Iteration: 756
    Time:  75.4
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  0.6836907187281215
    Accuracy:  0.5289486663884357
Iteration: 757
    Time:  83.408
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.9044642203893515
    Accuracy:  0.4945365557536897
Iteration: 758
    Time:  90.247
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.8997606148177532
    Accuracy:  0.5353226846757977
Iteration: 759
    Time:  89.393
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.6607861079672558
    Accuracy:  0.5425503661266456
Iteration: 760
    Time:  94.493
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.758566223700233
    Accuracy:  0.5602306787570664
Iteration: 761
    Time:  88.755
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.5353316324181014
    Accuracy:  0.5599461243692377
Iteration: 762
    Time:  69.368
    Number of Data points:         352
    Number of Training batches:    11 

    Loss:  0.621114160693872
    Accuracy:  0.5607808172402018
Iteration: 763
    Time:  102.419
    Number of Data points:         536
    Number of Training batches:    17 

    Loss:  1.5158789988993995
    Accuracy:  0.5600978867094131
Iteration: 764
    Time:  94.389
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  1.448365076966377
    Accuracy:  0.5549379671434533
Iteration: 765
    Time:  91.927
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.3646724372944603
    Accuracy:  0.545661494100239
Iteration: 766
    Time:  91.924
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  0.6932354748408899
    Accuracy:  0.5567591152255568
Iteration: 767
    Time:  85.909
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.6965165142418617
    Accuracy:  0.56245020298213
Iteration: 768
    Time:  85.849
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.568316965971614
    Accuracy:  0.5626209356148272
Iteration: 769
    Time:  90.079
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.5742360201188863
    Accuracy:  0.5626399059073491
Iteration: 770
    Time:  96.079
    Number of Data points:         512
    Number of Training batches:    16 

    Loss:  1.5173729534819482
    Accuracy:  0.5623743218120424
Iteration: 771
    Time:  83.345
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.6152035366875919
    Accuracy:  0.5626968167849148
Iteration: 772
    Time:  95.583
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.555889015926917
    Accuracy:  0.5626778464923929
Iteration: 773
    Time:  93.234
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  1.5318451851195491
    Accuracy:  0.5627537276624806
Iteration: 774
    Time:  110.445
    Number of Data points:         552
    Number of Training batches:    18 

    Loss:  1.5343110969319798
    Accuracy:  0.5625829950297834
Iteration: 775
    Time:  89.086
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.5606588278213493
    Accuracy:  0.5625829950297834
Iteration: 776
    Time:  91.585
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.5736153909861226
    Accuracy:  0.5626968167849148
Iteration: 777
    Time:  88.655
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  1.4770299596627725
    Accuracy:  0.5624122623970862
Iteration: 778
    Time:  90.933
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  1.5185659581804054
    Accuracy:  0.5620707971316917
Iteration: 779
    Time:  91.065
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.3091298385688057
    Accuracy:  0.5565314717152938
Iteration: 780
    Time:  87.72
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.6470803046699819
    Accuracy:  0.5602496490495883
Iteration: 781
    Time:  96.801
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  1.4285591573127496
    Accuracy:  0.5553553135789354
Iteration: 782
    Time:  100.18
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  1.356834668383869
    Accuracy:  0.5449975338619721
Iteration: 783
    Time:  94.375
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  1.200746803083972
    Accuracy:  0.5139431650036044
Iteration: 784
    Time:  83.627
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.967410881505242
    Accuracy:  0.5538946010547483
Iteration: 785
    Time:  91.891
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.0224811554984967
    Accuracy:  0.5135258185681223
Iteration: 786
    Time:  77.935
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  0.9645592780075491
    Accuracy:  0.46350115718784385
Iteration: 787
    Time:  82.699
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.0158381586834435
    Accuracy:  0.5075881170087643
Iteration: 788
    Time:  84.582
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.6324861975528886
    Accuracy:  0.5234283112645597
Iteration: 789
    Time:  95.163
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.9713181135639312
    Accuracy:  0.47059604659103843
Iteration: 790
    Time:  85.229
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.8366513987709444
    Accuracy:  0.43677201502447166
Iteration: 791
    Time:  76.822
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.7511089022404791
    Accuracy:  0.4123003376712069
Iteration: 792
    Time:  71.753
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  1.4469863424633063
    Accuracy:  0.41687217816898736
Iteration: 793
    Time:  88.256
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.6799135810389364
    Accuracy:  0.40653336874454604
Iteration: 794
    Time:  72.941
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  0.6692237949470498
    Accuracy:  0.39959024168152674
Iteration: 795
    Time:  68.051
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.4898111085841976
    Accuracy:  0.4034032704784308
Iteration: 796
    Time:  88.523
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.368746533064616
    Accuracy:  0.4165686534886368
Iteration: 797
    Time:  66.555
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  1.2361325914457681
    Accuracy:  0.43614599537124865
Iteration: 798
    Time:  82.342
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.1242757381793438
    Accuracy:  0.4767424213681375
Iteration: 799
    Time:  72.449
    Number of Data points:         360
    Number of Training batches:    12 

    Loss:  0.8602968160764705
    Accuracy:  0.44874226960579733
Iteration: 800
    Time:  90.291
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.786770123258095
    Accuracy:  0.41507000037940583
Iteration: 801
    Time:  88.815
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  1.4373647601600419
    Accuracy:  0.4202868308229313
Iteration: 802
    Time:  73.811
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.9167552997903338
    Accuracy:  0.3863869180862769
Iteration: 803
    Time:  83.501
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.2922962509246574
    Accuracy:  0.3935197480745153
Iteration: 804
    Time:  94.426
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.1200964196200258
    Accuracy:  0.43170694692112155
Iteration: 805
    Time:  95.954
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.7963939019012672
    Accuracy:  0.4058124976287134
Iteration: 806
    Time:  103.001
    Number of Data points:         520
    Number of Training batches:    17 

    Loss:  1.4087859240305554
    Accuracy:  0.4102515460788405
Iteration: 807
    Time:  86.339
    Number of Data points:         512
    Number of Training batches:    16 

    Loss:  1.4078692238082846
    Accuracy:  0.41442501043366087
Iteration: 808
    Time:  90.44
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.2008450761388272
    Accuracy:  0.43975035095041165
Iteration: 809
    Time:  78.403
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.8587159786970571
    Accuracy:  0.4142922183860075
Iteration: 810
    Time:  71.126
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  0.829706779239282
    Accuracy:  0.39746556891907275
Iteration: 811
    Time:  92.417
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.727716347196996
    Accuracy:  0.3868232348142808
Iteration: 812
    Time:  77.241
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.2745505806916262
    Accuracy:  0.3915468376522366
Iteration: 813
    Time:  93.602
    Number of Data points:         512
    Number of Training batches:    16 

    Loss:  1.4218157623165055
    Accuracy:  0.3954547179117502
Iteration: 814
    Time:  86.371
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.7414824776332809
    Accuracy:  0.38815115529081456
Iteration: 815
    Time:  90.586
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.6999545443191245
    Accuracy:  0.38403460181356
Iteration: 816
    Time:  76.509
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  1.3137635358764908
    Accuracy:  0.3877907197328983
Iteration: 817
    Time:  95.123
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  1.443072218674418
    Accuracy:  0.3893652540122169
Iteration: 818
    Time:  100.152
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  1.201631333407042
    Accuracy:  0.4018856470766779
Iteration: 819
    Time:  102.044
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  1.092491003557026
    Accuracy:  0.45268809045035474
Iteration: 820
    Time:  82.747
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.9758629125897779
    Accuracy:  0.5533254922790909
Iteration: 821
    Time:  101.956
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  1.416374816468686
    Accuracy:  0.549910839625147
Iteration: 822
    Time:  84.854
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.9497402632936472
    Accuracy:  0.42383427552452857
Iteration: 823
    Time:  84.646
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.8843856039519229
    Accuracy:  0.39551162878931595
Iteration: 824
    Time:  79.012
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  0.785104583446323
    Accuracy:  0.3892514322570854
Iteration: 825
    Time:  84.091
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  1.4353266799520052
    Accuracy:  0.3942785597753917
Iteration: 826
    Time:  95.673
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  1.4203591526671255
    Accuracy:  0.39850893500777784
Iteration: 827
    Time:  80.774
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.7747024387382714
    Accuracy:  0.3917744811624995
Iteration: 828
    Time:  85.61
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.1636870313129448
    Accuracy:  0.41083962514701977
Iteration: 829
    Time:  88.359
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.8243338172418828
    Accuracy:  0.3938612133399097
Iteration: 830
    Time:  85.041
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.196255113450105
    Accuracy:  0.4078802595136017
Iteration: 831
    Time:  86.821
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.9205771120577905
    Accuracy:  0.3828963842622453
Iteration: 832
    Time:  101.26
    Number of Data points:         512
    Number of Training batches:    16 

    Loss:  1.1509924860843757
    Accuracy:  0.39850893500777784
Iteration: 833
    Time:  81.02
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.8515819247194147
    Accuracy:  0.38412945327616954
Iteration: 834
    Time:  73.289
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.1110455453163708
    Accuracy:  0.38970671927761125
Iteration: 835
    Time:  90.562
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.856277553237515
    Accuracy:  0.38424327503130096
Iteration: 836
    Time:  90.105
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.766897382384141
    Accuracy:  0.3824031566566756
Iteration: 837
    Time:  84.792
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.7007442811890574
    Accuracy:  0.3823652160716318
Iteration: 838
    Time:  97.378
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  1.3218947853137606
    Accuracy:  0.38274462192207004
Iteration: 839
    Time:  113.031
    Number of Data points:         520
    Number of Training batches:    17 

    Loss:  0.7056133135895103
    Accuracy:  0.3823652160716318
Iteration: 840
    Time:  82.351
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.2961133282989552
    Accuracy:  0.38276359221459194
Iteration: 841
    Time:  103.445
    Number of Data points:         520
    Number of Training batches:    17 

    Loss:  0.7198843548651376
    Accuracy:  0.3823652160716318
Iteration: 842
    Time:  78.843
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.6888057016293309
    Accuracy:  0.3823652160716318
Iteration: 843
    Time:  89.123
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  1.3959981733417146
    Accuracy:  0.3824410972417195
Iteration: 844
Could not find child with move:  2 6
An Exception was thrown
Iteration: 845
    Time:  91.934
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.2797680326036034
    Accuracy:  0.38454679971165157
Iteration: 846
Could not find child with move:  2 4
An Exception was thrown
Iteration: 847
    Time:  95.971
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  1.1763905373560015
    Accuracy:  0.39462002504078614
Iteration: 848
    Time:  82.923
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.8510916223758489
    Accuracy:  0.38651971013393027
Iteration: 849
    Time:  83.626
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.7537880087266247
    Accuracy:  0.3828963842622453
Iteration: 850
    Time:  93.519
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  1.4196539409512214
    Accuracy:  0.3829153545547672
Iteration: 851
    Time:  83.089
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.1756424102242788
    Accuracy:  0.3848882649770459
Iteration: 852
    Time:  77.023
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  1.1053944427822124
    Accuracy:  0.4012027165458891
Iteration: 853
    Time:  103.826
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  1.0000941586324086
    Accuracy:  0.5495124634821869
Iteration: 854
    Time:  88.686
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.8604255987651116
    Accuracy:  0.5607808172402018
Iteration: 855
    Time:  70.314
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  1.149646424442219
    Accuracy:  0.5511628789315931
Iteration: 856
    Time:  71.197
    Number of Data points:         368
    Number of Training batches:    12 

    Loss:  0.8823616300654807
    Accuracy:  0.561615510111166
Iteration: 857
    Time:  76.017
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.0834986075781194
    Accuracy:  0.526975755966157
Iteration: 858
    Time:  84.885
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.9717266304144204
    Accuracy:  0.3898584816177865
Iteration: 859
    Time:  79.764
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.8629094119142413
    Accuracy:  0.38424327503130096
Iteration: 860
    Time:  82.6
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.8134453654176047
    Accuracy:  0.3828205030921577
Iteration: 861
    Time:  83.37
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.7352878743445372
    Accuracy:  0.38270668133702623
Iteration: 862
    Time:  92.04
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  1.2284000815715095
    Accuracy:  0.3833516712827712
Iteration: 863
    Time:  96.625
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  0.761626382659472
    Accuracy:  0.3824031566566756
Iteration: 864
    Time:  95.469
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.7140946998607476
    Accuracy:  0.3823652160716318
Iteration: 865
    Time:  92.417
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  1.310904630960048
    Accuracy:  0.38257388928937286
Iteration: 866
    Time:  86.02
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  1.1787968219019886
    Accuracy:  0.3828963842622453
Iteration: 867
    Time:  88.236
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.109267531418077
    Accuracy:  0.3903327389308343
Iteration: 868
    Time:  80.706
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.9994018723858008
    Accuracy:  0.534829457070228
Iteration: 869
    Time:  98.026
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  0.859278538116951
    Accuracy:  0.5603824410972417
Iteration: 870
    Time:  86.142
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  1.4347711800667846
    Accuracy:  0.5578214516067838
Iteration: 871
    Time:  95.276
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.7624475486831129
    Accuracy:  0.5626778464923929
Iteration: 872
    Time:  92.683
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  1.2378581506656232
    Accuracy:  0.5556208976742422
Iteration: 873
    Time:  83.928
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.8093102627610256
    Accuracy:  0.5615775695261221
Iteration: 874
    Time:  107.327
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  1.436688290391966
    Accuracy:  0.5596615699814091
Iteration: 875
    Time:  82.239
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.7250525021848107
    Accuracy:  0.5624122623970862
Iteration: 876
    Time:  90.896
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.1818171719733093
    Accuracy:  0.5602117084645445
Iteration: 877
    Time:  88.016
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.0646294526949378
    Accuracy:  0.4961110900330083
Iteration: 878
    Time:  100.924
    Number of Data points:         504
    Number of Training batches:    16 

    Loss:  0.8992312840180863
    Accuracy:  0.384451948249042
Iteration: 879
    Time:  82.531
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.7482081326114705
    Accuracy:  0.38259285958189476
Iteration: 880
    Time:  81.622
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  1.2174954764572496
    Accuracy:  0.3867473536441932
Iteration: 881
    Time:  70.411
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  1.0921628407962374
    Accuracy:  0.40899950677239444
Iteration: 882
    Time:  77.968
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.9122455167342837
    Accuracy:  0.38564707667792236
Iteration: 883
    Time:  87.821
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.8376327448736193
    Accuracy:  0.38259285958189476
Iteration: 884
    Time:  73.651
    Number of Data points:         368
    Number of Training batches:    12 

    Loss:  1.1925828882969216
    Accuracy:  0.3848123838069583
Iteration: 885
    Time:  82.319
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.0622032793951588
    Accuracy:  0.4136282581477406
Iteration: 886
    Time:  91.375
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.8615853508710629
    Accuracy:  0.3873733732974162
Iteration: 887
    Time:  82.234
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  1.1095124114266866
    Accuracy:  0.42140607808172403
Iteration: 888
    Time:  88.868
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.8473895607300667
    Accuracy:  0.3865576507189741
Iteration: 889
    Time:  84.173
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.082572551968812
    Accuracy:  0.4234928102591342
Iteration: 890
    Time:  87.189
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.912518981705821
    Accuracy:  0.5408620100921956
Iteration: 891
    Time:  100.215
    Number of Data points:         520
    Number of Training batches:    17 

    Loss:  0.8394553064445104
    Accuracy:  0.43440072845923283
Iteration: 892
    Time:  64.585
    Number of Data points:         344
    Number of Training batches:    11 

    Loss:  0.7566285152515174
    Accuracy:  0.40550897294836286
Iteration: 893
    Time:  89.0
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  1.02433341629299
    Accuracy:  0.5266342907007626
Iteration: 894
    Time:  83.118
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.7164812826664023
    Accuracy:  0.5503850969381948
Iteration: 895
    Time:  107.665
    Number of Data points:         560
    Number of Training batches:    18 

    Loss:  1.498385969059405
    Accuracy:  0.5478430777402588
Iteration: 896
    Time:  79.276
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  1.1399949672116054
    Accuracy:  0.509769700648784
Iteration: 897
    Time:  95.797
    Number of Data points:         504
    Number of Training batches:    16 

    Loss:  1.4217502280150431
    Accuracy:  0.4952194862844785
Iteration: 898
    Time:  97.591
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  0.8775688899144813
    Accuracy:  0.5510490571764617
Iteration: 899
    Time:  90.863
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.7104233297490917
    Accuracy:  0.5591304017907957
Iteration: 900
    Time:  91.852
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  0.623769027059654
    Accuracy:  0.562241529764389
Iteration: 901
    Time:  88.84
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.395908940695955
    Accuracy:  0.5577076298516523
Iteration: 902
Could not find child with move:  4 7
An Exception was thrown
Iteration: 903
    Time:  87.022
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  1.4638642191881057
    Accuracy:  0.5536859278370072
Iteration: 904
    Time:  77.927
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  1.2960776662496523
    Accuracy:  0.5438782866031794
Iteration: 905
    Time:  91.494
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.9827448480595059
    Accuracy:  0.4016769738589369
Iteration: 906
    Time:  82.561
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.9262063264987297
    Accuracy:  0.4989186933262511
Iteration: 907
    Time:  78.307
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  0.8729142330283861
    Accuracy:  0.4147095648214896
Iteration: 908
    Time:  80.343
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.8420288524926741
    Accuracy:  0.5028834844633304
Iteration: 909
Could not find child with move:  5 1
An Exception was thrown
Iteration: 910
    Time:  82.264
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.815737965115157
    Accuracy:  0.5471791175019919
Iteration: 911
    Time:  83.206
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.7731996438885034
    Accuracy:  0.560534203437417
Iteration: 912
    Time:  80.321
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.6221773618089781
    Accuracy:  0.5619190347915165
Iteration: 913
    Time:  89.095
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.6027611546566511
    Accuracy:  0.5628865197101339
Iteration: 914
    Time:  102.127
    Number of Data points:         512
    Number of Training batches:    16 

    Loss:  0.5667094744673618
    Accuracy:  0.5630572523428311
Iteration: 915
    Time:  72.869
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.5962861151454727
    Accuracy:  0.5632659255605721
Iteration: 916
    Time:  88.011
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.5798621817647376
    Accuracy:  0.5634176879007474
Iteration: 917
    Time:  78.008
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  0.596232556911132
    Accuracy:  0.563721212581098
Iteration: 918
    Time:  77.729
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.5727026123391928
    Accuracy:  0.563721212581098
Iteration: 919
    Time:  84.484
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.5139394383678269
    Accuracy:  0.5636453314110104
Iteration: 920
    Time:  87.25
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  1.4803418872921221
    Accuracy:  0.5631521038054407
Iteration: 921
    Time:  79.921
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.5906634989148679
    Accuracy:  0.5635504799484008
Iteration: 922
    Time:  89.161
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.5833273020466251
    Accuracy:  0.5637022422885761
Iteration: 923
    Time:  81.274
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.5791001742338324
    Accuracy:  0.5637591531661418
Iteration: 924
    Time:  86.007
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.5761157531790644
    Accuracy:  0.5638540046287513
Iteration: 925
    Time:  83.112
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.439861524869187
    Accuracy:  0.5629054900026559
Iteration: 926
    Time:  87.847
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.5711477272438624
    Accuracy:  0.5629813711727435
Iteration: 927
    Time:  92.895
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.6030197644929971
    Accuracy:  0.563721212581098
Iteration: 928
    Time:  86.805
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.5725315712871765
    Accuracy:  0.5637781234586637
Iteration: 929
    Time:  94.835
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  0.5726854726068792
    Accuracy:  0.5637970937511857
Iteration: 930
    Time:  88.531
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.5259499818098714
    Accuracy:  0.5637781234586637
Iteration: 931
    Time:  89.232
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.5635944155118147
    Accuracy:  0.5638160640437075
Iteration: 932
    Time:  79.201
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  0.5600171117458767
    Accuracy:  0.5637970937511857
Iteration: 933
    Time:  73.394
    Number of Data points:         368
    Number of Training batches:    12 

    Loss:  0.565801502174388
    Accuracy:  0.5637970937511857
Iteration: 934
    Time:  85.397
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  1.4926200922930049
    Accuracy:  0.5635694502409228
Iteration: 935
    Time:  73.274
    Number of Data points:         368
    Number of Training batches:    12 

    Loss:  0.5815499672926053
    Accuracy:  0.5637591531661418
Iteration: 936
    Time:  79.384
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  1.5177278933360274
    Accuracy:  0.5636073908259666
Iteration: 937
    Time:  88.562
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  1.5313760936030592
    Accuracy:  0.5634556284857912
Iteration: 938
    Time:  89.737
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.5160758754380925
    Accuracy:  0.5632090146830064
Iteration: 939
    Time:  91.643
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.5832720669405708
    Accuracy:  0.563512539363357
Iteration: 940
    Time:  87.844
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.5696678800996824
    Accuracy:  0.5636453314110104
Iteration: 941
    Time:  80.21
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  1.5300463637048696
    Accuracy:  0.563512539363357
Iteration: 942
    Time:  84.445
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.421658047475414
    Accuracy:  0.5616724209887316
Iteration: 943
    Time:  83.115
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.5793644209304268
    Accuracy:  0.5619380050840384
Iteration: 944
    Time:  94.541
    Number of Data points:         504
    Number of Training batches:    16 

    Loss:  1.4699945314655307
    Accuracy:  0.5600978867094131
Iteration: 945
    Time:  99.581
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  1.4360113068330995
    Accuracy:  0.5559244223545927
Iteration: 946
    Time:  77.3
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  1.0844846962727572
    Accuracy:  0.5309974579808021
Iteration: 947
    Time:  78.972
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  1.0879587433070694
    Accuracy:  0.45469894145767725
Iteration: 948
    Time:  73.509
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  1.070411888787037
    Accuracy:  0.5278483894221649
Iteration: 949
    Time:  87.047
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.6690595848696984
    Accuracy:  0.5434799104602193
Iteration: 950
    Time:  103.569
    Number of Data points:         520
    Number of Training batches:    17 

    Loss:  1.4240718695844414
    Accuracy:  0.5374663277307736
Iteration: 951
    Time:  81.408
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.9529081334006264
    Accuracy:  0.44813522024509617
Iteration: 952
    Time:  83.165
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.831755385536697
    Accuracy:  0.5289676366809576
Iteration: 953
    Time:  91.463
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.8058296701156716
    Accuracy:  0.46207838524870054
Iteration: 954
    Time:  66.574
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  0.6579765830080732
    Accuracy:  0.44758508176196077
Iteration: 955
    Time:  84.025
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.6536202290602947
    Accuracy:  0.42535189892628145
Iteration: 956
    Time:  62.136
    Number of Data points:         320
    Number of Training batches:    10 

    Loss:  1.2677030284702524
    Accuracy:  0.45168266494669346
Iteration: 957
    Time:  99.253
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  1.458770596646726
    Accuracy:  0.4639754145008916
Iteration: 958
    Time:  81.831
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  1.2065395735879723
    Accuracy:  0.5236938953598664
Iteration: 959
    Time:  92.823
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.7956726306334584
    Accuracy:  0.4563114163220397
Iteration: 960
    Time:  100.446
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  0.7911373133585855
    Accuracy:  0.3968774898508935
Iteration: 961
    Time:  76.783
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  0.6811188167719042
    Accuracy:  0.38966877869256744
Iteration: 962
    Time:  90.677
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.6062857825023801
    Accuracy:  0.3869180862768904
Iteration: 963
    Time:  93.374
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.61374562467024
    Accuracy:  0.3849831164396555
Iteration: 964
    Time:  79.324
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.4237171795418821
    Accuracy:  0.3883408582160337
Iteration: 965
    Time:  83.331
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.5855112322379126
    Accuracy:  0.38761998710020107
Iteration: 966
    Time:  73.734
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  0.6053782539591954
    Accuracy:  0.38568501726296617
Iteration: 967
    Time:  93.574
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  1.5017922170193925
    Accuracy:  0.3873354327123724
Iteration: 968
Could not find child with move:  6 4
An Exception was thrown
Iteration: 969
    Time:  110.769
    Number of Data points:         528
    Number of Training batches:    17 

    Loss:  1.4372773013064573
    Accuracy:  0.3934438669044277
Iteration: 970
    Time:  85.468
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  1.360290330961669
    Accuracy:  0.4180293660128239
Iteration: 971
    Time:  86.055
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  1.328198425761809
    Accuracy:  0.4552301096482908
Iteration: 972
    Time:  86.934
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.7600973024722758
    Accuracy:  0.4146526539439238
Iteration: 973
Could not find child with move:  2 0
An Exception was thrown
Iteration: 974
    Time:  99.891
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  0.6780233668428708
    Accuracy:  0.3993815684637857
Iteration: 975
    Time:  91.346
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.379796736001483
    Accuracy:  0.42324619645634937
Iteration: 976
    Time:  85.17
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  1.4588125142883943
    Accuracy:  0.4355010054255037
Iteration: 977
    Time:  103.562
    Number of Data points:         528
    Number of Training batches:    17 

    Loss:  1.4357037317236623
    Accuracy:  0.4469211215236939
Iteration: 978
    Time:  102.614
    Number of Data points:         512
    Number of Training batches:    16 

    Loss:  1.0456725443220676
    Accuracy:  0.5432332966574345
Iteration: 979
    Time:  78.498
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  0.9446417920670087
    Accuracy:  0.46955268050233334
Iteration: 980
    Time:  95.808
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.8131363231066678
    Accuracy:  0.5341275562469173
Iteration: 981
    Time:  86.044
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.6876294449789587
    Accuracy:  0.5480138103729559
Iteration: 982
    Time:  80.473
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.6462314412761732
    Accuracy:  0.5535531357893538
Iteration: 983
    Time:  72.997
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  0.6115688102845155
    Accuracy:  0.5553363432864135
Iteration: 984
    Time:  93.525
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.5837903022032896
    Accuracy:  0.5571764616610388
Iteration: 985
    Time:  83.707
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.6020756636350689
    Accuracy:  0.5596425996888872
Iteration: 986
    Time:  75.411
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.6212460743140492
    Accuracy:  0.563531509655879
Iteration: 987
    Time:  91.654
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.5091224219616854
    Accuracy:  0.5624691732746518
Iteration: 988
    Time:  91.372
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  1.3863867096021074
    Accuracy:  0.5559054520620708
Iteration: 989
    Time:  66.402
    Number of Data points:         344
    Number of Training batches:    11 

    Loss:  0.9557625611242102
    Accuracy:  0.535683120233714
Iteration: 990
    Time:  91.563
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.6913457772808922
    Accuracy:  0.5487536517813104
Iteration: 991
    Time:  85.146
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.1558672274294384
    Accuracy:  0.5075312061311985
Iteration: 992
    Time:  68.302
    Number of Data points:         336
    Number of Training batches:    11 

    Loss:  0.7396826583852096
    Accuracy:  0.5287399931706946
Iteration: 993
    Time:  101.454
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  0.6795004328527212
    Accuracy:  0.5496452555298402
Iteration: 994
    Time:  72.537
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.6031236631561776
    Accuracy:  0.5530219675987403
Iteration: 995
    Time:  77.339
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.3599340229720505
    Accuracy:  0.5420381682285541
Iteration: 996
    Time:  98.518
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.8270450755312269
    Accuracy:  0.503187009143681
Iteration: 997
    Time:  87.807
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.9148073771538373
    Accuracy:  0.40943582350039837
Iteration: 998
    Time:  105.465
    Number of Data points:         520
    Number of Training batches:    17 

    Loss:  0.6613506954614665
    Accuracy:  0.39505634176879006
Iteration: 999
    Time:  85.458
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  1.2059785293104244
    Accuracy:  0.439048450127101
Iteration: 1000
    Time:  73.982
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  0.734217719268795
    Accuracy:  0.4176879007474295
Iteration: 1001
    Time:  84.264
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.9039401697434563
    Accuracy:  0.5073984140835451
Iteration: 1002
    Time:  113.655
    Number of Data points:         552
    Number of Training batches:    18 

    Loss:  1.484950262052279
    Accuracy:  0.4979132678225898
Iteration: 1003
    Time:  81.592
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.8962147506586843
    Accuracy:  0.5416018515005502
Iteration: 1004
    Time:  81.099
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.6731402779315185
    Accuracy:  0.5467048601889442
Iteration: 1005
    Time:  88.804
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.6595815698061739
    Accuracy:  0.5540463633949235
Iteration: 1006
    Time:  91.058
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.4255387984621206
    Accuracy:  0.5473498501346891
Iteration: 1007
    Time:  86.143
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.5949261524456505
    Accuracy:  0.5502333345980195
Iteration: 1008
    Time:  91.378
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.4583801101953353
    Accuracy:  0.5453010585423227
Iteration: 1009
    Time:  82.352
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.0114010194045893
    Accuracy:  0.5105854232272261
Iteration: 1010
    Time:  75.435
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  0.8564711257792254
    Accuracy:  0.5382251394316501
Iteration: 1011
    Time:  78.255
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  1.4173612210987783
    Accuracy:  0.5293280722388739
Iteration: 1012
    Time:  73.044
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.8039246782047063
    Accuracy:  0.48626550821413667
Iteration: 1013
    Time:  80.082
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.6931425664629243
    Accuracy:  0.5223849451758547
Iteration: 1014
    Time:  76.368
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  1.010850792126041
    Accuracy:  0.46463937473915845
Iteration: 1015
    Time:  92.566
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.8091083558287544
    Accuracy:  0.40704556664263764
Iteration: 1016
    Time:  81.958
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  1.4769796822892214
    Accuracy:  0.41594263383541374
Iteration: 1017
    Time:  76.183
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  1.2374505954398225
    Accuracy:  0.4524414766475699
Iteration: 1018
    Time:  81.253
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.8021626316965254
    Accuracy:  0.5138862541260386
Iteration: 1019
    Time:  81.576
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.0310031990652482
    Accuracy:  0.5447509200591873
Iteration: 1020
    Time:  71.215
    Number of Data points:         368
    Number of Training batches:    12 

    Loss:  0.5988514125077736
    Accuracy:  0.5463633949235497
Iteration: 1021
    Time:  98.733
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.6206102900099313
    Accuracy:  0.5504230375232386
Iteration: 1022
    Time:  82.55
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.8873673998117487
    Accuracy:  0.5355882687711044
Iteration: 1023
    Time:  103.189
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  0.7732681199024417
    Accuracy:  0.4740676101225481
Iteration: 1024
    Time:  80.13
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  0.6926936748450743
    Accuracy:  0.4497856356945024
Iteration: 1025
    Time:  96.81
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.6153008107219325
    Accuracy:  0.4370565694123003
Iteration: 1026
    Time:  96.995
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.0028301423187485
    Accuracy:  0.5078157605190272
Iteration: 1027
    Time:  91.659
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.4280413700489558
    Accuracy:  0.5211139355768866
Iteration: 1028
    Time:  74.699
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.6342944908135335
    Accuracy:  0.5321356755321167
Iteration: 1029
    Time:  103.79
    Number of Data points:         520
    Number of Training batches:    17 

    Loss:  1.457584044170665
    Accuracy:  0.5316993588041128
Iteration: 1030
    Time:  77.76
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  0.8321146735951148
    Accuracy:  0.5000948514626096
Iteration: 1031
    Time:  92.971
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  1.26445550792251
    Accuracy:  0.5298212998444436
Iteration: 1032
    Time:  77.514
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.7439209183471137
    Accuracy:  0.5431763857798687
Iteration: 1033
    Time:  75.907
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  0.5687846102366328
    Accuracy:  0.5438024054330918
Iteration: 1034
    Time:  75.459
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  0.8876847741821724
    Accuracy:  0.5568160261031225
Iteration: 1035
Could not find child with move:  2 6
An Exception was thrown
Iteration: 1036
    Time:  81.165
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.5682035587300087
    Accuracy:  0.5567591152255568
Iteration: 1037
    Time:  79.148
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.7146635606341996
    Accuracy:  0.5467048601889442
Iteration: 1038
    Time:  72.862
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  1.4622929558097861
    Accuracy:  0.5443335736237053
Iteration: 1039
    Time:  76.692
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.6059590437446657
    Accuracy:  0.5461736919983307
Iteration: 1040
    Time:  94.628
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  0.6279053256610801
    Accuracy:  0.5562658876199871
Iteration: 1041
    Time:  84.225
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  1.4622397658874773
    Accuracy:  0.5541032742724893
Iteration: 1042
    Time:  98.179
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  0.5687954098706018
    Accuracy:  0.5543119474902303
Iteration: 1043
    Time:  84.953
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  1.2955936177547924
    Accuracy:  0.5433471184125659
Iteration: 1044
    Time:  77.379
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.5921114725139401
    Accuracy:  0.5451113556171037
Iteration: 1045
    Time:  84.909
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.3672034573807414
    Accuracy:  0.5372386842205107
Iteration: 1046
    Time:  95.354
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  0.6004003130721862
    Accuracy:  0.540786128922108
Iteration: 1047
    Time:  93.41
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  1.425741407256433
    Accuracy:  0.5350191599954471
Iteration: 1048
    Time:  85.534
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.4888313145384013
    Accuracy:  0.5334446257161285
Iteration: 1049
    Time:  77.182
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.6732744085702111
    Accuracy:  0.5392305649353113
Iteration: 1050
    Time:  93.453
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.3142216494716676
    Accuracy:  0.5308267253481048
Iteration: 1051
    Time:  91.117
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.7422056447941006
    Accuracy:  0.5081572257844216
Iteration: 1052
Could not find child with move:  0 1
An Exception was thrown
Iteration: 1053
    Time:  78.162
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.9117960729310434
    Accuracy:  0.44910270516371364
Iteration: 1054
    Time:  95.55
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.6779562972588824
    Accuracy:  0.4082596653640399
Iteration: 1055
    Time:  66.303
    Number of Data points:         336
    Number of Training batches:    11 

    Loss:  1.3520339329369002
    Accuracy:  0.42537086921880335
Iteration: 1056
    Time:  78.733
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.0283592611792753
    Accuracy:  0.4891489926774671
Iteration: 1057
    Time:  73.255
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.8965975634804959
    Accuracy:  0.4137041393178283
Iteration: 1058
    Time:  71.895
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  0.7838776156523637
    Accuracy:  0.3887392343589938
Iteration: 1059
    Time:  74.485
    Number of Data points:         368
    Number of Training batches:    12 

    Loss:  1.4074601996016407
    Accuracy:  0.39589103463975417
Iteration: 1060
    Time:  81.223
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  0.5928379213683921
    Accuracy:  0.3929126987138142
Iteration: 1061
    Time:  82.693
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  1.467594939968157
    Accuracy:  0.3981105588648177
Iteration: 1062
    Time:  85.864
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.5976739752231724
    Accuracy:  0.3952460446940092
Iteration: 1063
    Time:  82.89
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  1.029902435482838
    Accuracy:  0.46016238570398754
Iteration: 1064
    Time:  80.574
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.9838382746116972
    Accuracy:  0.5253063702242289
Iteration: 1065
    Time:  71.205
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  0.8500938544588656
    Accuracy:  0.5466100087263346
Iteration: 1066
    Time:  68.142
    Number of Data points:         360
    Number of Training batches:    12 

    Loss:  0.9880849533234456
    Accuracy:  0.5232955192169063
Iteration: 1067
    Time:  82.346
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.0111838945973053
    Accuracy:  0.5469325036992071
Iteration: 1068
    Time:  85.87
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  1.441422496705091
    Accuracy:  0.5409189209697614
Iteration: 1069
    Time:  84.73
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  1.0018760826610704
    Accuracy:  0.4820541032742725
Iteration: 1070
    Time:  93.592
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.684390691839774
    Accuracy:  0.4459156960200326
Iteration: 1071
    Time:  94.045
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.7451903223964853
    Accuracy:  0.3873544030048943
Iteration: 1072
    Time:  77.571
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  1.3074463312189708
    Accuracy:  0.4156580794475851
Iteration: 1073
    Time:  80.127
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.5938365868734935
    Accuracy:  0.40704556664263764
Iteration: 1074
    Time:  93.855
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.6699203698602619
    Accuracy:  0.3935197480745153
Iteration: 1075
    Time:  71.673
    Number of Data points:         360
    Number of Training batches:    12 

    Loss:  0.6149710078715295
    Accuracy:  0.390408620100922
Iteration: 1076
    Time:  80.718
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.5655091133177172
    Accuracy:  0.3899533330803961
Iteration: 1077
    Time:  89.611
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.600310689307716
    Accuracy:  0.386367947793755
Iteration: 1078
    Time:  88.839
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  1.4878391347472575
    Accuracy:  0.38896687786925677
Iteration: 1079
    Time:  91.493
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  1.3637775949679314
    Accuracy:  0.40738703190803205
Iteration: 1080
    Time:  71.803
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  1.234974309047393
    Accuracy:  0.4664036119436962
Iteration: 1081
    Time:  74.861
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  0.7409035457318874
    Accuracy:  0.49730621846188866
Iteration: 1082
    Time:  88.15
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  1.3198195355384934
    Accuracy:  0.4528777933755739
Iteration: 1083
    Time:  84.4
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.0360901669857598
    Accuracy:  0.49954471297947417
Iteration: 1084
    Time:  99.874
    Number of Data points:         504
    Number of Training batches:    16 

    Loss:  1.0434140868958106
    Accuracy:  0.410574041051713
Iteration: 1085
    Time:  73.879
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  1.1763184073182582
    Accuracy:  0.45375042683158173
Iteration: 1086
    Time:  95.536
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.8893828250804163
    Accuracy:  0.5421899305687293
Iteration: 1087
    Time:  88.665
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.0279053011358423
    Accuracy:  0.45805668323405546
Iteration: 1088
    Time:  94.277
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.8703373418547109
    Accuracy:  0.5365747239822438
Iteration: 1089
    Time:  81.906
    Number of Data points:         368
    Number of Training batches:    12 

    Loss:  0.7220128699573283
    Accuracy:  0.5464961869712031
Iteration: 1090
    Time:  82.041
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.7152499364954021
    Accuracy:  0.5542740069051865
Iteration: 1091
    Time:  79.536
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.0184219074301928
    Accuracy:  0.5232765489243845
Iteration: 1092
    Time:  91.785
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.7321155056065528
    Accuracy:  0.5457753158553705
Iteration: 1093
    Time:  79.913
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.7322423619159755
    Accuracy:  0.5563227984975528
Iteration: 1094
    Time:  91.467
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  1.4977145044843179
    Accuracy:  0.5527563835034336
Iteration: 1095
Could not find child with move:  1 6
An Exception was thrown
Iteration: 1096
    Time:  78.224
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  1.2485486410912967
    Accuracy:  0.5349053382403157
Iteration: 1097
    Time:  81.416
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.7983460876516918
    Accuracy:  0.4770838866335319
Iteration: 1098
    Time:  94.629
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.865057100795227
    Accuracy:  0.5416967029631596
Iteration: 1099
    Time:  89.26
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.9094651157413474
    Accuracy:  0.560515233144895
Iteration: 1100
    Time:  62.461
    Number of Data points:         320
    Number of Training batches:    10 

    Loss:  0.6242950746641222
    Accuracy:  0.5607239063626361
Iteration: 1101
    Time:  97.996
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  0.6768642688996812
    Accuracy:  0.5621466783017794
Iteration: 1102
    Time:  67.426
    Number of Data points:         344
    Number of Training batches:    11 

    Loss:  1.335794201370271
    Accuracy:  0.5602686193421103
Iteration: 1103
    Time:  82.215
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.5964614764535471
    Accuracy:  0.5602496490495883
Iteration: 1104
    Time:  86.729
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.6430602495281177
    Accuracy:  0.5620897674242137
Iteration: 1105
    Time:  104.468
    Number of Data points:         520
    Number of Training batches:    17 

    Loss:  1.3477358028720705
    Accuracy:  0.5547482642182342
Iteration: 1106
    Time:  102.467
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  1.2176623297222082
    Accuracy:  0.5309215768107144
Iteration: 1107
    Time:  94.695
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.741248702214406
    Accuracy:  0.5564745608377282
Iteration: 1108
    Time:  97.619
    Number of Data points:         512
    Number of Training batches:    16 

    Loss:  0.6872321884286258
    Accuracy:  0.562241529764389
Iteration: 1109
    Time:  95.323
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  1.0646347328020975
    Accuracy:  0.5451113556171037
Iteration: 1110
    Time:  92.848
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.0815241048037303
    Accuracy:  0.4712600068293053
Iteration: 1111
    Time:  89.0
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.8064511287872859
    Accuracy:  0.5355313578935387
Iteration: 1112
    Time:  95.865
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  0.7136759879928162
    Accuracy:  0.44879918048336304
Iteration: 1113
    Time:  82.655
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  1.099427098759154
    Accuracy:  0.5129187692074212
Iteration: 1114
    Time:  79.46
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.7223414178531287
    Accuracy:  0.5496452555298402
Iteration: 1115
    Time:  80.378
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.8307253692326767
    Accuracy:  0.5632090146830064
Iteration: 1116
    Time:  77.372
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.5867398559914867
    Accuracy:  0.5640057669689267
Iteration: 1117
    Time:  72.905
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.595306994243562
    Accuracy:  0.5640816481390143
Iteration: 1118
    Time:  68.925
    Number of Data points:         352
    Number of Training batches:    11 

    Loss:  0.6199425676411484
    Accuracy:  0.5641764996016239
Iteration: 1119
    Time:  83.503
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  1.337335399760723
    Accuracy:  0.5593390750085366
Iteration: 1120
    Time:  98.143
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  1.0277637704475298
    Accuracy:  0.48734681488788556
Iteration: 1121
    Time:  68.379
    Number of Data points:         360
    Number of Training batches:    12 

    Loss:  1.0044076545037492
    Accuracy:  0.3853625222900937
Iteration: 1122
    Time:  85.531
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  1.0495598921570188
    Accuracy:  0.507000037940585
Iteration: 1123
    Time:  72.315
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  1.0594117979250774
    Accuracy:  0.5614068368934249
Iteration: 1124
    Time:  77.488
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  0.7465242944387928
    Accuracy:  0.5647266380847593
Iteration: 1125
    Time:  94.59
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.6357031708742094
    Accuracy:  0.5640247372614485
Iteration: 1126
    Time:  71.006
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  1.3007125625798568
    Accuracy:  0.564555905452062
Iteration: 1127
    Time:  83.454
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.6360018757028896
    Accuracy:  0.5644800242819744
Iteration: 1128
    Time:  87.025
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.6531965875952875
    Accuracy:  0.5641764996016239
Iteration: 1129
    Time:  82.71
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.5746784542803195
    Accuracy:  0.5641954698941458
Iteration: 1130
    Time:  88.545
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  1.4458095440747036
    Accuracy:  0.5643851728193648
Iteration: 1131
    Time:  86.338
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.3467936747321345
    Accuracy:  0.5650681033501537
Iteration: 1132
    Time:  103.041
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  1.4229728632414982
    Accuracy:  0.5650301627651099
Iteration: 1133
    Time:  71.081
    Number of Data points:         368
    Number of Training batches:    12 

    Loss:  0.6725006852134111
    Accuracy:  0.5653336874454604
Iteration: 1134
    Time:  67.79
    Number of Data points:         368
    Number of Training batches:    12 

    Loss:  0.7393200956538056
    Accuracy:  0.5649163410099783
Iteration: 1135
    Time:  90.734
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.6080585423599264
    Accuracy:  0.5643851728193648
Iteration: 1136
    Time:  78.243
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.6107800455037632
    Accuracy:  0.5642903213567553
Iteration: 1137
    Time:  80.777
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.407763164337808
    Accuracy:  0.5648025192548469
Iteration: 1138
    Time:  99.992
    Number of Data points:         504
    Number of Training batches:    16 

    Loss:  1.2515553450970347
    Accuracy:  0.5634556284857912
Iteration: 1139
    Time:  82.903
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.9925963393694756
    Accuracy:  0.5139621352961262
Iteration: 1140
    Time:  91.171
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  1.4350676616480273
    Accuracy:  0.5138672838335168
Iteration: 1141
    Time:  93.512
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.8562791573876642
    Accuracy:  0.5566452934704254
Iteration: 1142
    Time:  93.077
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.6343124847324416
    Accuracy:  0.5640247372614485
Iteration: 1143
    Time:  85.607
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.749348387172061
    Accuracy:  0.5649922221800661
Iteration: 1144
    Time:  98.313
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.6160348139281117
    Accuracy:  0.564366202526843
Iteration: 1145
    Time:  89.492
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.6684533037249094
    Accuracy:  0.5643282619417992
Iteration: 1146
    Time:  79.592
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.5842888342979535
    Accuracy:  0.5642523807717115
Iteration: 1147
    Time:  69.76
    Number of Data points:         368
    Number of Training batches:    12 

    Loss:  0.6603504029665744
    Accuracy:  0.5641195887240581
Iteration: 1148
    Time:  95.69
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  1.3806040577536254
    Accuracy:  0.5645179648670182
Iteration: 1149
    Time:  88.668
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.5816676754484817
    Accuracy:  0.5643282619417992
Iteration: 1150
    Time:  69.722
    Number of Data points:         344
    Number of Training batches:    11 

    Loss:  1.4663206209689008
    Accuracy:  0.564555905452062
Iteration: 1151
    Time:  98.179
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  0.6210401533094007
    Accuracy:  0.5642903213567553
Iteration: 1152
    Time:  80.16
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.2785290869788482
    Accuracy:  0.5643851728193648
Iteration: 1153
    Time:  74.84
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  1.061625921416766
    Accuracy:  0.5581818871647001
Iteration: 1154
    Time:  81.899
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.9023897346008252
    Accuracy:  0.5376750009485146
Iteration: 1155
    Time:  86.645
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.7382423977926328
    Accuracy:  0.5532685814015252
Iteration: 1156
    Time:  84.51
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.9000889698924998
    Accuracy:  0.5612740448457715
Iteration: 1157
    Time:  68.708
    Number of Data points:         360
    Number of Training batches:    12 

    Loss:  1.25854187439069
    Accuracy:  0.5617293318662974
Iteration: 1158
    Time:  86.133
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.5859158286072239
    Accuracy:  0.5619000644989945
Iteration: 1159
    Time:  83.313
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.7658147201803116
    Accuracy:  0.5633987176082256
Iteration: 1160
    Time:  88.253
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  1.5096275819345135
    Accuracy:  0.5632090146830064
Iteration: 1161
    Time:  95.031
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  1.226671191662506
    Accuracy:  0.5609705201654209
Iteration: 1162
Could not find child with move:  2 6
An Exception was thrown
Iteration: 1163
    Time:  84.488
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.699725937512379
    Accuracy:  0.561368896308381
Iteration: 1164
    Time:  67.582
    Number of Data points:         344
    Number of Training batches:    11 

    Loss:  1.211699209290728
    Accuracy:  0.5604393519748074
Iteration: 1165
    Time:  80.538
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  0.7185810642026939
    Accuracy:  0.5614637477709906
Iteration: 1166
    Time:  72.18
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  1.4010847763061827
    Accuracy:  0.5617293318662974
Iteration: 1167
    Time:  67.265
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  1.4714077383559336
    Accuracy:  0.5604203816822856
Iteration: 1168
    Time:  77.051
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.4619180248251609
    Accuracy:  0.5602117084645445
Iteration: 1169
    Time:  81.541
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  1.1017650098984146
    Accuracy:  0.5306559927154076
Iteration: 1170
    Time:  87.785
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.9815156000370573
    Accuracy:  0.43072049170998217
Iteration: 1171
    Time:  91.327
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  1.4706282330633378
    Accuracy:  0.4465227453807338
Iteration: 1172
    Time:  65.718
    Number of Data points:         368
    Number of Training batches:    12 

    Loss:  1.0654970908147876
    Accuracy:  0.5400842280987973
Iteration: 1173
    Time:  91.737
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  0.8283143047066153
    Accuracy:  0.5626209356148272
Iteration: 1174
    Time:  92.013
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  0.668715108538272
    Accuracy:  0.5626019653223052
Iteration: 1175
    Time:  77.363
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  1.481693906129555
    Accuracy:  0.5627347573699586
Iteration: 1176
    Time:  92.786
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  0.7759460525644687
    Accuracy:  0.5637401828736199
Iteration: 1177
    Time:  62.448
    Number of Data points:         344
    Number of Training batches:    11 

    Loss:  1.236355301380605
    Accuracy:  0.5626968167849148
Iteration: 1178
    Time:  78.895
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.1868511420224095
    Accuracy:  0.5603445005121979
Iteration: 1179
    Time:  100.282
    Number of Data points:         512
    Number of Training batches:    16 

    Loss:  1.4332497339061219
    Accuracy:  0.559263193838449
Iteration: 1180
    Time:  96.431
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.8840432058712782
    Accuracy:  0.5630572523428311
Iteration: 1181
    Time:  70.536
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.6522038032006873
    Accuracy:  0.5633418067306598
Iteration: 1182
    Time:  81.978
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.6919016089496296
    Accuracy:  0.5635504799484008
Iteration: 1183
    Time:  91.167
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.3531991829548808
    Accuracy:  0.5631331335129187
Iteration: 1184
    Time:  102.636
    Number of Data points:         520
    Number of Training batches:    17 

    Loss:  1.2328062015776926
    Accuracy:  0.5620328565466479
Iteration: 1185
    Time:  75.078
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  0.8741290130862116
    Accuracy:  0.5641006184315362
Iteration: 1186
    Time:  77.697
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.7800295206888408
    Accuracy:  0.5640816481390143
Iteration: 1187
    Time:  77.989
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  1.263726431894541
    Accuracy:  0.56413855901658
Iteration: 1188
    Time:  74.156
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.7460261140311992
    Accuracy:  0.5639678263838829
Iteration: 1189
    Time:  97.856
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  1.208126237151598
    Accuracy:  0.5632090146830064
Iteration: 1190
    Time:  81.772
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.7738747263947485
    Accuracy:  0.5643851728193648
Iteration: 1191
    Time:  91.344
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  1.4606765428269128
    Accuracy:  0.5641764996016239
Iteration: 1192
    Time:  88.764
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.7585595875308812
    Accuracy:  0.5640057669689267
Iteration: 1193
    Time:  83.848
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.1598917017208614
    Accuracy:  0.5635884205334446
Iteration: 1194
    Time:  90.387
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.8182897604984893
    Accuracy:  0.5642334104791896
Iteration: 1195
    Time:  85.494
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.7210524025939807
    Accuracy:  0.5643092916492772
Iteration: 1196
    Time:  77.895
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  0.6563124455264949
    Accuracy:  0.5640626778464924
Iteration: 1197
    Time:  90.15
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.6138104073223051
    Accuracy:  0.5640626778464924
Iteration: 1198
    Time:  82.521
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  1.3140049591126026
    Accuracy:  0.5641195887240581
Iteration: 1199
    Time:  78.25
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  1.193282923933991
    Accuracy:  0.5643851728193648
Iteration: 1200
    Time:  79.366
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.755348557309747
    Accuracy:  0.5640816481390143
Iteration: 1201
Could not find child with move:  2 0
An Exception was thrown
Iteration: 1202
    Time:  76.373
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  1.1394629321883
    Accuracy:  0.5625260841522176
Iteration: 1203
    Time:  89.503
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.125296128301536
    Accuracy:  0.5358728231589331
Iteration: 1204
    Time:  87.218
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.001854317256811
    Accuracy:  0.42269605797321397
Iteration: 1205
    Time:  82.324
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.8622926510113657
    Accuracy:  0.39611867815001706
Iteration: 1206
    Time:  78.257
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  0.7569716988683355
    Accuracy:  0.3849831164396555
Iteration: 1207
    Time:  93.862
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.6630523701424037
    Accuracy:  0.38264977045946047
Iteration: 1208
    Time:  91.5
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  1.4437891636499307
    Accuracy:  0.3843001859088667
Iteration: 1209
    Time:  103.417
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  1.3747450975960553
    Accuracy:  0.3997609743142239
Iteration: 1210
    Time:  97.974
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  0.9760601234043915
    Accuracy:  0.5205637970937512
Iteration: 1211
    Time:  85.102
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.1207804616956103
    Accuracy:  0.40907538794248205
Iteration: 1212
    Time:  85.912
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.7980222869780959
    Accuracy:  0.38921349167204156
Iteration: 1213
    Time:  75.008
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.1368122112722094
    Accuracy:  0.4236635428918314
Iteration: 1214
    Time:  73.773
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.9843404916549717
    Accuracy:  0.5175095799977235
Iteration: 1215
    Time:  102.775
    Number of Data points:         520
    Number of Training batches:    17 

    Loss:  0.9117312390083253
    Accuracy:  0.3922487384755473
Iteration: 1216
Could not find child with move:  8 4
An Exception was thrown
Iteration: 1217
    Time:  96.924
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  0.6946739379179403
    Accuracy:  0.3843191562013886
Iteration: 1218
    Time:  94.317
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.1871447801041197
    Accuracy:  0.41027051637136247
Iteration: 1219
    Time:  77.461
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.6942207224828615
    Accuracy:  0.3890806996243882
Iteration: 1220
    Time:  97.005
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  1.440568643381246
    Accuracy:  0.39359562924460295
Iteration: 1221
    Time:  96.245
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.7122084521812534
    Accuracy:  0.3843191562013886
Iteration: 1222
    Time:  89.748
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.6254634796120754
    Accuracy:  0.3829343248472891
Iteration: 1223
    Time:  73.274
    Number of Data points:         368
    Number of Training batches:    12 

    Loss:  1.289307049199839
    Accuracy:  0.38629206662366733
Iteration: 1224
    Time:  94.883
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.6496460615194805
    Accuracy:  0.38257388928937286
Iteration: 1225
    Time:  76.518
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  1.3080719034347084
    Accuracy:  0.3934818074894715
Iteration: 1226
    Time:  80.731
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.6350394719414131
    Accuracy:  0.38752513563759156
Iteration: 1227
    Time:  79.169
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  1.2237531126391492
    Accuracy:  0.421197404863983
Iteration: 1228
    Time:  86.943
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  1.4414167642228497
    Accuracy:  0.42148195925181164
Iteration: 1229
    Time:  84.742
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  1.0263648575826927
    Accuracy:  0.5
Iteration: 1230
    Time:  110.739
    Number of Data points:         520
    Number of Training batches:    17 

    Loss:  1.4274308681556318
    Accuracy:  0.5036422961642069
Iteration: 1231
    Time:  91.434
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  0.8262975260761743
    Accuracy:  0.5587889365254012
Iteration: 1232
    Time:  77.298
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.8010315059774453
    Accuracy:  0.5634745987783132
Iteration: 1233
    Time:  90.614
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  1.2127176411943392
    Accuracy:  0.5468945631141632
Iteration: 1234
    Time:  83.101
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.8016558537160237
    Accuracy:  0.5645179648670182
Iteration: 1235
    Time:  71.54
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  1.287470001355362
    Accuracy:  0.5566263231779034
Iteration: 1236
    Time:  90.086
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.0731379971792387
    Accuracy:  0.47300527374132106
Iteration: 1237
    Time:  86.507
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.9059755547652105
    Accuracy:  0.5452062070797131
Iteration: 1238
    Time:  82.469
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.8708137798970543
    Accuracy:  0.564783548962325
Iteration: 1239
    Time:  66.317
    Number of Data points:         360
    Number of Training batches:    12 

    Loss:  1.0880590991961776
    Accuracy:  0.5558106005994612
Iteration: 1240
    Time:  91.994
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.8445473846622952
    Accuracy:  0.5649163410099783
Iteration: 1241
    Time:  86.522
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.7524613270298781
    Accuracy:  0.5638729749212733
Iteration: 1242
    Time:  82.234
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.6550602924526242
    Accuracy:  0.5640247372614485
Iteration: 1243
    Time:  77.744
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.6396618956109928
    Accuracy:  0.5639678263838829
Iteration: 1244
    Time:  92.911
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.6023309543031977
    Accuracy:  0.5639867966764047
Iteration: 1245
    Time:  108.194
    Number of Data points:         536
    Number of Training batches:    17 

    Loss:  1.4706865360843795
    Accuracy:  0.5639678263838829
Iteration: 1246
    Time:  89.321
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  0.6325587969089722
    Accuracy:  0.5639867966764047
Iteration: 1247
    Time:  90.719
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.6004884604451882
    Accuracy:  0.5640057669689267
Iteration: 1248
    Time:  89.376
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  1.3309953606925415
    Accuracy:  0.5648784004249345
Iteration: 1249
    Time:  84.16
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.6424745325380593
    Accuracy:  0.564555905452062
Iteration: 1250
    Time:  77.662
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  1.3949638334990613
    Accuracy:  0.5651439845202413
Iteration: 1251
    Time:  87.547
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  1.4758411617172036
    Accuracy:  0.5659786773912053
Iteration: 1252
    Time:  83.024
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  1.174249253181972
    Accuracy:  0.562867549417612
Iteration: 1253
    Time:  84.233
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  1.0614050618826225
    Accuracy:  0.5168266494669348
Iteration: 1254
    Time:  106.17
    Number of Data points:         512
    Number of Training batches:    16 

    Loss:  0.769005551456144
    Accuracy:  0.5632279849755283
Iteration: 1255
    Time:  88.139
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  1.4426224475958631
    Accuracy:  0.561368896308381
Iteration: 1256
    Time:  83.037
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.870991963088245
    Accuracy:  0.4812004401107865
Iteration: 1257
    Time:  79.669
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.856337418500128
    Accuracy:  0.5480517509579997
Iteration: 1258
    Time:  79.983
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  1.1174405220082766
    Accuracy:  0.47734947072883865
Iteration: 1259
    Time:  85.481
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.752713743616548
    Accuracy:  0.4062108737716736
Iteration: 1260
    Time:  91.428
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.7126254219501361
    Accuracy:  0.3860264825283606
Iteration: 1261
    Time:  79.824
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  1.3396243126560228
    Accuracy:  0.4002542019197936
Iteration: 1262
    Time:  60.86
    Number of Data points:         328
    Number of Training batches:    11 

    Loss:  0.7776446021675281
    Accuracy:  0.3864058883787988
Iteration: 1263
    Time:  90.453
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.6197733285622515
    Accuracy:  0.38420533444625715
Iteration: 1264
    Time:  94.958
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  1.091473407310109
    Accuracy:  0.42383427552452857
Iteration: 1265
    Time:  81.229
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.6715833094490719
    Accuracy:  0.39904010319839134
Iteration: 1266
    Time:  71.978
    Number of Data points:         368
    Number of Training batches:    12 

    Loss:  1.1289203566451131
    Accuracy:  0.4767803619531813
Iteration: 1267
    Time:  64.007
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  0.9160910797878529
    Accuracy:  0.39750350950411656
Iteration: 1268
    Time:  98.517
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.8251928963383132
    Accuracy:  0.4905717646166104
Iteration: 1269
    Time:  67.835
    Number of Data points:         360
    Number of Training batches:    12 

    Loss:  0.6892779332825404
    Accuracy:  0.45219486284478505
Iteration: 1270
    Time:  69.026
    Number of Data points:         368
    Number of Training batches:    12 

    Loss:  1.1667981085191619
    Accuracy:  0.5417536138407254
Iteration: 1271
    Time:  87.7
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.698860044821199
    Accuracy:  0.5598133323215844
Iteration: 1272
    Time:  92.942
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.7656408234177109
    Accuracy:  0.48379937018628827
Iteration: 1273
    Time:  94.315
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  0.6333230263036865
    Accuracy:  0.5209432029441894
Iteration: 1274
    Time:  84.795
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.7369348050482112
    Accuracy:  0.5568539666881663
Iteration: 1275
    Time:  90.699
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.5882350495077687
    Accuracy:  0.5590734909132299
Iteration: 1276
    Time:  92.551
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  1.4872233057542856
    Accuracy:  0.5552414918238039
Iteration: 1277
    Time:  79.483
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  0.9244598872142706
    Accuracy:  0.4900026558409531
Iteration: 1278
    Time:  91.197
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.9520206295934159
    Accuracy:  0.5587130553553136
Iteration: 1279
    Time:  73.214
    Number of Data points:         368
    Number of Training batches:    12 

    Loss:  0.5975672973865896
    Accuracy:  0.560534203437417
Iteration: 1280
    Time:  81.932
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  1.2298285801101698
    Accuracy:  0.5410327427248928
Iteration: 1281
    Time:  102.783
    Number of Data points:         504
    Number of Training batches:    16 

    Loss:  1.240217520380497
    Accuracy:  0.47099442273399855
Iteration: 1282
    Time:  92.831
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  1.4611226970415685
    Accuracy:  0.46513260234472814
Iteration: 1283
Could not find child with move:  2 4
An Exception was thrown
Iteration: 1284
    Time:  102.473
    Number of Data points:         504
    Number of Training batches:    16 

    Loss:  0.6490423403775671
    Accuracy:  0.41395075312061314
Iteration: 1285
    Time:  88.718
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.252170013349373
    Accuracy:  0.470899571271389
Iteration: 1286
    Time:  76.722
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.624494276621576
    Accuracy:  0.45115149675607996
Iteration: 1287
    Time:  94.423
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  1.467158049507611
    Accuracy:  0.45283985279053
Iteration: 1288
    Time:  93.697
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.6788976848401252
    Accuracy:  0.39498046059870245
Iteration: 1289
    Time:  75.812
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  0.91575238375447
    Accuracy:  0.445403498121941
Iteration: 1290
    Time:  73.223
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  0.6656375659598599
    Accuracy:  0.41892096976135373
Iteration: 1291
    Time:  95.782
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.650234221437233
    Accuracy:  0.39708616306863453
Iteration: 1292
    Time:  81.61
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.6479360715715635
    Accuracy:  0.3897826004476989
Iteration: 1293
    Time:  80.464
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.8014037227827809
    Accuracy:  0.38280153279963575
Iteration: 1294
    Time:  79.285
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.4723276463424182
    Accuracy:  0.38329476040520544
Iteration: 1295
    Time:  95.152
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  1.4745999205476938
    Accuracy:  0.38416739386121335
Iteration: 1296
    Time:  84.127
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.3622349402049734
    Accuracy:  0.38669044276662745
Iteration: 1297
    Time:  77.745
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  0.5877648180017464
    Accuracy:  0.3859885419433168
Iteration: 1298
    Time:  94.757
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.6520999473206774
    Accuracy:  0.38327579011268353
Iteration: 1299
    Time:  88.334
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  1.4534581697155717
    Accuracy:  0.3844140076639982
Iteration: 1300
    Time:  91.895
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.5680662740575397
    Accuracy:  0.38401563152103807
Iteration: 1301
    Time:  77.722
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.660503881316029
    Accuracy:  0.3832188792351178
Iteration: 1302
    Time:  101.377
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.5626775776744687
    Accuracy:  0.38314299806503016
Iteration: 1303
    Time:  92.571
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  1.5196335306144335
    Accuracy:  0.38331373069772734
Iteration: 1304
    Time:  98.78
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  1.5075437142904053
    Accuracy:  0.3841104829836476
Iteration: 1305
    Time:  86.19
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.5678726656934298
    Accuracy:  0.3837500474257313
Iteration: 1306
    Time:  107.932
    Number of Data points:         504
    Number of Training batches:    16 

    Loss:  0.5740550634987076
    Accuracy:  0.3833516712827712
Iteration: 1307
    Time:  79.426
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.5157782460845997
    Accuracy:  0.3837690177182532
Iteration: 1308
    Time:  75.938
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  0.6575463770653539
    Accuracy:  0.382972265432333
Iteration: 1309
    Time:  74.528
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  0.5722715947058636
    Accuracy:  0.3829153545547672
Iteration: 1310
    Time:  85.443
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.5131177961923195
    Accuracy:  0.382972265432333
Iteration: 1311
    Time:  81.983
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  1.5079031553252211
    Accuracy:  0.38327579011268353
Iteration: 1312
    Time:  78.168
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  1.435314126408806
    Accuracy:  0.38522973024244034
Iteration: 1313
    Time:  94.868
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  1.5068921753682205
    Accuracy:  0.38720264066471904
Iteration: 1314
    Time:  69.327
    Number of Data points:         344
    Number of Training batches:    11 

    Loss:  0.6164858794233647
    Accuracy:  0.38562810638540046
Iteration: 1315
    Time:  91.481
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  1.335870269871219
    Accuracy:  0.3992298061236104
Iteration: 1316
    Time:  96.38
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.6160747940711108
    Accuracy:  0.39306446105398946
Iteration: 1317
    Time:  66.396
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  1.4473431942168293
    Accuracy:  0.4008991918655386
Iteration: 1318
    Time:  103.583
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  1.0022934815385982
    Accuracy:  0.48937663618773003
Iteration: 1319
    Time:  74.071
    Number of Data points:         368
    Number of Training batches:    12 

    Loss:  0.9724501554783006
    Accuracy:  0.5377698524111242
Iteration: 1320
    Time:  87.701
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.9482660452506366
    Accuracy:  0.48385628106385403
Iteration: 1321
    Time:  70.953
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  0.8127745980571109
    Accuracy:  0.5274689835717267
Iteration: 1322
    Time:  76.789
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.7438642253344299
    Accuracy:  0.545889137610502
Iteration: 1323
    Time:  92.806
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.7458971285783921
    Accuracy:  0.558637174185226
Iteration: 1324
    Time:  98.271
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  1.4363320631186338
    Accuracy:  0.5533634328641348
Iteration: 1325
    Time:  85.719
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.2636305215015213
    Accuracy:  0.5258754789998862
Iteration: 1326
    Time:  83.988
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.9194463645884715
    Accuracy:  0.5564745608377282
Iteration: 1327
    Time:  83.661
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.8284360348981187
    Accuracy:  0.524016390332739
Iteration: 1328
    Time:  86.424
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  1.024373983302405
    Accuracy:  0.5604962628523732
Iteration: 1329
    Time:  100.509
    Number of Data points:         504
    Number of Training batches:    16 

    Loss:  0.7733616928688555
    Accuracy:  0.5232575786318625
Iteration: 1330
    Time:  73.393
    Number of Data points:         368
    Number of Training batches:    12 

    Loss:  0.6742520245433793
    Accuracy:  0.5353226846757977
Iteration: 1331
    Time:  78.045
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  1.0463081095355102
    Accuracy:  0.4931137838145464
Iteration: 1332
    Time:  94.673
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  1.2040823291413743
    Accuracy:  0.42284782031338924
Iteration: 1333
    Time:  84.458
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.7610219946357619
    Accuracy:  0.3914330158971051
Iteration: 1334
    Time:  83.531
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.6359671063065558
    Accuracy:  0.3874113138824601
Iteration: 1335
    Time:  93.433
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.9918412075909415
    Accuracy:  0.42523807717115
Iteration: 1336
    Time:  77.11
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.6814597180290256
    Accuracy:  0.40296695375042685
Iteration: 1337
    Time:  83.644
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.9296512558658707
    Accuracy:  0.49385362522290094
Iteration: 1338
    Time:  63.269
    Number of Data points:         336
    Number of Training batches:    11 

    Loss:  0.8586879110876378
    Accuracy:  0.5319839131919414
Iteration: 1339
    Time:  80.102
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.6760403615317377
    Accuracy:  0.5445422468414463
Iteration: 1340
    Time:  88.525
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.6939989160519838
    Accuracy:  0.5591493720833175
Iteration: 1341
    Time:  78.775
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.6166441684590406
    Accuracy:  0.5630382820503093
Iteration: 1342
    Time:  98.694
    Number of Data points:         504
    Number of Training batches:    16 

    Loss:  1.4636676214190152
    Accuracy:  0.5583336495048754
Iteration: 1343
    Time:  79.504
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.432533651167233
    Accuracy:  0.5502523048905414
Iteration: 1344
    Time:  101.022
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  1.042864239611545
    Accuracy:  0.469192244944417
Iteration: 1345
    Time:  100.411
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.844135610821923
    Accuracy:  0.40605911143149825
Iteration: 1346
    Time:  94.493
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.7889697240378701
    Accuracy:  0.38314299806503016
Iteration: 1347
    Time:  78.379
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.6162060144745636
    Accuracy:  0.3828205030921577
Iteration: 1348
    Time:  72.489
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  1.4844547541165365
    Accuracy:  0.38318093865007397
Iteration: 1349
    Time:  95.074
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.3218152121470255
    Accuracy:  0.38811321470577076
Iteration: 1350
    Time:  79.898
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.9374955365265811
    Accuracy:  0.43686686648708123
Iteration: 1351
    Time:  90.115
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.7305625994284133
    Accuracy:  0.4002921425048374
Iteration: 1352
    Time:  94.971
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.6507008747101928
    Accuracy:  0.3918313920400653
Iteration: 1353
    Time:  82.628
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.6631058502928321
    Accuracy:  0.38720264066471904
Iteration: 1354
    Time:  87.963
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  1.1826038355173158
    Accuracy:  0.42984785825397426
Iteration: 1355
    Time:  86.689
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.0145297798204949
    Accuracy:  0.38665250218158365
Iteration: 1356
    Time:  75.211
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  0.6256604486321602
    Accuracy:  0.3853814925826156
Iteration: 1357
    Time:  92.595
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  1.4779155984906434
    Accuracy:  0.38722161095724095
Iteration: 1358
    Time:  89.044
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  1.4459872416150046
    Accuracy:  0.39198315438024056
Iteration: 1359
    Time:  93.699
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.6350198667356649
    Accuracy:  0.3860644231134044
Iteration: 1360
    Time:  108.843
    Number of Data points:         544
    Number of Training batches:    17 

    Loss:  1.465211127064739
    Accuracy:  0.38963083810752364
Iteration: 1361
    Time:  90.575
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.6224277317200915
    Accuracy:  0.3860264825283606
Iteration: 1362
    Time:  104.637
    Number of Data points:         528
    Number of Training batches:    17 

    Loss:  1.4678586680574124
    Accuracy:  0.3893652540122169
Iteration: 1363
    Time:  81.118
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.6119111880429203
    Accuracy:  0.3867663239367151
Iteration: 1364
Could not find child with move:  3 1
An Exception was thrown
Iteration: 1365
    Time:  75.508
    Number of Data points:         360
    Number of Training batches:    12 

    Loss:  0.6567100367199936
    Accuracy:  0.38412945327616954
Iteration: 1366
    Time:  93.854
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  1.275805455078335
    Accuracy:  0.39397503509504117
Iteration: 1367
    Time:  62.437
    Number of Data points:         320
    Number of Training batches:    10 

    Loss:  1.176463698146106
    Accuracy:  0.41899685093144134
Iteration: 1368
    Time:  79.203
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  1.0764723965660858
    Accuracy:  0.48573434002352317
Iteration: 1369
    Time:  73.016
    Number of Data points:         352
    Number of Training batches:    11 

    Loss:  0.7425663495002023
    Accuracy:  0.5125773039420268
Iteration: 1370
    Time:  97.115
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  0.9024431630843207
    Accuracy:  0.4270023143756877
Iteration: 1371
    Time:  77.828
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.9711126708250158
    Accuracy:  0.5112683537580149
Iteration: 1372
    Time:  76.938
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  0.7593587253254598
    Accuracy:  0.5313389232461965
Iteration: 1373
    Time:  95.953
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  1.29323308624802
    Accuracy:  0.5502523048905414
Iteration: 1374
    Time:  70.248
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  0.9210895475499492
    Accuracy:  0.5216830443525439
Iteration: 1375
    Time:  82.893
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.9437065518366602
    Accuracy:  0.5582387980422658
Iteration: 1376
    Time:  80.097
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.6798466066982544
    Accuracy:  0.5634366581932694
Iteration: 1377
    Time:  85.928
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.593952453201651
    Accuracy:  0.5634176879007474
Iteration: 1378
    Time:  76.206
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  1.4541964985566704
    Accuracy:  0.5633607770231817
Iteration: 1379
    Time:  99.329
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  1.4968890529449967
    Accuracy:  0.5628106385400463
Iteration: 1380
    Time:  87.472
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.5816711172847492
    Accuracy:  0.5633607770231817
Iteration: 1381
    Time:  75.833
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  1.4539921359537673
    Accuracy:  0.5612740448457715
Iteration: 1382
    Time:  99.226
    Number of Data points:         520
    Number of Training batches:    17 

    Loss:  1.515460109774392
    Accuracy:  0.5593201047160147
Iteration: 1383
    Time:  70.491
    Number of Data points:         368
    Number of Training batches:    12 

    Loss:  0.634998373398741
    Accuracy:  0.5620897674242137
Iteration: 1384
    Time:  103.559
    Number of Data points:         528
    Number of Training batches:    17 

    Loss:  1.4916476505840888
    Accuracy:  0.5592821641309709
Iteration: 1385
    Time:  91.707
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.6041814329316767
    Accuracy:  0.5617293318662974
Iteration: 1386
    Time:  77.976
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.6154499796313166
    Accuracy:  0.5633228364381379
Iteration: 1387
    Time:  89.054
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.4859305117017982
    Accuracy:  0.5616534506962098
Iteration: 1388
    Time:  77.993
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  1.3176177235652438
    Accuracy:  0.552661532040824
Iteration: 1389
    Time:  106.025
    Number of Data points:         512
    Number of Training batches:    16 

    Loss:  0.6524804814763491
    Accuracy:  0.561805213036385
Iteration: 1390
    Time:  73.372
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.3449155137283484
    Accuracy:  0.5535721060818758
Iteration: 1391
    Time:  97.801
    Number of Data points:         520
    Number of Training batches:    17 

    Loss:  1.4643642620788482
    Accuracy:  0.5508593542512426
Iteration: 1392
    Time:  97.482
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  0.6522900911161241
    Accuracy:  0.5571005804909511
Iteration: 1393
    Time:  88.627
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.609024264502746
    Accuracy:  0.5600409758318473
Iteration: 1394
    Time:  90.338
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.6001656400427627
    Accuracy:  0.5610274310429867
Iteration: 1395
    Time:  112.373
    Number of Data points:         520
    Number of Training batches:    17 

    Loss:  1.2078420452253347
    Accuracy:  0.5367833971999848
Iteration: 1396
    Time:  87.005
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.7150495648499742
    Accuracy:  0.556512501422772
Iteration: 1397
    Time:  77.858
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.6144705594822337
    Accuracy:  0.5590545206207079
Iteration: 1398
    Time:  74.246
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  1.0467569317958985
    Accuracy:  0.5387373373297416
Iteration: 1399
    Time:  90.014
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.8772146346417055
    Accuracy:  0.5581818871647001
Iteration: 1400
    Time:  71.271
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  0.5938321118559781
    Accuracy:  0.5588079068179231
Iteration: 1401
    Time:  87.062
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.610997238636282
    Accuracy:  0.5601358272944569
Iteration: 1402
    Time:  98.747
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  0.6656646728554519
    Accuracy:  0.5634745987783132
Iteration: 1403
    Time:  84.242
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.5052790393322115
    Accuracy:  0.5634366581932694
Iteration: 1404
    Time:  99.601
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  0.6112256153493367
    Accuracy:  0.5636643017035323
Iteration: 1405
    Time:  97.346
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  0.5901620948612316
    Accuracy:  0.5637591531661418
Iteration: 1406
    Time:  74.146
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  1.4492552925390898
    Accuracy:  0.5637781234586637
Iteration: 1407
    Time:  99.244
    Number of Data points:         504
    Number of Training batches:    16 

    Loss:  1.2937865212711634
    Accuracy:  0.5571954319535607
Iteration: 1408
    Time:  83.52
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.1422208552237318
    Accuracy:  0.5298971810145312
Iteration: 1409
    Time:  100.913
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  0.7981734597425183
    Accuracy:  0.5591493720833175
Iteration: 1410
    Time:  93.725
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.8538585446619353
    Accuracy:  0.5389460105474826
Iteration: 1411
    Time:  94.115
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.7984542677869733
    Accuracy:  0.506374018287362
Iteration: 1412
    Time:  78.93
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.9856714075214978
    Accuracy:  0.5391167431801799
Iteration: 1413
    Time:  93.601
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.7312556294159295
    Accuracy:  0.5561900064498995
Iteration: 1414
    Time:  88.343
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  1.0031903474430361
    Accuracy:  0.5217968661076754
Iteration: 1415
    Time:  92.642
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.7936815750123704
    Accuracy:  0.5444094547937929
Iteration: 1416
    Time:  89.521
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  1.50423745125603
    Accuracy:  0.5419433167659445
Iteration: 1417
    Time:  101.171
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  0.6569432351535518
    Accuracy:  0.5576507189740866
Iteration: 1418
    Time:  77.053
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  1.0977746163944897
    Accuracy:  0.5315665667564594
Iteration: 1419
    Time:  78.389
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.9603760287679186
    Accuracy:  0.4822058656144478
Iteration: 1420
    Time:  85.944
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.8838648878929966
    Accuracy:  0.5290435178510453
Iteration: 1421
    Time:  98.83
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  1.0233774346507263
    Accuracy:  0.45957430663580834
Iteration: 1422
    Time:  91.606
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.6903529661698067
    Accuracy:  0.4121485753310316
Iteration: 1423
    Time:  86.914
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.2260471026211612
    Accuracy:  0.48254733087984214
Iteration: 1424
    Time:  74.24
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.6602895919510545
    Accuracy:  0.5052358007360473
Iteration: 1425
    Time:  94.204
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.9416505423463121
    Accuracy:  0.4339264711461851
Iteration: 1426
    Time:  87.571
    Number of Data points:         504
    Number of Training batches:    16 

    Loss:  1.492761588586508
    Accuracy:  0.444777478468718
Iteration: 1427
    Time:  85.47
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.8360637129314749
    Accuracy:  0.503831999089426
Iteration: 1428
    Time:  71.061
    Number of Data points:         360
    Number of Training batches:    12 

    Loss:  0.6828122365922472
    Accuracy:  0.46991311606024966
Iteration: 1429
    Time:  87.689
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.6889196250239704
    Accuracy:  0.43320560003035247
Iteration: 1430
    Time:  89.218
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.6155678996362649
    Accuracy:  0.4185036233258717
Iteration: 1431
    Time:  99.239
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  0.7361768059925676
    Accuracy:  0.391888302917631
Iteration: 1432
    Time:  79.935
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.5821873296187066
    Accuracy:  0.39012406571309327
Iteration: 1433
    Time:  86.515
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  1.2094020826862395
    Accuracy:  0.407823348636036
Iteration: 1434
    Time:  94.15
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.6144198627103834
    Accuracy:  0.3982812914975149
Iteration: 1435
    Time:  77.636
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  1.5019711366673172
    Accuracy:  0.40209432029441894
Iteration: 1436
    Time:  109.885
    Number of Data points:         552
    Number of Training batches:    18 

    Loss:  0.6264490976664485
    Accuracy:  0.39393709450999737
Iteration: 1437
    Time:  111.456
    Number of Data points:         560
    Number of Training batches:    18 

    Loss:  1.487399587625665
    Accuracy:  0.4023219638046819
Iteration: 1438
    Time:  95.991
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  1.349517788575647
    Accuracy:  0.4316500360435558
Iteration: 1439
    Time:  84.654
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.7265146782141725
    Accuracy:  0.4058124976287134
Iteration: 1440
    Time:  90.828
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  1.4284480422310601
    Accuracy:  0.4251621960010623
Iteration: 1441
    Time:  82.758
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.7970612577837582
    Accuracy:  0.4895094282353834
Iteration: 1442
    Time:  96.067
    Number of Data points:         512
    Number of Training batches:    16 

    Loss:  1.499908763587753
    Accuracy:  0.4810676480631331
Iteration: 1443
    Time:  85.37
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.7160236486414286
    Accuracy:  0.44618128011533936
Iteration: 1444
    Time:  80.215
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.5829441383795932
    Accuracy:  0.4391053610046667
Iteration: 1445
    Time:  69.968
    Number of Data points:         360
    Number of Training batches:    12 

    Loss:  0.8423733953491069
    Accuracy:  0.40152521151876164
Iteration: 1446
    Time:  93.937
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.5877031423292642
    Accuracy:  0.39803467769473005
Iteration: 1447
    Time:  67.057
    Number of Data points:         344
    Number of Training batches:    11 

    Loss:  0.6788350311049942
    Accuracy:  0.3898584816177865
Iteration: 1448
    Time:  91.468
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  1.5385389463516719
    Accuracy:  0.3912053723868422
Iteration: 1449
    Time:  81.22
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  1.248054253955177
    Accuracy:  0.42377736464696286
Iteration: 1450
    Time:  84.069
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.5868452944896203
    Accuracy:  0.41829495010813067
Iteration: 1451
    Time:  85.584
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.6625602351259837
    Accuracy:  0.39551162878931595
Iteration: 1452
    Time:  94.97
    Number of Data points:         504
    Number of Training batches:    16 

    Loss:  1.542067323817262
    Accuracy:  0.3972189551162879
Iteration: 1453
    Time:  74.142
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  1.5006404095216785
    Accuracy:  0.4016959441514588
Iteration: 1454
    Time:  92.704
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  1.5163795734116299
    Accuracy:  0.4046742800773988
Iteration: 1455
    Time:  89.193
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.5938673568893761
    Accuracy:  0.3994005387563076
Iteration: 1456
    Time:  87.809
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.5580247000430898
    Accuracy:  0.398888340858216
Iteration: 1457
    Time:  100.67
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.600621751961952
    Accuracy:  0.3918313920400653
Iteration: 1458
    Time:  81.768
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  1.296737253657659
    Accuracy:  0.42624350267481126
Iteration: 1459
    Time:  89.445
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  1.1702472003222666
    Accuracy:  0.48374245930872256
Iteration: 1460
    Time:  80.237
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  0.9917262952596124
    Accuracy:  0.44067989528398527
Iteration: 1461
    Time:  91.574
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.7284256328411587
    Accuracy:  0.394866638843571
Iteration: 1462
    Time:  87.643
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.5630799041467712
    Accuracy:  0.3942595894828698
Iteration: 1463
    Time:  80.423
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.5164268854936367
    Accuracy:  0.39560648025192546
Iteration: 1464
    Time:  89.06
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.6980205311741006
    Accuracy:  0.38572295784801003
Iteration: 1465
    Time:  97.761
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  1.5487245573318682
    Accuracy:  0.38574192814053193
Iteration: 1466
    Time:  88.433
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.6042657980245598
    Accuracy:  0.38416739386121335
Iteration: 1467
    Time:  91.02
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.508136880088885
    Accuracy:  0.38574192814053193
Iteration: 1468
    Time:  80.52
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.5790116664328933
    Accuracy:  0.3854004628751375
Iteration: 1469
    Time:  91.175
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.474155316147294
    Accuracy:  0.38720264066471904
Iteration: 1470
    Time:  68.846
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  1.542502702046974
    Accuracy:  0.3873733732974162
Iteration: 1471
Could not find child with move:  5 4
An Exception was thrown
Iteration: 1472
    Time:  88.894
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  1.5393635976227744
    Accuracy:  0.3878286603179421
Iteration: 1473
    Time:  76.919
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  1.1973960963138408
    Accuracy:  0.4091133285275259
Iteration: 1474
    Time:  70.237
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  0.8263470138645305
    Accuracy:  0.3898774519103085
Iteration: 1475
    Time:  96.722
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.5597589478571285
    Accuracy:  0.38949804605987026
Iteration: 1476
    Time:  90.426
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  1.4254691074067938
    Accuracy:  0.39515119323139963
Iteration: 1477
    Time:  100.019
    Number of Data points:         504
    Number of Training batches:    16 

    Loss:  0.5689704574961246
    Accuracy:  0.3939181242174754
Iteration: 1478
    Time:  95.297
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  0.9527956115296656
    Accuracy:  0.43923815305232006
Iteration: 1479
    Time:  73.303
    Number of Data points:         352
    Number of Training batches:    11 

    Loss:  0.7971357233394262
    Accuracy:  0.4736123231020222
Iteration: 1480
    Time:  77.901
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.6157994427929362
    Accuracy:  0.4566908221724779
Iteration: 1481
    Time:  91.267
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  1.454475210415523
    Accuracy:  0.4574116932883105
Iteration: 1482
    Time:  78.522
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  0.9500710755019205
    Accuracy:  0.4077474674659483
Iteration: 1483
    Time:  85.948
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.6129708520035927
    Accuracy:  0.39556853966688166
Iteration: 1484
    Time:  81.298
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.575523738504556
    Accuracy:  0.39462002504078614
Iteration: 1485
    Time:  92.371
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.5650096019585756
    Accuracy:  0.3936904807072125
Iteration: 1486
    Time:  81.568
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  1.493433150543681
    Accuracy:  0.39746556891907275
Iteration: 1487
    Time:  109.699
    Number of Data points:         528
    Number of Training batches:    17 

    Loss:  1.1022522750401105
    Accuracy:  0.4747884812383807
Iteration: 1488
    Time:  78.569
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  1.244338748746875
    Accuracy:  0.511894373411238
Iteration: 1489
    Time:  92.581
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.8003327298540637
    Accuracy:  0.46441173122889556
Iteration: 1490
    Time:  76.584
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.876175971106253
    Accuracy:  0.508062374321812
Iteration: 1491
    Time:  83.786
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.8062815386627785
    Accuracy:  0.5364798725196342
Iteration: 1492
    Time:  88.43
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  1.3066819068046565
    Accuracy:  0.5180028076032932
Iteration: 1493
    Time:  80.899
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.8229417194450479
    Accuracy:  0.4702356110331221
Iteration: 1494
    Time:  74.735
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.6199893923485708
    Accuracy:  0.4545661494100239
Iteration: 1495
    Time:  80.421
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.5829438416569501
    Accuracy:  0.45160678377660585
Iteration: 1496
    Time:  91.969
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.5903308555309034
    Accuracy:  0.4437341123800129
Iteration: 1497
    Time:  73.593
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  0.6814513991719529
    Accuracy:  0.4224494441704291
Iteration: 1498
    Time:  85.671
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.5775340512565111
    Accuracy:  0.41899685093144134
Iteration: 1499
    Time:  101.246
    Number of Data points:         520
    Number of Training batches:    17 

    Loss:  1.468295300026864
    Accuracy:  0.41651174261107105
Iteration: 1500
    Time:  101.924
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  1.0313000467206521
    Accuracy:  0.48831429980650304
Iteration: 1501
    Time:  87.674
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.975745689620154
    Accuracy:  0.4272299578859506
Iteration: 1502
    Time:  84.187
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.5718527490202148
    Accuracy:  0.42383427552452857
Iteration: 1503
    Time:  91.703
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.5688947101783471
    Accuracy:  0.4211784345714611
Iteration: 1504
    Time:  83.774
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.5875569698557791
    Accuracy:  0.41592366354289184
Iteration: 1505
    Time:  102.157
    Number of Data points:         528
    Number of Training batches:    17 

    Loss:  0.9067951369949657
    Accuracy:  0.48689152786735973
Iteration: 1506
    Time:  103.585
    Number of Data points:         512
    Number of Training batches:    16 

    Loss:  1.5414262997286887
    Accuracy:  0.4880676860037182
Iteration: 1507
    Time:  93.698
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.6776033304676694
    Accuracy:  0.5176803126304208
Iteration: 1508
    Time:  66.816
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  0.765573784703783
    Accuracy:  0.5384907235269568
Iteration: 1509
An Exception was thrown
Iteration: 1510
    Time:  77.336
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  1.1504992000664458
    Accuracy:  0.5176803126304208
Iteration: 1511
    Time:  91.294
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.5907655512158844
    Accuracy:  0.5238835982850856
Iteration: 1512
    Time:  67.67
    Number of Data points:         360
    Number of Training batches:    12 

    Loss:  0.9027743799090118
    Accuracy:  0.5002466138027848
Iteration: 1513
    Time:  83.176
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.711986711425019
    Accuracy:  0.5294418939940054
Iteration: 1514
    Time:  87.065
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.6290997970377514
    Accuracy:  0.5390029214250484
Iteration: 1515
    Time:  84.592
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.5008761745618304
    Accuracy:  0.5354365064309292
Iteration: 1516
    Time:  88.791
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  1.4863332092288573
    Accuracy:  0.5305611412527981
Iteration: 1517
    Time:  96.246
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  1.2897448134153855
    Accuracy:  0.4999620594149562
Iteration: 1518
    Time:  78.915
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  0.719154567118468
    Accuracy:  0.4811245589406989
Iteration: 1519
    Time:  83.873
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.6559891191763179
    Accuracy:  0.46352012748036575
Iteration: 1520
    Time:  83.478
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.8909205618714454
    Accuracy:  0.48178851917896576
Iteration: 1521
    Time:  93.478
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.6437788629935296
    Accuracy:  0.45219486284478505
Iteration: 1522
    Time:  86.825
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.2026452480909815
    Accuracy:  0.47981560875668705
Iteration: 1523
    Time:  77.392
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  1.2191091248324468
    Accuracy:  0.5020108510073226
Iteration: 1524
    Time:  83.249
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.7604315520101951
    Accuracy:  0.5305232006677543
Iteration: 1525
    Time:  71.092
    Number of Data points:         352
    Number of Training batches:    11 

    Loss:  0.9592688461911123
    Accuracy:  0.5490382061691391
Iteration: 1526
    Time:  96.04
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.9478624187576176
    Accuracy:  0.5235421330196912
Iteration: 1527
    Time:  84.649
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.8770482259661908
    Accuracy:  0.5491709982167925
Iteration: 1528
    Time:  86.785
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  1.4339304250987885
    Accuracy:  0.539932465758622
Iteration: 1529
    Time:  85.489
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.6246037395025047
    Accuracy:  0.5463444246310278
Iteration: 1530
    Time:  92.964
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.8412553162560819
    Accuracy:  0.5606100846075046
Iteration: 1531
    Time:  76.308
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.7502861976926793
    Accuracy:  0.5630382820503093
Iteration: 1532
    Time:  70.576
    Number of Data points:         352
    Number of Training batches:    11 

    Loss:  0.6123004480654658
    Accuracy:  0.5633797473157036
Iteration: 1533
    Time:  87.237
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.5647061421097339
    Accuracy:  0.5634176879007474
Iteration: 1534
    Time:  86.744
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.5736350048157982
    Accuracy:  0.5636263611184884
Iteration: 1535
    Time:  84.648
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.6311288470520466
    Accuracy:  0.5639488560913609
Iteration: 1536
    Time:  75.064
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  1.4606157340052874
    Accuracy:  0.5635884205334446
Iteration: 1537
    Time:  93.789
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  1.496718970198532
    Accuracy:  0.5633607770231817
Iteration: 1538
    Time:  77.986
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  1.360217287182733
    Accuracy:  0.5625640247372614
Iteration: 1539
    Time:  88.196
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.606694695041293
    Accuracy:  0.5625260841522176
Iteration: 1540
    Time:  84.682
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.5804739273398243
    Accuracy:  0.5629244602951777
Iteration: 1541
    Time:  80.023
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.5716782385682663
    Accuracy:  0.5630572523428311
Iteration: 1542
    Time:  105.015
    Number of Data points:         520
    Number of Training batches:    17 

    Loss:  1.535238205902677
    Accuracy:  0.5627347573699586
Iteration: 1543
    Time:  66.892
    Number of Data points:         352
    Number of Training batches:    11 

    Loss:  0.5811238843616615
    Accuracy:  0.5629624008802215
Iteration: 1544
    Time:  78.822
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  1.4550558076788391
    Accuracy:  0.5626778464923929
Iteration: 1545
    Time:  88.311
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.6121662320799617
    Accuracy:  0.5630762226353531
Iteration: 1546
    Time:  97.998
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.4761616629498437
    Accuracy:  0.5626209356148272
Iteration: 1547
    Time:  95.81
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  1.4877904195880522
    Accuracy:  0.5621277080092575
Iteration: 1548
    Time:  91.265
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  1.2795439982886512
    Accuracy:  0.555222521531282
Iteration: 1549
    Time:  93.232
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.6898537245275008
    Accuracy:  0.5614447774784688
Iteration: 1550
    Time:  71.115
    Number of Data points:         368
    Number of Training batches:    12 

    Loss:  0.6370212142578007
    Accuracy:  0.5630572523428311
Iteration: 1551
    Time:  94.083
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  1.187157641154405
    Accuracy:  0.5482983647607846
Iteration: 1552
    Time:  95.559
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.7750659139129837
    Accuracy:  0.5258565087073642
Iteration: 1553
    Time:  110.873
    Number of Data points:         512
    Number of Training batches:    16 

    Loss:  1.465071497013891
    Accuracy:  0.5216451037675001
Iteration: 1554
    Time:  82.405
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.865826915432245
    Accuracy:  0.5449595932769283
Iteration: 1555
    Time:  71.382
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.7743279937385794
    Accuracy:  0.5546344424631028
Iteration: 1556
    Time:  86.85
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.7158024872817982
    Accuracy:  0.561805213036385
Iteration: 1557
    Time:  98.302
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  1.527209432601163
    Accuracy:  0.5613119854308154
Iteration: 1558
    Time:  100.136
    Number of Data points:         512
    Number of Training batches:    16 

    Loss:  0.6413970468281196
    Accuracy:  0.562658876199871
Iteration: 1559
    Time:  77.879
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  1.3473304715309287
    Accuracy:  0.5609894904579429
Iteration: 1560
    Time:  91.917
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.3615907323045227
    Accuracy:  0.5542740069051865
Iteration: 1561
    Time:  75.546
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  1.2310014257979593
    Accuracy:  0.5389460105474826
Iteration: 1562
    Time:  92.197
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.729648668168906
    Accuracy:  0.551618165952119
Iteration: 1563
    Time:  101.735
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.6522315611491362
    Accuracy:  0.5577266001441742
Iteration: 1564
    Time:  108.274
    Number of Data points:         520
    Number of Training batches:    17 

    Loss:  1.340239842086873
    Accuracy:  0.5423796334939485
Iteration: 1565
    Time:  87.192
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.2463512905162142
    Accuracy:  0.5153090260651819
Iteration: 1566
    Time:  96.825
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  1.4500325454150647
    Accuracy:  0.5105664529347043
Iteration: 1567
    Time:  80.328
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.9040203638265185
    Accuracy:  0.4639185036233259
Iteration: 1568
    Time:  79.457
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.8759488740735569
    Accuracy:  0.5253822513943165
Iteration: 1569
    Time:  88.308
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  1.1175640846048986
    Accuracy:  0.46295101870470845
Iteration: 1570
    Time:  73.737
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  0.9845447682653043
    Accuracy:  0.5273551618165953
Iteration: 1571
    Time:  102.201
    Number of Data points:         528
    Number of Training batches:    17 

    Loss:  1.4341587755461906
    Accuracy:  0.5295367454566149
Iteration: 1572
    Time:  84.648
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.437095391341027
    Accuracy:  0.5290814584360891
Iteration: 1573
    Time:  87.453
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.7840801279292222
    Accuracy:  0.5476154342299958
Iteration: 1574
    Time:  86.469
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.8842286854984113
    Accuracy:  0.5241871229654361
Iteration: 1575
    Time:  83.671
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.836255665767385
    Accuracy:  0.4715825018021778
Iteration: 1576
    Time:  90.814
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  0.9811306398613624
    Accuracy:  0.5264635580680654
Iteration: 1577
    Time:  77.726
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.779094290284205
    Accuracy:  0.5389080699624388
Iteration: 1578
    Time:  107.232
    Number of Data points:         536
    Number of Training batches:    17 

    Loss:  0.8721903617800316
    Accuracy:  0.48634138938422433
Iteration: 1579
    Time:  86.22
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.7060207521368337
    Accuracy:  0.4652084835148158
Iteration: 1580
    Time:  68.989
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  0.9807660876706867
    Accuracy:  0.5161247486436241
Iteration: 1581
    Time:  106.295
    Number of Data points:         512
    Number of Training batches:    16 

    Loss:  1.4624081586392985
    Accuracy:  0.5248131426186592
Iteration: 1582
    Time:  71.028
    Number of Data points:         344
    Number of Training batches:    11 

    Loss:  1.0968488767819642
    Accuracy:  0.4931137838145464
Iteration: 1583
    Time:  80.178
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.636242310804847
    Accuracy:  0.4817316083014
Iteration: 1584
    Time:  88.169
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  1.1816885763440192
    Accuracy:  0.5236180141897788
Iteration: 1585
    Time:  76.212
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.5069819373411613
    Accuracy:  0.5209811435292332
Iteration: 1586
    Time:  93.027
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.8079301635857445
    Accuracy:  0.5446370983040558
Iteration: 1587
    Time:  76.974
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  0.8944258059885025
    Accuracy:  0.5180786887733809
Iteration: 1588
    Time:  81.087
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.8106005390153128
    Accuracy:  0.5385855749895664
Iteration: 1589
    Time:  80.765
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.6700119495320579
    Accuracy:  0.5327806654778616
Iteration: 1590
    Time:  83.754
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.0295169013904737
    Accuracy:  0.49823576279546233
Iteration: 1591
    Time:  91.541
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.9734294879740483
    Accuracy:  0.535702090526236
Iteration: 1592
    Time:  87.858
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.8919855080361627
    Accuracy:  0.5476913154000834
Iteration: 1593
    Time:  81.601
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.7593782529593185
    Accuracy:  0.5562089767424213
Iteration: 1594
    Time:  92.59
    Number of Data points:         520
    Number of Training batches:    17 

    Loss:  1.5175294672640622
    Accuracy:  0.5552604621163258
Iteration: 1595
    Time:  89.11
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.6824923927884523
    Accuracy:  0.5590545206207079
Iteration: 1596
    Time:  81.033
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.6485265890848988
    Accuracy:  0.5620707971316917
Iteration: 1597
    Time:  92.703
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  1.1606944554772716
    Accuracy:  0.5463254543385059
Iteration: 1598
    Time:  81.251
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  1.4654526042479699
    Accuracy:  0.5454717911750199
Iteration: 1599
Could not find child with move:  8 1
An Exception was thrown
Iteration: 1600
    Time:  71.394
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  0.9917464407248063
    Accuracy:  0.5303334977425352
Iteration: 1601
    Time:  74.801
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.7118373469196007
    Accuracy:  0.5394582084455742
Iteration: 1602
    Time:  81.557
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  1.1455669447756327
    Accuracy:  0.5169215009295444
Iteration: 1603
    Time:  85.914
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.837045653133276
    Accuracy:  0.4638426224532382
Iteration: 1604
    Time:  91.572
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  1.441513362460765
    Accuracy:  0.4875744583981485
Iteration: 1605
    Time:  88.504
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.3789444159627566
    Accuracy:  0.5104146905945289
Iteration: 1606
    Time:  95.379
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  1.4638803510178886
    Accuracy:  0.5179269264332056
Iteration: 1607
    Time:  94.379
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.6594298825609606
    Accuracy:  0.47291042227871155
Iteration: 1608
    Time:  108.136
    Number of Data points:         512
    Number of Training batches:    16 

    Loss:  1.5245191180613302
    Accuracy:  0.4797207572940775
Iteration: 1609
    Time:  79.321
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  1.293768933166158
    Accuracy:  0.5143036005615207
Iteration: 1610
    Time:  87.846
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.7633333388763169
    Accuracy:  0.5405205448268012
Iteration: 1611
    Time:  82.934
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  1.1103842119765086
    Accuracy:  0.5030731873885496
Iteration: 1612
    Time:  66.224
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  0.7723928825100663
    Accuracy:  0.4634632166028
Iteration: 1613
    Time:  106.667
    Number of Data points:         504
    Number of Training batches:    16 

    Loss:  0.6048465695350339
    Accuracy:  0.4488750616534507
Iteration: 1614
    Time:  92.215
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.567222080300559
    Accuracy:  0.446048488067686
Iteration: 1615
    Time:  94.261
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  1.28643531664774
    Accuracy:  0.5058238798042266
Iteration: 1616
    Time:  92.774
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  1.5157035547748487
    Accuracy:  0.5103008688393975
Iteration: 1617
    Time:  90.726
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.1091112305640887
    Accuracy:  0.5457563455628486
Iteration: 1618
    Time:  72.94
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  0.7781169475030291
    Accuracy:  0.5282657358576469
Iteration: 1619
An Exception was thrown
Iteration: 1620
    Time:  74.867
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.8418781254130071
    Accuracy:  0.4861706567515271
Iteration: 1621
    Time:  77.625
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  1.4547831364716688
    Accuracy:  0.49726827787684486
Iteration: 1622
    Time:  79.327
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.8098861796084885
    Accuracy:  0.536517813104678
Iteration: 1623
    Time:  96.204
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  1.455778892351362
    Accuracy:  0.5414311188678529
Iteration: 1624
    Time:  93.172
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  0.7460143875349191
    Accuracy:  0.4940812687331639
Iteration: 1625
    Time:  89.546
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.3362117467562942
    Accuracy:  0.522745380733771
Iteration: 1626
    Time:  98.553
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  0.8029135707429078
    Accuracy:  0.453693515954016
Iteration: 1627
    Time:  91.063
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.510207565410578
    Accuracy:  0.45997268277876846
Iteration: 1628
    Time:  95.315
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  1.1587119724118682
    Accuracy:  0.5280570626399059
Iteration: 1629
    Time:  90.862
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.8603083215712366
    Accuracy:  0.5455476723451076
Iteration: 1630
    Time:  89.125
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.2639412168332218
    Accuracy:  0.5373714762681641
Iteration: 1631
    Time:  78.79
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.8591768774534398
    Accuracy:  0.5111924725879273
Iteration: 1632
    Time:  85.839
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.7804986924914649
    Accuracy:  0.47592669878969535
Iteration: 1633
    Time:  100.598
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  0.7237152946021878
    Accuracy:  0.4158288120802823
Iteration: 1634
    Time:  77.794
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  1.2549708812675253
    Accuracy:  0.46515157263725004
Iteration: 1635
    Time:  69.126
    Number of Data points:         352
    Number of Training batches:    11 

    Loss:  1.1760883670397762
    Accuracy:  0.49880487157111963
Iteration: 1636
    Time:  102.338
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.6737006383335422
    Accuracy:  0.4724930758432295
Iteration: 1637
    Time:  73.872
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.659784374023896
    Accuracy:  0.4577531585537049
Iteration: 1638
    Time:  91.764
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  1.4751231759160817
    Accuracy:  0.4668209583791782
Iteration: 1639
    Time:  69.781
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  0.9106754779402233
    Accuracy:  0.5152331448950943
Iteration: 1640
    Time:  84.854
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.7323243028385041
    Accuracy:  0.5292711613613081
Iteration: 1641
    Time:  100.774
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  0.7973850909254452
    Accuracy:  0.4607694350646887
Iteration: 1642
    Time:  83.828
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.2998157109924655
    Accuracy:  0.5023712865652389
Iteration: 1643
    Time:  61.326
    Number of Data points:         320
    Number of Training batches:    10 

    Loss:  0.7820026441307764
    Accuracy:  0.5221762719581136
Iteration: 1644
    Time:  100.914
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.6543435691989105
    Accuracy:  0.508290017832075
Iteration: 1645
    Time:  86.073
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.7259927364058462
    Accuracy:  0.47382099631976327
Iteration: 1646
    Time:  106.671
    Number of Data points:         544
    Number of Training batches:    17 

    Loss:  0.7432360478632358
    Accuracy:  0.5203361535834883
Iteration: 1647
    Time:  87.563
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.7099352687276956
    Accuracy:  0.49317069469211217
Iteration: 1648
    Time:  80.053
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  1.468206585077753
    Accuracy:  0.502959365633418
Iteration: 1649
    Time:  86.928
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.7253639592460345
    Accuracy:  0.5291383693136548
Iteration: 1650
    Time:  86.728
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.3294970371465118
    Accuracy:  0.5112114428804492
Iteration: 1651
    Time:  71.986
    Number of Data points:         368
    Number of Training batches:    12 

    Loss:  0.8584101199140902
    Accuracy:  0.5349622491178814
Iteration: 1652
    Time:  72.865
    Number of Data points:         368
    Number of Training batches:    12 

    Loss:  0.7174423654583583
    Accuracy:  0.5398565845885344
Iteration: 1653
    Time:  96.947
    Number of Data points:         504
    Number of Training batches:    16 

    Loss:  1.5032987655151187
    Accuracy:  0.5392305649353113
Iteration: 1654
    Time:  88.57
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.7667023065235259
    Accuracy:  0.5436127025078726
Iteration: 1655
    Time:  83.285
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  1.4707408157221808
    Accuracy:  0.5415828812080282
Iteration: 1656
    Time:  117.182
    Number of Data points:         552
    Number of Training batches:    18 

    Loss:  1.4984098043469904
    Accuracy:  0.540577455704367
Iteration: 1657
    Time:  76.149
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  0.7409919634538984
    Accuracy:  0.5362711993018933
Iteration: 1658
    Time:  65.296
    Number of Data points:         344
    Number of Training batches:    11 

    Loss:  0.9537441105589607
    Accuracy:  0.5154987289904011
Iteration: 1659
    Time:  104.127
    Number of Data points:         512
    Number of Training batches:    16 

    Loss:  0.720380293048143
    Accuracy:  0.5318131805592442
Iteration: 1660
    Time:  83.583
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.7038809501523974
    Accuracy:  0.5383010206017377
Iteration: 1661
    Time:  69.357
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.6306121380998022
    Accuracy:  0.5404067230716698
Iteration: 1662
    Time:  73.473
    Number of Data points:         368
    Number of Training batches:    12 

    Loss:  0.6162069111523436
    Accuracy:  0.5421140493986417
Iteration: 1663
    Time:  88.208
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.6666741904282757
    Accuracy:  0.5472360283795576
Iteration: 1664
    Time:  98.467
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.7458919685900924
    Accuracy:  0.5396858519558372
Iteration: 1665
    Time:  87.752
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.7144060757754914
    Accuracy:  0.5235421330196912
Iteration: 1666
    Time:  92.835
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  1.492651263057841
    Accuracy:  0.5231627271692529
Iteration: 1667
    Time:  77.348
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  1.4546185782464698
    Accuracy:  0.5158971051333612
Iteration: 1668
    Time:  64.564
    Number of Data points:         352
    Number of Training batches:    11 

    Loss:  0.8967683792604564
    Accuracy:  0.5353606252608415
Iteration: 1669
    Time:  91.166
    Number of Data points:         504
    Number of Training batches:    16 

    Loss:  1.2498317342204988
    Accuracy:  0.5117615813635846
Iteration: 1670
    Time:  79.668
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.6098650285548778
    Accuracy:  0.49971544561217135
Iteration: 1671
    Time:  95.067
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  0.7334329825753967
    Accuracy:  0.4690973934818075
Iteration: 1672
    Time:  60.31
    Number of Data points:         320
    Number of Training batches:    10 

    Loss:  1.503164296439223
    Accuracy:  0.47289145198618965
Iteration: 1673
    Time:  92.418
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  0.6913366693236329
    Accuracy:  0.4493493189664985
Iteration: 1674
    Time:  78.869
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.5727360706148323
    Accuracy:  0.44714876503395684
Iteration: 1675
    Time:  97.448
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  1.0759181354357408
    Accuracy:  0.4904010319839132
Iteration: 1676
    Time:  74.056
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.8809520446520754
    Accuracy:  0.5156504913305763
Iteration: 1677
    Time:  70.288
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  0.6134476918740416
    Accuracy:  0.5083089881245969
Iteration: 1678
    Time:  94.603
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.6263431511225074
    Accuracy:  0.4771218272185757
Iteration: 1679
    Time:  93.358
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.8064339440961398
    Accuracy:  0.5290814584360891
Iteration: 1680
    Time:  82.514
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.7054723438969362
    Accuracy:  0.5380733770914747
Iteration: 1681
    Time:  78.312
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  1.2231478492436987
    Accuracy:  0.5290055772660014
Iteration: 1682
    Time:  67.837
    Number of Data points:         368
    Number of Training batches:    12 

    Loss:  0.6411125808225394
    Accuracy:  0.5325150813825549
Iteration: 1683
    Time:  80.73
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.6136618874706291
    Accuracy:  0.5349812194104033
Iteration: 1684
    Time:  69.506
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.7339506985017115
    Accuracy:  0.5186667678415601
Iteration: 1685
    Time:  87.349
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  1.0108977920683702
    Accuracy:  0.45266912015783284
Iteration: 1686
    Time:  87.667
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.6005674259444861
    Accuracy:  0.44722464620404445
Iteration: 1687
    Time:  76.775
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.5944525396430463
    Accuracy:  0.4414007663998179
Iteration: 1688
    Time:  86.16
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.5349689161431606
    Accuracy:  0.4430511818492241
Iteration: 1689
    Time:  88.412
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.5672838476866529
    Accuracy:  0.4415714990325151
Iteration: 1690
    Time:  101.507
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  1.260510456093865
    Accuracy:  0.48002428197442804
Iteration: 1691
    Time:  94.317
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.6617267932687381
    Accuracy:  0.521038054406799
Iteration: 1692
    Time:  93.849
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.9247562361831988
    Accuracy:  0.4771787380961414
Iteration: 1693
    Time:  73.074
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  1.4318514352207892
    Accuracy:  0.4890162006298137
Iteration: 1694
    Time:  89.811
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.6269673073211027
    Accuracy:  0.4946503775088212
Iteration: 1695
    Time:  86.58
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.134726645780571
    Accuracy:  0.5319649428994195
Iteration: 1696
    Time:  80.511
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.6054686156866779
    Accuracy:  0.5351329817505786
Iteration: 1697
    Time:  88.903
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  1.5000890976608208
    Accuracy:  0.533786090981523
Iteration: 1698
    Time:  89.377
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.305819163447397
    Accuracy:  0.5390218917175703
Iteration: 1699
    Time:  92.544
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.5616727934183924
    Accuracy:  0.5389270402549607
Iteration: 1700
    Time:  84.341
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  1.2594140246941552
    Accuracy:  0.5315855370489813
Iteration: 1701
    Time:  87.605
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.1257155408729818
    Accuracy:  0.5100542550366126
Iteration: 1702
    Time:  85.824
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.6825289067801747
    Accuracy:  0.5302955571574913
Iteration: 1703
    Time:  90.145
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.5832589930741249
    Accuracy:  0.5321356755321167
Iteration: 1704
    Time:  90.474
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.6963961323014182
    Accuracy:  0.5241491823803923
Iteration: 1705
    Time:  95.005
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  0.6443040546298632
    Accuracy:  0.5311492203209773
Iteration: 1706
    Time:  85.544
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.9176470768592299
    Accuracy:  0.543119474902303
Iteration: 1707
    Time:  87.646
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.87412426668466
    Accuracy:  0.5356451796486702
Iteration: 1708
    Time:  79.038
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.6789613360247707
    Accuracy:  0.5332169822058657
Iteration: 1709
    Time:  86.385
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.6093584120276033
    Accuracy:  0.5358538528664112
Iteration: 1710
    Time:  85.23
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.5056549487718642
    Accuracy:  0.5343362294646583
Iteration: 1711
    Time:  76.606
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  1.0917265397026794
    Accuracy:  0.5179269264332056
Iteration: 1712
    Time:  87.616
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.5828252361535162
    Accuracy:  0.5200326289031377
Iteration: 1713
    Time:  82.066
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.6223341025281712
    Accuracy:  0.5255719543195356
Iteration: 1714
    Time:  81.645
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.6147039462246926
    Accuracy:  0.5303524680350571
Iteration: 1715
    Time:  92.815
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.6007466046210944
    Accuracy:  0.5262928254353683
Iteration: 1716
    Time:  69.571
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.5706987082942652
    Accuracy:  0.5274879538642486
Iteration: 1717
    Time:  75.743
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.7070384572165982
    Accuracy:  0.5144363926091741
Iteration: 1718
    Time:  103.2
    Number of Data points:         528
    Number of Training batches:    17 

    Loss:  1.5074157958006429
    Accuracy:  0.5154038775277915
Iteration: 1719
    Time:  81.123
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.5999609318347034
    Accuracy:  0.5126531851121144
Iteration: 1720
    Time:  81.449
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.7917344754779437
    Accuracy:  0.474295253632811
Iteration: 1721
    Time:  88.77
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.7250167399697426
    Accuracy:  0.4594035740031111
Iteration: 1722
    Time:  79.45
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.5258924088513264
    Accuracy:  0.4677694730052737
Iteration: 1723
    Time:  95.359
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  1.0956284843616961
    Accuracy:  0.42134916720415827
Iteration: 1724
    Time:  89.986
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  1.4952342423602132
    Accuracy:  0.4162271882232424
Iteration: 1725
    Time:  72.293
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  0.557384580732395
    Accuracy:  0.41541146564480025
Iteration: 1726
    Time:  79.011
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.5439136576066597
    Accuracy:  0.41634100997837387
Iteration: 1727
    Time:  90.357
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.5740793507017946
    Accuracy:  0.40958758584057364
Iteration: 1728
    Time:  100.096
    Number of Data points:         504
    Number of Training batches:    16 

    Loss:  1.548862515593144
    Accuracy:  0.40994802139848996
Iteration: 1729
    Time:  65.314
    Number of Data points:         360
    Number of Training batches:    12 

    Loss:  0.5764698884798266
    Accuracy:  0.4084114277042152
Iteration: 1730
    Time:  82.899
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.5866413858917037
    Accuracy:  0.40196152824676556
Iteration: 1731
    Time:  94.489
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.5100605962096856
    Accuracy:  0.4038206169139128
Iteration: 1732
    Time:  91.79
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.5640787207437608
    Accuracy:  0.40298592404294875
Iteration: 1733
    Time:  78.847
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.6323335808275148
    Accuracy:  0.3903896498084
Iteration: 1734
    Time:  88.719
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.5598948927652879
    Accuracy:  0.3899533330803961
Iteration: 1735
    Time:  106.312
    Number of Data points:         504
    Number of Training batches:    16 

    Loss:  0.5726506405491306
    Accuracy:  0.38860644231134045
Iteration: 1736
    Time:  80.543
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.5600426164362716
    Accuracy:  0.3883598285085556
Iteration: 1737
    Time:  91.225
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  1.5269081273598104
    Accuracy:  0.38900481845430057
Iteration: 1738
    Time:  79.182
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.5479642937216413
    Accuracy:  0.38919452137951965
Iteration: 1739
    Time:  82.782
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.5471706385453508
    Accuracy:  0.3892704025496073
Iteration: 1740
    Time:  92.244
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  1.539839313248631
    Accuracy:  0.38963083810752364
Iteration: 1741
    Time:  73.048
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  0.5763468590249826
    Accuracy:  0.3884546799711652
Iteration: 1742
    Time:  92.202
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  0.5562154416301464
    Accuracy:  0.3883787988010775
Iteration: 1743
    Time:  81.506
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.5532359243878363
    Accuracy:  0.3883029176309899
Iteration: 1744
    Time:  86.507
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.5404944968600145
    Accuracy:  0.3884167393861213
Iteration: 1745
    Time:  81.592
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  1.546736448013379
    Accuracy:  0.38862541260386235
Iteration: 1746
    Time:  91.674
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.5571682865663729
    Accuracy:  0.38843570967864327
Iteration: 1747
    Time:  84.938
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  1.549813870372188
    Accuracy:  0.3885495314337747
Iteration: 1748
    Time:  85.364
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.5548703976174656
    Accuracy:  0.38843570967864327
Iteration: 1749
    Time:  95.831
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.552702487563541
    Accuracy:  0.3884736502636871
Iteration: 1750
    Time:  75.304
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  0.5570170304196375
    Accuracy:  0.3883218879235118
Iteration: 1751
    Time:  93.09
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.5535638888687308
    Accuracy:  0.38828394733846794
Iteration: 1752
    Time:  81.201
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.5529989543713761
    Accuracy:  0.38828394733846794
Iteration: 1753
    Time:  83.461
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  1.541081744007386
    Accuracy:  0.3885305611412528
Iteration: 1754
    Time:  96.239
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  0.5560880923689893
    Accuracy:  0.3884167393861213
Iteration: 1755
    Time:  98.263
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  1.4217091900675878
    Accuracy:  0.3924384414007664
Iteration: 1756
    Time:  84.274
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.5589553485197751
    Accuracy:  0.3919072732101529
Iteration: 1757
    Time:  100.714
    Number of Data points:         512
    Number of Training batches:    16 

    Loss:  1.5483345828249997
    Accuracy:  0.3922677087680692
Iteration: 1758
    Time:  77.873
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.4747588613055134
    Accuracy:  0.39549265849679405
Iteration: 1759
    Time:  93.291
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  1.5443622132839432
    Accuracy:  0.3959479455173199
Iteration: 1760
    Time:  81.855
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.6031147717367296
    Accuracy:  0.3934628371969496
Iteration: 1761
    Time:  93.328
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  1.544966304647711
    Accuracy:  0.3940509162651288
Iteration: 1762
    Time:  89.772
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.5543678017190067
    Accuracy:  0.39374739158477823
Iteration: 1763
    Time:  82.974
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.5562632195993489
    Accuracy:  0.3933869560268619
Iteration: 1764
    Time:  111.095
    Number of Data points:         536
    Number of Training batches:    17 

    Loss:  1.541019360522601
    Accuracy:  0.3943544409454794
Iteration: 1765
    Time:  70.487
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  1.5421049138066831
    Accuracy:  0.3947528170884395
Iteration: 1766
Could not find child with move:  0 5
An Exception was thrown
Iteration: 1767
    Time:  82.118
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.564940792069127
    Accuracy:  0.393804302462344
Iteration: 1768
    Time:  83.558
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.5304666307852601
    Accuracy:  0.39515119323139963
Iteration: 1769
    Time:  72.116
    Number of Data points:         360
    Number of Training batches:    12 

    Loss:  0.5523203693457405
    Accuracy:  0.39511325264635583
Iteration: 1770
    Time:  93.366
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  1.5388973502110945
    Accuracy:  0.3963842622453238
Iteration: 1771
    Time:  87.293
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.5304735214180254
    Accuracy:  0.39801570740220815
Iteration: 1772
    Time:  92.504
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.4977834681795037
    Accuracy:  0.4016959441514588
Iteration: 1773
    Time:  79.733
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.5630539101984265
    Accuracy:  0.40108889479075766
Iteration: 1774
    Time:  77.559
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  1.475353057393743
    Accuracy:  0.4053951511932314
Iteration: 1775
    Time:  112.705
    Number of Data points:         536
    Number of Training batches:    17 

    Loss:  0.6044120456386225
    Accuracy:  0.39943847934135146
Iteration: 1776
    Time:  98.662
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.5533745493786439
    Accuracy:  0.3993625981712638
Iteration: 1777
    Time:  78.816
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.5628943399937204
    Accuracy:  0.39850893500777784
Iteration: 1778
    Time:  97.97
    Number of Data points:         504
    Number of Training batches:    16 

    Loss:  1.5392297947217382
    Accuracy:  0.39945744963387336
Iteration: 1779
    Time:  80.887
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.449105497144186
    Accuracy:  0.4042759039344387
Iteration: 1780
    Time:  88.823
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.4377141664255724
    Accuracy:  0.4128315058618204
Iteration: 1781
    Time:  80.832
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  0.5686330139519575
    Accuracy:  0.4111431498273703
Iteration: 1782
Could not find child with move:  4 0
An Exception was thrown
Iteration: 1783
    Time:  90.592
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.6236308028776688
    Accuracy:  0.4007663998178852
Iteration: 1784
An Exception was thrown
Iteration: 1785
    Time:  86.403
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.6788831215548493
    Accuracy:  0.39164168911484615
Iteration: 1786
    Time:  92.39
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  1.543494023826523
    Accuracy:  0.39202109496528437
Iteration: 1787
    Time:  79.599
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  1.5413079847483864
    Accuracy:  0.3924574116932883
Iteration: 1788
    Time:  99.689
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.5561543516009981
    Accuracy:  0.3922297681830254
Iteration: 1789
    Time:  92.874
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.5533176767575071
    Accuracy:  0.39211594642789394
Iteration: 1790
    Time:  76.109
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  1.5422970067458999
    Accuracy:  0.3924384414007664
Iteration: 1791
    Time:  105.455
    Number of Data points:         528
    Number of Training batches:    17 

    Loss:  1.546741401555658
    Accuracy:  0.39270402549607314
Iteration: 1792
    Time:  83.642
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.5669629626879967
    Accuracy:  0.39213491672041584
Iteration: 1793
Could not find child with move:  6 1
An Exception was thrown
Iteration: 1794
    Time:  88.665
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.5686153139025899
    Accuracy:  0.39145198618962707
Iteration: 1795
    Time:  63.977
    Number of Data points:         336
    Number of Training batches:    11 

    Loss:  1.5123435217470556
    Accuracy:  0.39257123344841977
Iteration: 1796
    Time:  88.393
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.5607210529997666
    Accuracy:  0.3917175702849338
Iteration: 1797
    Time:  97.934
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  1.5373818642046966
    Accuracy:  0.39251432257085406
Iteration: 1798
    Time:  83.709
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.5102918861059895
    Accuracy:  0.3947338467959176
Iteration: 1799
    Time:  73.786
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  1.5362020278917
    Accuracy:  0.39558750995940356
Iteration: 1800
    Time:  106.584
    Number of Data points:         528
    Number of Training batches:    17 

    Loss:  1.5344040375036656
    Accuracy:  0.3973707174564632
Iteration: 1801
    Time:  110.532
    Number of Data points:         544
    Number of Training batches:    17 

    Loss:  1.5376299972988905
    Accuracy:  0.39822438061994914
Iteration: 1802
    Time:  98.934
    Number of Data points:         504
    Number of Training batches:    16 

    Loss:  0.5829792099989942
    Accuracy:  0.39591000493227607
Iteration: 1803
    Time:  73.925
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  0.5591861385083838
    Accuracy:  0.39553059908183785
Iteration: 1804
    Time:  82.56
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  1.476200395084902
    Accuracy:  0.40101301362067004
Iteration: 1805
    Time:  87.737
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  1.5237565904702897
    Accuracy:  0.4029100428728611
Iteration: 1806
    Time:  72.487
    Number of Data points:         352
    Number of Training batches:    11 

    Loss:  1.509648727099682
    Accuracy:  0.40456045832226734
Iteration: 1807
    Time:  80.983
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  1.4905224304380422
    Accuracy:  0.4087908335546534
Iteration: 1808
    Time:  89.173
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.539307285188007
    Accuracy:  0.4097772887657928
Iteration: 1809
    Time:  80.298
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  1.4857017897779057
    Accuracy:  0.41544940622984405
Iteration: 1810
    Time:  98.055
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  1.3332955911225335
    Accuracy:  0.4390294798345791
Iteration: 1811
    Time:  83.968
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.5183968014400118
    Accuracy:  0.44274765716887354
Iteration: 1812
    Time:  90.427
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  1.5338017811020173
    Accuracy:  0.4453845278294191
Iteration: 1813
    Time:  98.025
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  1.3969083473662813
    Accuracy:  0.45908107903023865
Iteration: 1814
    Time:  90.052
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.4667799733086044
    Accuracy:  0.46943885874720187
Iteration: 1815
    Time:  88.85
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.5706158142619949
    Accuracy:  0.4671434533520507
Iteration: 1816
    Time:  104.105
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  1.4322835929116076
    Accuracy:  0.4780134309671055
Iteration: 1817
    Time:  91.266
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.7342501031896582
    Accuracy:  0.5121599575065447
Iteration: 1818
    Time:  70.272
    Number of Data points:         368
    Number of Training batches:    12 

    Loss:  0.6083146427856047
    Accuracy:  0.5201085100732253
Iteration: 1819
    Time:  83.551
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.7205220725224696
    Accuracy:  0.49428994195090487
Iteration: 1820
    Time:  92.083
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.4469246014660382
    Accuracy:  0.510813066737489
Iteration: 1821
    Time:  92.89
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.6045384156569168
    Accuracy:  0.5228592024889024
Iteration: 1822
    Time:  106.709
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  0.818888287065186
    Accuracy:  0.5548620859733657
Iteration: 1823
    Time:  122.797
    Number of Data points:         576
    Number of Training batches:    18 

    Loss:  1.549082907095953
    Accuracy:  0.5548431156808438
Iteration: 1824
    Time:  88.96
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.5001369657493595
    Accuracy:  0.5536479872519634
Iteration: 1825
    Time:  82.32
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.9201032749419651
    Accuracy:  0.558409530674963
Iteration: 1826
    Time:  69.481
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  1.017523840305471
    Accuracy:  0.5510300868839397
Iteration: 1827
    Time:  89.415
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.9118882134432776
    Accuracy:  0.5360245854991084
Iteration: 1828
    Time:  79.924
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.6689359165520137
    Accuracy:  0.5431763857798687
Iteration: 1829
    Time:  86.323
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  1.167753471748028
    Accuracy:  0.5557536897218955
Iteration: 1830
    Time:  95.35
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  0.6552236669979413
    Accuracy:  0.5589027582805327
Iteration: 1831
    Time:  76.106
    Number of Data points:         376
    Number of Training batches:    12 

    Loss:  1.0197158913709206
    Accuracy:  0.5520924232651667
Iteration: 1832
    Time:  77.357
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.9305215032826293
    Accuracy:  0.5602496490495883
Iteration: 1833
    Time:  82.584
    Number of Data points:         400
    Number of Training batches:    13 

    Loss:  0.6476849010683556
    Accuracy:  0.5632279849755283
Iteration: 1834
    Time:  82.335
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.5728399543036635
    Accuracy:  0.5631900443904845
Iteration: 1835
    Time:  99.529
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.5713251390342898
    Accuracy:  0.5634176879007474
Iteration: 1836
    Time:  84.969
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  1.503778785914388
    Accuracy:  0.562867549417612
Iteration: 1837
    Time:  92.089
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.4129412614105468
    Accuracy:  0.5603824410972417
Iteration: 1838
    Time:  113.606
    Number of Data points:         528
    Number of Training batches:    17 

    Loss:  0.6335237673956805
    Accuracy:  0.5630951929278749
Iteration: 1839
    Time:  92.656
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  1.49608105349934
    Accuracy:  0.562658876199871
Iteration: 1840
    Time:  98.799
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  0.5735747494862816
    Accuracy:  0.562867549417612
Iteration: 1841
    Time:  81.263
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  1.5373617010456941
    Accuracy:  0.5628296088325682
Iteration: 1842
    Time:  79.799
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.7392528406092483
    Accuracy:  0.5645938460371059
Iteration: 1843
    Time:  92.715
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  0.5805221668956071
    Accuracy:  0.5647076677922374
Iteration: 1844
    Time:  66.527
    Number of Data points:         344
    Number of Training batches:    11 

    Loss:  1.545271824304264
    Accuracy:  0.5647645786698031
Iteration: 1845
    Time:  97.215
    Number of Data points:         488
    Number of Training batches:    16 

    Loss:  1.3887242007565204
    Accuracy:  0.562658876199871
Iteration: 1846
    Time:  77.795
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  1.4430689932218204
    Accuracy:  0.5600409758318473
Iteration: 1847
    Time:  84.475
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  1.028989972091709
    Accuracy:  0.5529460864286527
Iteration: 1848
    Time:  73.453
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  1.3642983959625954
    Accuracy:  0.5480896915430435
Iteration: 1849
    Time:  95.067
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  0.7170994165963337
    Accuracy:  0.5582957089198315
Iteration: 1850
    Time:  96.385
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  1.0211672475564124
    Accuracy:  0.5444473953788368
Iteration: 1851
    Time:  108.582
    Number of Data points:         536
    Number of Training batches:    17 

    Loss:  0.8321726055001716
    Accuracy:  0.49028721022878174
Iteration: 1852
    Time:  100.492
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.8829973870791554
    Accuracy:  0.5497780475774936
Iteration: 1853
    Time:  104.816
    Number of Data points:         528
    Number of Training batches:    17 

    Loss:  1.51475294529781
    Accuracy:  0.5508214136661987
Iteration: 1854
    Time:  72.102
    Number of Data points:         344
    Number of Training batches:    11 

    Loss:  1.3609039545342925
    Accuracy:  0.5433660887050878
Iteration: 1855
    Time:  76.103
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  0.9465974363731159
    Accuracy:  0.5231816974617749
Iteration: 1856
    Time:  103.08
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  1.4838755964377164
    Accuracy:  0.5321167052395948
Iteration: 1857
    Time:  100.653
    Number of Data points:         512
    Number of Training batches:    16 

    Loss:  1.4738639399311075
    Accuracy:  0.5377698524111242
Iteration: 1858
    Time:  93.142
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.3065214195167183
    Accuracy:  0.5485070379785256
Iteration: 1859
    Time:  100.343
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  0.6822876134729204
    Accuracy:  0.5544257692453618
Iteration: 1860
    Time:  78.549
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.8812300010679774
    Accuracy:  0.5324012596274235
Iteration: 1861
    Time:  95.373
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.6591919097621594
    Accuracy:  0.5108699776150548
Iteration: 1862
    Time:  75.022
    Number of Data points:         360
    Number of Training batches:    12 

    Loss:  0.6867185718465755
    Accuracy:  0.4837045187236787
Iteration: 1863
    Time:  85.611
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  0.7609571558562064
    Accuracy:  0.5214933414273248
Iteration: 1864
    Time:  90.821
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.4223176462893554
    Accuracy:  0.5307698144705392
Iteration: 1865
    Time:  99.468
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  1.2772177941766358
    Accuracy:  0.5568160261031225
Iteration: 1866
    Time:  97.23
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  1.4773369208550702
    Accuracy:  0.5537997495921387
Iteration: 1867
    Time:  81.58
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.9574569055177348
    Accuracy:  0.5353606252608415
Iteration: 1868
    Time:  84.553
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  0.8295257572957792
    Accuracy:  0.5117046704860189
Iteration: 1869
    Time:  91.926
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  1.4652249316059704
    Accuracy:  0.5169215009295444
Iteration: 1870
    Time:  78.794
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  0.6529627283430547
    Accuracy:  0.5017262966194939
Iteration: 1871
    Time:  111.739
    Number of Data points:         552
    Number of Training batches:    18 

    Loss:  0.7139482747511658
    Accuracy:  0.4289562545054445
Iteration: 1872
    Time:  101.815
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  1.4805353229053289
    Accuracy:  0.43637363888151154
Iteration: 1873
    Time:  107.588
    Number of Data points:         504
    Number of Training batches:    16 

    Loss:  0.6173223303736095
    Accuracy:  0.4246689683954927
Iteration: 1874
    Time:  92.925
    Number of Data points:         480
    Number of Training batches:    15 

    Loss:  1.5409829663717143
    Accuracy:  0.4255605721440225
Iteration: 1875
    Time:  65.81
    Number of Data points:         352
    Number of Training batches:    11 

    Loss:  1.4510594837886264
    Accuracy:  0.43140342224077094
Iteration: 1876
    Time:  91.65
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.6660821628896045
    Accuracy:  0.4082027544864742
Iteration: 1877
    Time:  93.251
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  1.519794305841904
    Accuracy:  0.4126797435216451
Iteration: 1878
    Time:  83.619
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.0059351165279804
    Accuracy:  0.4711272147816519
Iteration: 1879
    Time:  94.749
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.6463866555388207
    Accuracy:  0.4561975945669082
Iteration: 1880
    Time:  89.966
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.6033690074813969
    Accuracy:  0.44866638843570966
Iteration: 1881
    Time:  79.979
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  1.4905404445502224
    Accuracy:  0.45323822893349014
Iteration: 1882
    Time:  93.355
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.7301589269846122
    Accuracy:  0.4277231854915203
Iteration: 1883
    Time:  79.904
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  0.998724954954093
    Accuracy:  0.4673331562772698
Iteration: 1884
    Time:  76.413
    Number of Data points:         360
    Number of Training batches:    12 

    Loss:  0.6584618775634281
    Accuracy:  0.44775581439465795
Iteration: 1885
    Time:  90.181
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.5883636843899228
    Accuracy:  0.44434116174071403
Iteration: 1886
    Time:  58.224
    Number of Data points:         288
    Number of Training batches:    9 

    Loss:  1.1059699378602186
    Accuracy:  0.46638464165117427
Iteration: 1887
    Time:  93.534
    Number of Data points:         496
    Number of Training batches:    16 

    Loss:  1.5233161371696808
    Accuracy:  0.4692870964070266
Iteration: 1888
    Time:  96.896
    Number of Data points:         472
    Number of Training batches:    15 

    Loss:  0.7516002038563402
    Accuracy:  0.4242326516674887
Iteration: 1889
    Time:  91.525
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  1.3141406352289937
    Accuracy:  0.4639754145008916
Iteration: 1890
    Time:  98.269
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.6896799672116395
    Accuracy:  0.49127366543992107
Iteration: 1891
    Time:  90.345
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.6599994457162516
    Accuracy:  0.4692301855294609
Iteration: 1892
    Time:  82.188
    Number of Data points:         440
    Number of Training batches:    14 

    Loss:  0.5928998161895324
    Accuracy:  0.46388056303828207
Iteration: 1893
    Time:  74.362
    Number of Data points:         368
    Number of Training batches:    12 

    Loss:  0.724893554928673
    Accuracy:  0.4835337860909815
Iteration: 1894
    Time:  97.315
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  0.706925438530052
    Accuracy:  0.5300679136472285
Iteration: 1895
    Time:  86.401
    Number of Data points:         456
    Number of Training batches:    15 

    Loss:  0.650753310526106
    Accuracy:  0.5068482756004098
Iteration: 1896
    Time:  111.295
    Number of Data points:         520
    Number of Training batches:    17 

    Loss:  1.5346876488714036
    Accuracy:  0.5096938194786964
Iteration: 1897
    Time:  81.042
    Number of Data points:         408
    Number of Training batches:    13 

    Loss:  0.8375915136655402
    Accuracy:  0.46251470197670447
Iteration: 1898
    Time:  69.912
    Number of Data points:         392
    Number of Training batches:    13 

    Loss:  0.6967581867910291
    Accuracy:  0.44754714117691696
Iteration: 1899
    Time:  97.422
    Number of Data points:         504
    Number of Training batches:    16 

    Loss:  1.5248745855279258
    Accuracy:  0.4490078537011041
Iteration: 1900
    Time:  77.511
    Number of Data points:         432
    Number of Training batches:    14 

    Loss:  1.5056512515180285
    Accuracy:  0.4528208824980081
Iteration: 1901
    Time:  87.906
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.4120557290354476
    Accuracy:  0.4766665401980498
Iteration: 1902
    Time:  80.623
    Number of Data points:         416
    Number of Training batches:    13 

    Loss:  1.46431605844581
    Accuracy:  0.4865880031870091
Iteration: 1903
    Time:  88.772
    Number of Data points:         424
    Number of Training batches:    14 

    Loss:  0.667659361226961
    Accuracy:  0.447110824448913
Iteration: 1904
    Time:  84.251
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.0699973343106972
    Accuracy:  0.5043062564024737
Iteration: 1905
    Time:  76.955
    Number of Data points:         384
    Number of Training batches:    12 

    Loss:  1.4130417466892018
    Accuracy:  0.5177941343855522
Iteration: 1906
    Time:  89.958
    Number of Data points:         448
    Number of Training batches:    14 

    Loss:  1.2690244049517785
    Accuracy:  0.5352657737982319
Iteration: 1907
    Time:  95.23
    Number of Data points:         464
    Number of Training batches:    15 

    Loss:  1.2248377084170339
    Accuracy:  0.5593770155935804
Iteration: 1908
    Time:  109.148
    Number of Data points:         536
    Number of Training batches:    17 

    Loss:  0.7622026333454994
    Accuracy:  0.5431763857798687
Iteration: 1909
